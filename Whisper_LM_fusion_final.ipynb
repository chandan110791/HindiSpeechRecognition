{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandan110791/HindiSpeechRecognition/blob/main/Whisper_LM_fusion_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtnWp1Z9NIrh"
      },
      "source": [
        "# Fusing LM with Whisper for lower WER\n",
        "The aim is to fuse a BPE-level LM scores with the generated tokens scores while beam-search decoding in Whisper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWD69559NPaz"
      },
      "source": [
        "## **MILESTONE 1**:\n",
        "Instantiate a Language Model to be integrated with Whisper.\n",
        "The chosen LM is an n-gram language model, trained with [KenLM](https://github.com/kpu/kenlm) library.\n",
        "\n",
        "### Step 1:\n",
        "Write code to run an already available LM in a standalone manner and be able to give a score any input sequence.\n",
        "**Chosen Model**: [Riva ASR Hindi LM](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN5ZcXEbPFgD"
      },
      "source": [
        "Download and build the KenLM toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOD5vBabeTED",
        "outputId": "e245aa24-055e-4895-e543-8bc2052c8c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-13 11:27:39--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 480.36K  1.67MB/s    in 0.3s    \n",
            "\n",
            "2023-11-13 11:27:40 (1.67 MB/s) - written to stdout [491888/491888]\n",
            "\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.3s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 50%] Built target probing_hash_table_benchmark\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 57%] Built target kenlm_filter\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 75%] Built target fragment\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 77%] Built target query\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 86%] Built target kenlm_benchmark\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 91%] Built target kenlm_builder\n",
            "[ 92%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 96%] Built target phrase_table_vocab\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "build_binary  filter\tkenlm_benchmark  phrase_table_vocab\t       query\n",
            "count_ngrams  fragment\tlmplz\t\t probing_hash_table_benchmark\n"
          ]
        }
      ],
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz\n",
        "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
        "!ls kenlm/build/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQgYC5RKfKHp"
      },
      "source": [
        "Download the KenLM Python library\n",
        "\n",
        "❗❗**Don't forget to restart the runtime after running this cell** ❗❗\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C3lwRxNebYv",
        "outputId": "e2f9d66a-0bcc-4f1f-ab47-43bffd8fe3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184345 sha256=6cc9a5db8180947baa0ae0b8fd35c040b77ff8e307bf437b2fafd6295101aa79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9az3r8uo/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJviLM3FcWAB"
      },
      "source": [
        "## ***Pointer 1:Please add comments on the model being downloaded and whats its purpose ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr61mDKxZru1"
      },
      "source": [
        "Downloading the Hindi ASR n-gram language model from Nvidia which can be found [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n",
        "\n",
        "This will be used for fusion with Whisper.\n",
        "I uploaded the binary version to a shareable location in my Gdrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "NU0mgmnmhsxe",
        "outputId": "6484130f-7253-4276-9d29-58098fb08827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 147MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LXkmNaklfx",
        "outputId": "151e2382-782e-41f4-8c8d-316b4fa00a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "import kenlm\n",
        "model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(model.order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fo71Q-qbfuU",
        "outputId": "a853e9f9-0f9d-4ed4-eb86-a3fae25a457d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-20.935253143310547 -21.663846969604492\n"
          ]
        }
      ],
      "source": [
        "# Below are 2 pairs of sentences that sound exactly the same in hindi but one of them is incorrect (lexically or semantically)\n",
        "# Generated using Bing Chat\n",
        "book_correct = \"मुझे यह किताब पसंद है।\"\n",
        "book_incorrect = \"मुझे यह किताब पसन्द है।\"\n",
        "\n",
        "correct_score = model.score(book_correct)\n",
        "incorrect_score = model.score(book_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDslvQ98bhFd",
        "outputId": "335af234-ca71-441e-f1c2-d51c10524ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-19.827430725097656 -22.76061248779297\n"
          ]
        }
      ],
      "source": [
        "sings_correct = \"वह बहुत अच्छा गाता है।\"\n",
        "sings_incorrect = \"वह बहुत अच्छा घाता है।\"\n",
        "\n",
        "\n",
        "correct_score = model.score(sings_correct)\n",
        "incorrect_score = model.score(sings_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt69WiP8dIJV"
      },
      "source": [
        "## ***Pointer 2:Please elaborate on the model being downloaded and whats its purpose . Also , why are we doing it two times  ***\n",
        "\n",
        "This is unnecessary and can be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SJcuIrcggxHt",
        "outputId": "f2eafece-e032-484d-d4bf-7ad71cfd5cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4xQ3YCtsyONtpccGjOD1s9FtHqBX7RL\n",
            "To: /content/language_model_3p0.arpa\n",
            "100%|██████████| 3.18G/3.18G [00:33<00:00, 95.6MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.arpa'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # download the original arpa LM file for inspection\n",
        "# url = \"https://drive.google.com/uc?id=1-4xQ3YCtsyONtpccGjOD1s9FtHqBX7RL\"\n",
        "# output = \"language_model_3p0.arpa\"\n",
        "# gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wuzy3sEdTsq"
      },
      "source": [
        "$$:Please elaborate if we need to prepare a new arpa file for our model\n",
        "\n",
        "We can use this model for the time being, and finetune it later with the text data from our training set.\n",
        "However, I think it's not likely to come up with a better model than this, as this model is built by a team in Nvidia and it's probable that our training set is included in training this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43gXFE7Sg8kU",
        "outputId": "86667dff-df12-4421-d17b-1d376ffebb01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.2548329\t<s> दोनों ही झल्लाये\n",
            "-0.2760634\t<s> चौधरी के अशुभचिंतकों\n",
            "-0.04973512\tडालियों पर बैठी शुकमंडली\n",
            "-0.07060567\tमनुष्यों को उन्हें बेमुरौवत\n",
            "-0.049646165\tऔर कड़क कर बोलेमेरी\n",
            "-0.04038189\tनिराश हो कर कहानहीं\n",
            "-0.08863469\tपड़ते ही वह अव्यवस्थितचित्त\n",
            "-0.19321889\tदोनों पक्षों से सवालजवाब\n",
            "-0.051110353\tझगड़ू साहु ने कहासमझू\n",
            "-0.20675866\tकरें तो उनकी भलमनसी\n",
            "-0.04876329\tनीति को सराहता थाइसे\n",
            "-0.06436408\t<s> मित्रता की मुरझायी\n",
            "-0.23735626\tकी गहराई से उपजतें\n",
            "-0.17502813\tपूर्णता की ओर बढातें\n",
            "-0.18197767\tजहाँ से अच्छा हिन्दोसिताँ\n",
            "-0.04437429\tहैं इसकी यह गुलसिताँ\n",
            "-0.06926097\tसंतरी हमारा वह पासबाँ\n",
            "-0.09434804\tजिनके दम से रश्कएजनाँ\n",
            "\n",
            "\\end\\\n"
          ]
        }
      ],
      "source": [
        "# inspect the last 20 lines inside the LM source\n",
        "!tail -20 language_model_3p0.arpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQA6huWockMP"
      },
      "outputs": [],
      "source": [
        "# some useful KenLM commands for future reference\n",
        "# generate binary\n",
        "# !kenlm/build/bin/build_binary dataset_tokenized_3gram.arpa dataset_tokenized_3gram.binary\n",
        "# create a new LM\n",
        "# !kenlm/build/bin/lmplz -o 3 --text dataset_tokenized.txt --arpa dataset_tokenized_3gram.arpa --discount_fallback\n",
        "# !tail -20 dataset_tokenized_3gram.arpa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGlHlhrffpHT"
      },
      "source": [
        "# Integrating the LM with Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKmnxRsofoXu",
        "outputId": "b9938565-d8e9-4d25-e8c4-7262cabc01c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m7.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m963.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=799894 sha256=5cd706d6cdee8f6830cf056e88a1d63ee3addf9ed9f5475756fcf6de1929ec39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wakv1z_z/wheels/7e/59/d2/1662a1f0ae2217e2cd01935b4ac823b4eade5c382bed87a164\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=e3f1120ba7d88a2773bd61ab328bf198c9f34c030eacff15beb2c74d23a483f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai-whisper\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28qXwUAIhQmA"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import kenlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h061i7Dhaeq",
        "outputId": "d6884838-d9bf-4a41-bef8-d78b259d8cfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 112MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWRBxk5khiKQ",
        "outputId": "a95ab83a-f2f9-4e97-cd17-cfa061aa7d15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\n",
            "To: /content/sample.wav\n",
            "100%|██████████| 197k/197k [00:00<00:00, 77.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOZKw5wGlNWm"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd1uG_bTTeSC"
      },
      "outputs": [],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDH0eYJ8TkU4"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmbBreqNX3IX"
      },
      "source": [
        "## Baseline Whisper\n",
        "Without nbest or LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LFz_dwKdlXyR",
        "outputId": "37969971-4d76-4717-f7c7-53447af2d18c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uew0igzbYPO"
      },
      "source": [
        "# Decoding with LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wAsYJNj3blQO",
        "outputId": "222b37f8-62be-4e2b-b86a-c7b1917097c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:04<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding the LM\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEluDSiWd2iC"
      },
      "source": [
        "$$:\n",
        "\n",
        "## ***Pointer 4: Getting an error here while trying to run the code . Elaborate a bit on the what happening here . Can you please refer to the function with changes done  ***\n",
        "\n",
        "The error was due to the fact that the imported whisper here is the original one, which doesn't include the changed that we did to the decoding options.\n",
        "\n",
        "Replaced this:\n",
        "```\n",
        "!pip install openai-whisper\n",
        "```\n",
        "with this:\n",
        "```\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "```\n",
        "\n",
        "and the error is fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVX9bKV9BaR"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=5,\n",
        "        patience=1.0, lm_path=\"/content/language_model_3p0.bin\", lm_alpha=1.0, lm_beta=0.0,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "decoding_withLM = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BPtkRefB-FUv",
        "outputId": "7bd1f8b6-1eb1-4066-f59d-95a6917af9aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoding_withLM.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzCM2xRb28i"
      },
      "source": [
        "# Decoding with nbest (beam search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF6AnpXkb5XM",
        "outputId": "a314a338-bb04-440b-c8ff-48efabf24b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45291578358617324\n",
            "ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45523316981428763\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है. -0.47296941078315347\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं -0.48318856449450476\n",
            "ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है -0.46669308344523114\n"
          ]
        }
      ],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "nbest = whisper.decode(model, mel, options)\n",
        "\n",
        "\n",
        "for candidate in nbest:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J38npjnkcDW7"
      },
      "source": [
        "### Adding LM rescoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23wLneazBit1",
        "outputId": "072daaa5-d1c2-4466-fa8d-f91450ef2d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(lm_model.order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAdRnI_UBzWJ",
        "outputId": "44cedf0d-4d24-4c0d-fdfe-6cd16a271c6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45291578358617324,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45523316981428763,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.',\n",
              "  -0.47296941078315347,\n",
              "  -44.10427474975586),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं',\n",
              "  -0.48318856449450476,\n",
              "  -37.30411148071289),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.46669308344523114,\n",
              "  -37.54087829589844)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "nbest_with_lm_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUBQ-WVCCH1N",
        "outputId": "7b430fe5-3f6c-4549-a8a0-955bf8efc6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8135461623093178),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8158635485374321),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है', -0.8421018664042155),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं', -0.8562296793016337),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.', -0.9140121582807121)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh5OtW5kz7gU"
      },
      "source": [
        "# Decoding with nbest (best of N hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rof-6s_mykVX"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, best_of=10, return_nbest=True, without_timestamps=True, temperature=0.3, language=\"hi\")\n",
        "nbest_best_of_n_hyp = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuDcmFH106lC",
        "outputId": "cded2418-b2e9-4e0f-c99f-a6d14937f715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45742596898760113\n",
            "ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है -0.5202431113032971\n",
            "ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है -0.5065439448637121\n",
            "ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey. -0.9538334877260269\n",
            "ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है -0.5101523081461589\n",
            "ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है -0.4865361798194147\n",
            "ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है -0.49694071144893254\n",
            "ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है -0.5291237149919782\n",
            "ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है -0.5426437135726686\n",
            "ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है -0.49345003325363684\n"
          ]
        }
      ],
      "source": [
        "for candidate in nbest_best_of_n_hyp:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOXOEofa2ZAe",
        "outputId": "980fca20-e1d0-4608-9c31-8ed779ab9a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45742596898760113,\n",
              "  -35.82866668701172),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है',\n",
              "  -0.5202431113032971,\n",
              "  -49.43550491333008),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -0.5065439448637121,\n",
              "  -54.91597366333008),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -0.9538334877260269,\n",
              "  -81.96270751953125),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है',\n",
              "  -0.5101523081461589,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.4865361798194147,\n",
              "  -46.603515625),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है',\n",
              "  -0.49694071144893254,\n",
              "  -49.201133728027344),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है',\n",
              "  -0.5291237149919782,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.5426437135726686,\n",
              "  -42.747047424316406),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है',\n",
              "  -0.49345003325363684,\n",
              "  -50.678977966308594)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest_best_of_n_hyp]\n",
        "nbest_with_lm_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIuqEbJ-2d-k",
        "outputId": "bb2afb82-8baa-45ec-a4cd-c152175916cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8157126358577182),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.9525713360694148),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.9701141878158327),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है', -0.976416384379069),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है', -0.9889520487292061),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है', -0.9953877912248883),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है', -1.0002398129167227),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है', -1.014598160436598),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -1.0557036814970129),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -1.7734605629213394)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores_bestofNSampling = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores_bestofNSampling.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores_bestofNSampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcAl6kVkuSSw"
      },
      "source": [
        "# **RUN THE NOTEBOOK STARTING HERE**\n",
        "\n",
        "# The next sections include:\n",
        "- Importing a finetuned huggingface model to our codebase\n",
        "- Running the evaluation of the 4 decoding variants on the imported dataset\n",
        "- Computing the WER and CER for each of the decoding variants\n",
        "\n",
        "## The decoding strategies are:\n",
        "1. baseline decoding without LM\n",
        "2. Deep fusion of the LM with the token probabilities during beam search decoding (try to find the optimal value for lm_alpha)\n",
        "3. Shallow fusion by rescoring the N best candidates generated through beam search (try to find the optimal value for lm_weight)\n",
        "4. Shallow fusion by rescoring the N best candidates generated through greedy decoding using best of N sampling (try to find the optimal value for lm_weight and temperature)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRMuGzF1WX8",
        "outputId": "f2bfe8d3-5dae-4717-81d9-e70b0e86ed0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m|\u001b[0m \u001b[32m7.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=799899 sha256=52f9e635162731a9f1bfbfc551f7266e19a5f655431ba9e8f58ebd211e82334e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3wimy175/wheels/7e/59/d2/1662a1f0ae2217e2cd01935b4ac823b4eade5c382bed87a164\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=3d15f2aef62dcd0567448c806077e53dd1f4747d288df16ebc5a1cfb4f443474\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[2K     \u001b[32m|\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184304 sha256=3e5b619d14348c095bf88e28e778aa60041c0888a229f7e357c4f5cee3e9ec35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wk4viun8/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-m50aex6_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-m50aex6_\n",
            "  Resolved https://github.com/huggingface/transformers to commit 35551f9a0f66a22de4971b4a51b3c172d3b87f95\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.36.0.dev0-py3-none-any.whl size=8049176 sha256=e34778efa0242b7bd19eedf151659d4e99ee2a36775e456c82e491f266054f93\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ff_s_ink/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.0.dev0\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.5.2\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.7.1-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=970f42c669eafd485cc2f5116f3c4b140ce41866dcbe4cab52f32f52e182daf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.7.1 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 orjson-3.9.10 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install transformers\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "# !pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Otxfl9LTGNej",
        "outputId": "9b867c2a-fe1d-4d53-8b86-45cfda5113a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:05<00:00, 52.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'language_model_3p0.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9rpmw6hfbcf"
      },
      "source": [
        "$$\n",
        "\n",
        "$$:\n",
        "\n",
        "## ***Pointer 5: its looking for a file named as pytorchmodel.bin , it does not exists hence note  able to integrate the model : CKSINGH/whisper-small-hi-iiib tuned at : https://colab.research.google.com/github/chandan110791/HindiSpeechRecognition/blob/main/fine_tune_whisper_iiitb.ipynb#scrollTo=d7030622-caf7-4039-939b-6195cdaa2585  . Any inputs ***\n",
        "\n",
        "The reason for this is that the model file after finetuning must be pickled:\n",
        "so pytorch_model.bin should be found in this path:\n",
        "https://huggingface.co/CKSINGH/whisper-small-hi-iiib/tree/main\n",
        "\n",
        "Will use this one https://huggingface.co/sanchit-gandhi/whisper-small-hi/tree/main to make the required changes to the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXpUd4OoS3y"
      },
      "source": [
        "## In the next cell, you need to change the repo id to your repo after generating the pytorch_model.bin (pickle format of the finetuned model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def resample_audio(input_file_path, output_file_path, orig_sr, target_sr):\n",
        "    \"\"\"\n",
        "    Resample an audio file from original sample rate to target sample rate.\n",
        "\n",
        "    Args:\n",
        "    - input_file_path (str): Path to the input audio file.\n",
        "    - output_file_path (str): Path where the resampled audio file will be saved.\n",
        "    - orig_sr (int): Original sample rate of the audio file.\n",
        "    - target_sr (int): Target sample rate to resample the audio file.\n",
        "    \"\"\"\n",
        "    # Load the audio file\n",
        "    audio, sr = librosa.load(input_file_path, sr=orig_sr)\n",
        "\n",
        "    # Resample to target sample rate\n",
        "    audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    # Save the resampled audio\n",
        "    sf.write(output_file_path, audio_resampled, target_sr)\n"
      ],
      "metadata": {
        "id": "vehLOB9pCfdU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "7b37d0c9652b46d9bc8b217c08f1bd0c",
            "e6cb6986cf094da88e6bd72086c32c51",
            "2021abeaecb94bd7a7eb0cf6aef386af",
            "92c560cefd5745cf984ba6f3aef599a7",
            "41fd740b76e64ea0a6f60a73f5a43458",
            "dbdb5749b25745cd96a89d5901fba6cc",
            "fc61e213b7e0476097af539110e8f606",
            "3c8834384af04762bda88e03db6d933f",
            "c9dd1179d205455d8c28bab58dbb7476",
            "4dc6e4d43e9b4d86bbb984d4f756539c",
            "78b73b96a00a4d15b1471208cd1b8527"
          ]
        },
        "id": "kMDX0Asjuc4e",
        "outputId": "3d55ed9a-c68c-4463-ab2c-af164843a38b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b37d0c9652b46d9bc8b217c08f1bd0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/pytorch_model.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import whisper\n",
        "import kenlm\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "import torch\n",
        "import jiwer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "# using pickle to serialize the map_dict\n",
        "import pickle\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "filename = \"pytorch_model.bin\"\n",
        "\n",
        "\n",
        "#hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-firefox\", filename=filename, local_dir=\"/content/\")\n",
        "#hf_hub_download(repo_id=\"sanchit-gandhi/whisper-small-hi\", filename=filename, local_dir=\"/content/\")\n",
        "hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-graminVoice\", filename=filename, local_dir=\"/content/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKwYojN1ol9j"
      },
      "source": [
        "# Here you need to change the model size from \"small\" to \"medium\" if you finetuned the whisper-medium (as the one in this repo: https://huggingface.co/CKSINGH/whisper-small-hi-iiib/tree/main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P2IO4Vy8u4GW"
      },
      "outputs": [],
      "source": [
        "# to enable verbose printing of exceptions (+ layers matching name)\n",
        "DEBUG = True\n",
        "\n",
        "# set to True if your custom model has been trained using DDP (multi-gpu)\n",
        "# as in my case, in the custom HF model, keys have a prefix (model.)\n",
        "# it should come from the fact that I have trained on a milti-gpu machine, using DDP\n",
        "DDP_TRAINED = True\n",
        "\n",
        "# if DDP we have to add a prefix to match with the HF state_dict\n",
        "if DDP_TRAINED:\n",
        "    PREFIX = \"model.\"\n",
        "else:\n",
        "    PREFIX = \"\"\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "# the device where you're running this code\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# the name of the file with your fine-tuned model\n",
        "FINETUNED_MODEL = \"pytorch_model.bin\"\n",
        "\n",
        "# the name of the file for the serialized map_dict\n",
        "# a different name, to avoid overwrite it\n",
        "FILE_DICT = MODEL_SIZE + \"_map_dict05.pkl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q3vqObGaMSt9"
      },
      "outputs": [],
      "source": [
        "def import_hf_model(finetuned_model, model_size, device, file_dict, debug=True):\n",
        "\n",
        "  def has_numbers(inputString):\n",
        "      return any(char.isdigit() for char in inputString)\n",
        "\n",
        "  # next functions are used to make sanity checks for the mappings\n",
        "\n",
        "  # get if it is encoder or decoder\n",
        "  def extract_function(key_name):\n",
        "      # encoder or decoder is the first part of the key\n",
        "      first_part = key_name.split(\".\")[0]\n",
        "\n",
        "      key_func = None\n",
        "      if first_part in [\"enconder\", \"decoder\"]:\n",
        "          key_func = first_part\n",
        "\n",
        "      return key_func\n",
        "\n",
        "  def extract_layer_num(key_name):\n",
        "      # layer num is the third piece\n",
        "      layer_num = None\n",
        "\n",
        "      if has_numbers(key_name):\n",
        "          layer_num = key_name.split(\".\")[2]\n",
        "\n",
        "      return layer_num\n",
        "\n",
        "  # check that the two keys are for layers\n",
        "  # with the same function\n",
        "  # (both encoder or both decoder)\n",
        "  # and have the same layer number\n",
        "  # this way we are super-safe (I think)\n",
        "  def sanity_check(key1, key2):\n",
        "      is_ok = True\n",
        "\n",
        "      # check same func (encoder or decoder)\n",
        "      func1 = extract_function(key1)\n",
        "      func2 = extract_function(key2)\n",
        "\n",
        "      if func1 != func2:\n",
        "          print(f\"Warning: layers seem to have different functions: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      # check same layer_num\n",
        "      layer1 = extract_layer_num(key1)\n",
        "      layer2 = extract_layer_num(key2)\n",
        "\n",
        "      if layer1 != layer2:\n",
        "          print(f\"Warning: layers seem to have different numbers: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      return is_ok\n",
        "\n",
        "  if not os.path.isfile(file_dict):\n",
        "    # Vanilla means: not custom trained\n",
        "    print()\n",
        "    print(\"Loading vanilla Whisper model\")\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "    print(\"Loading vanilla HF Model\")\n",
        "    hugging_face_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        \"openai/whisper-\" + model_size\n",
        "    ).to(device)\n",
        "\n",
        "    # extract state-dict from both\n",
        "    state_d_openai = model.state_dict()\n",
        "    state_d_huggingface = hugging_face_model.model.state_dict()\n",
        "\n",
        "    # build the mapping between keys...\n",
        "    map_dict = {}\n",
        "    print(\"Matching layers...\")\n",
        "\n",
        "    # for every layer in OpenAI model\n",
        "    n_sanity_ok = 0\n",
        "\n",
        "    #\n",
        "    # here we're considering the cartesian product of the two state dict and try to match\n",
        "    # rules applied:\n",
        "    # 1. the two layers have the same shape\n",
        "    # 2. the two layer have the same parameters' values\n",
        "    # 3. we apply sanity check (see function above)\n",
        "    #\n",
        "    for k in tqdm(state_d_openai):\n",
        "        # find a layer in the HF model, check with j\n",
        "        for j in state_d_huggingface:\n",
        "            # where parameters have same shape and same values\n",
        "            if state_d_huggingface[j].shape == state_d_openai[k].shape:\n",
        "                if torch.all(torch.eq(state_d_huggingface[j], state_d_openai[k])).item():\n",
        "                    # found, register the mapping\n",
        "                    map_dict[k] = j\n",
        "                    # make some check and eventually print a warning\n",
        "                    if sanity_check(k, j) == True:\n",
        "                        n_sanity_ok += 1\n",
        "\n",
        "                        # if you enable thsi print you can see the name of the layer\n",
        "                        # chosen in the match and you will se that they have the same functions\n",
        "                        if debug:\n",
        "                            print(k, j)\n",
        "\n",
        "                    break\n",
        "\n",
        "\n",
        "    # check if we have matched every entry\n",
        "    print(\"Check if we have matched every entry in state_dict...\")\n",
        "    print()\n",
        "    print(f\"Number of keys: {len(map_dict.keys())}\")\n",
        "    assert len(map_dict.keys()) == len(state_d_openai.keys()), \"The match is not complete !\"\n",
        "\n",
        "    print(f\"Number of sanity_check ok: {n_sanity_ok}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Match is complete !!!\")\n",
        "    print()\n",
        "\n",
        "\n",
        "    # serialize the map_dict to file\n",
        "    print(\"Serializing map_dict...\")\n",
        "\n",
        "    with open(file_dict, \"wb\") as f:\n",
        "        pickle.dump(map_dict, f)\n",
        "        f.close()\n",
        "\n",
        "    print(f\"map_dict saved as: {file_dict}...\")\n",
        "    print()\n",
        "\n",
        "  else:\n",
        "    # loading with match keys\n",
        "    # restart from pickle file\n",
        "    print(\"Reloading map_dict...\")\n",
        "    print()\n",
        "    with open(file_dict, \"rb\") as f:\n",
        "        map_dict = pickle.load(f)\n",
        "\n",
        "  # loading fine-tuned dict\n",
        "  print(\"Loading fine tuned dict...\")\n",
        "\n",
        "  # added map_location to handle the fact that the custom model has been trained on GPU\n",
        "  state_dict_finetuned = torch.load(finetuned_model, map_location=torch.device(device))\n",
        "\n",
        "  print(state_dict_finetuned.keys())\n",
        "  # build the state_dict to be used\n",
        "  # take the key name from standard (OpenAI) and the value from finetuned (HF)\n",
        "  print(\"Rebuild the state dict...\")\n",
        "  new_state_dict = {}\n",
        "  n_except = 0\n",
        "  for k in tqdm(map_dict.keys()):\n",
        "      try:\n",
        "        # You must add \"model.\" if you have used DDP in custom training\n",
        "        # see DDP_TRAINED above\n",
        "        # PREFIX is added to a HF fine-tuned 8with DDP). It is not in vanulla HF models\n",
        "        new_state_dict[k] = state_dict_finetuned[PREFIX + map_dict[k]]\n",
        "      except Exception as ex:\n",
        "        n_except += 1\n",
        "\n",
        "        if debug:\n",
        "            print(\"exception\")\n",
        "            print(PREFIX + map_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  msg_err = f\"Rebuild state dict failed, {n_except} pick failed\"\n",
        "  assert n_except == 0, msg_err\n",
        "\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(\"Loading the final model...\")\n",
        "  model.load_state_dict(new_state_dict)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "806080cba50b42b8922fd85ad9b9e836",
            "3ee8e22d71d64547b448d55cf413c4fe",
            "21f43337225e4ec5bd0bad2944493929",
            "30c1f4e66d95487bae98a1209cc8a818",
            "5c48a0a1f752470687e8dd09e1533fd5",
            "d2ad19f44bf34038822d84b7f9dbe0d5",
            "41335379ccbb4437b885881d7ffae38f",
            "b21a5d30dc6648fb85aecc748dd095ea",
            "ee95e491eafb4df298c4cf35b29268e3",
            "48eb3725ef29428493bf82df67d84931",
            "e3cd6001976a4b0caa36136a79cbe66b",
            "e9a537c524a04a6dbd62faae16b5f6a8",
            "33fb0f90cec544b2ab4452a7ea76d193",
            "e0b70b7bb2e24d7d9e06054aba10ded6",
            "4c02e2870df7437093e6601f0b694e2f",
            "84e9ea63d8b24d63991e1e44c2b24c6e",
            "5c00fbc3423f4737bd80dab52d9abd26",
            "6ce0f28e3bde4018acb474c7b17570e4",
            "f8202a50b6444b37bd498e8056aaaa81",
            "246249c995594d8bab5506e4db1ea99f",
            "ca02d5f3bea94c598ab9d6e8e354d7b5",
            "500f0ae930d24c52ae169286b4a76ecb",
            "f6768953395749bbbb9e38679ea2798b",
            "886318f846884f2599bfc8f729e6bff9",
            "14394d3948c7441f9683a64f1a7d42ed",
            "6ac1f734c1fa481eb845a0a7a8784de4",
            "07fc379f8d124c1eb61eb4c4c96c087e",
            "e8d03f4bf262479dad370427b3bf5ec4",
            "e5f17fd3383f4746b22e79d96873d011",
            "63203d11435b4786a68c6700459408bf",
            "8f1941380a174f27a56b99ee1f757d31",
            "42b01fce9cc84fc8b3a84d0b2c0693d9",
            "840809356c1d4b4c88db70984ce585d4"
          ]
        },
        "id": "gCxqmfBJvE__",
        "outputId": "838b6e69-6063-4ddd-8cd1-06dd630f1ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading vanilla Whisper model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:07<00:00, 65.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading vanilla HF Model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "806080cba50b42b8922fd85ad9b9e836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9a537c524a04a6dbd62faae16b5f6a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.84k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6768953395749bbbb9e38679ea2798b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching layers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:01<00:00, 272.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if we have matched every entry in state_dict...\n",
            "\n",
            "Number of keys: 479\n",
            "Number of sanity_check ok: 479\n",
            "\n",
            "Match is complete !!!\n",
            "\n",
            "Serializing map_dict...\n",
            "map_dict saved as: small_map_dict05.pkl...\n",
            "\n",
            "Loading fine tuned dict...\n",
            "odict_keys(['model.encoder.conv1.weight', 'model.encoder.conv1.bias', 'model.encoder.conv2.weight', 'model.encoder.conv2.bias', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layer_norm.weight', 'model.encoder.layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layer_norm.weight', 'model.decoder.layer_norm.bias', 'proj_out.weight'])\n",
            "Rebuild the state dict...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:00<00:00, 999041.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the final model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = import_hf_model(finetuned_model=FINETUNED_MODEL, debug= False, model_size=MODEL_SIZE, device=DEVICE, file_dict=FILE_DICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A4eGVNxPC5U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d314288-38c2-4dea-c296-8d399f1477d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Whisper(\n",
              "  (encoder): AudioEncoder(\n",
              "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): TextDecoder(\n",
              "    (token_embedding): Embedding(51865, 768)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (cross_attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8536aa41d17347508a262bbc9693b7f8",
            "ba507efc55c145419acdec6f0fb62b2e",
            "f96cd823f757434997f49f4b2c7d2a04",
            "3f065f61e9e1443a85aee518670a4fa7",
            "ba67e8ff964d4073b870e1200a87fd4c",
            "ab9c06e19a154517b4ff46c7a52d29d4",
            "150486309a0540b0a51a96664f78aba7",
            "773b457557fd4352a317068d87fa4eef",
            "b805718a8b76423386511730e0fdeaff",
            "ab1471db6c574235ac5967dd80734786",
            "ff114fffeab840c6a8fab1662d1dddd7",
            "24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "e543d211badc4d41bd944df904ce0317",
            "d6ef36d77a09460d82ce46f28df66665",
            "c16fa1150d12439688fa21af50d995c7",
            "aed79d83bbe84ba5aa53f601588c4ee8",
            "28b858b805f54292a322d13611833c33",
            "7d5806a46c454e0c9c3f1ca5f70d4279",
            "455bae593a3240d9ba064c213a90ece9",
            "ba5939381af044029e254989149974db",
            "75a0a08417de42e88bdf8ffc693f42b6",
            "bb853deecb594dad80ae466afa531d75",
            "920da0787e654f6bb9a0c76cc88f0f5c",
            "bbb0d45741c8401b819941a9eda1c1a7",
            "b8b595673f6a4db4a47a25e88ebc2d4e",
            "981bc86f56014362942f1fad9d5fe00c",
            "a0f33f70e05d4897aac484cb940392d4",
            "4928327c81124c60bd8e3aca15942167",
            "7390656d2d4240969f6202876d1a57c7",
            "f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "273a08df24d343a7a227d09b9e23ebb4",
            "3dd766dafea94135862b6e9e0d9876cf"
          ]
        },
        "id": "rasFuIlSix6U",
        "outputId": "32a54d14-6a4d-4a6a-803d-dd495eb93801"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8536aa41d17347508a262bbc9693b7f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# #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\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGPaVW4glVi"
      },
      "source": [
        "$$:\n",
        "\n",
        "$$\n",
        "\n",
        "$$:\n",
        "\n",
        "## ***Pointer 6: We need to evaluate and calculate the WER,CER  on the Test data shared using our final model . Below are some boiler plates code to do the same  ***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-VwhKrCShjPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "979e875132624fbc85665f648b9a87e9",
            "81170fe84f6b4fba9272357af4e16925",
            "52d677cc98b74d1fad58f15bbfc8e20a",
            "fa1ae95c7ce243be94ef6ddbde0dc8b8",
            "58536d4db90d4444bceac430ebd31d8a",
            "053c927f36354a53a152ab23ec693ec0",
            "edb675e244df4c68bcb7048bc001cefa",
            "26a60000f2094bd6876125b5477fdada",
            "230ba208ed774d6894238621da7b2db4",
            "1862d8ae289f4e6bb66b0164a43aa688",
            "ecf4f7f9c4114a738893729a9b2911e1",
            "7c1e161946dc4e5fa0ca908303a1ddfd",
            "d609396bb7d24763b99aba7fce03982e",
            "0c1b68df0ceb4b71af740d6ec957769e",
            "480d12f85b9e4bb3afcdb928088ed10a",
            "89c07ccb0ca844f483535687af2ff187",
            "854156701c2b4b648adf713aba345c47",
            "470a61e298f645ee86cdbb21e07d56fb",
            "8ea561cfbe004907bd1fe0f7746abd71",
            "bdddcbfae5614387809db477218d7db9",
            "1508e0451600433ca863124c575e99d0",
            "a03095e4886c4bbdbc44f395a71958df",
            "a4e06df394b14f1a96209c1b195d9cd2",
            "27d13e0e5b184bd4a0dc672cf107af52",
            "fca7eaa031ba4a1b9f385e3fb41d5790",
            "fbd3c1674b2f4e76bcb2e7692c2ad10c",
            "d3edaa1efc4841e493f993bec8af1e35",
            "5a4907162a8a4b7ca0eebe90fb66c94f",
            "254066cc6112408394d64f41fdffd936",
            "a5e95c75ab434bd19a80f583c27ad80d",
            "ffe6e3b7dd2147b3a9207fc1bea6e15a",
            "0e13c66fc02f40fbb988fec5e2836d6b",
            "c15e21009aad48d0921251a972028ffc",
            "2ef0a972dcfd4abfacd660902e52aed6",
            "ed47061b191448fc89834ebabbb408a2",
            "0f238c9460a244369dfbef5db1199cee",
            "e48b1604bd0c4a729fec0a6d33a8c959",
            "a75494fbb4394af8b794031950d9fa0b",
            "e7a0357d202f41f58eb631ff8eb2fd3b",
            "a24c1c896dd448cc82ddc16fd5ea9fa6",
            "3639d15728fa4b95bddcdc0d20e428a5",
            "f5c3edf8376a48a9b52b84ecb34b65c1",
            "cb5c371605cf4ba4a8783ed96c12fb29",
            "95d535810eb2432388ed5c73dbb495e0",
            "d8ee5553a67b4c0db2192bb358110a31",
            "3a50685284b644c4b0d91b8376e67f61",
            "196c3e63aafd406a8a2b8f69fb858cd2",
            "9f013b618d3d4ab99d2fedfa14e23600",
            "72d96bae804b4083a60ca335063f1623",
            "02c9ea6c2ebd49b6901e0e2981f5ab4b",
            "a9d2157036de4a8b860a51cf6366fe17",
            "10167ae3c0b3409a823befcc054d742c",
            "69ecc9797b84462e8ffb86f8dc28cabe",
            "6d75737f462b4a0daf1d75d5d7fea58f",
            "763fb4b9b45843e880ef34a6752d8d23",
            "a14bc2fefe174d0987e8ab712fb52a8a",
            "e6604430fd9446e78102a5daf2273bda",
            "ed8f13e567bc4569b0be12525822b4f7",
            "3c14ab46888d4bbda2ae91986a70d948",
            "1a75cdb54dec46439bbe71bc8ff6a93f",
            "a2d94de758d74c01aa2f55a0ee5cfc01",
            "de9420358f6d421b84a0366fa51e9565",
            "05ab465bb89540c79d84f9de33b29d63",
            "5867b57a731b43de824842b1adf62e19",
            "017e70c733fc4203a6e0ee81e19fa395",
            "0bb61eda82a74419a4584b0ca01f0330",
            "6c6fbe0253cb426e952c00f951d1fd04",
            "13a8f8aaa37a4b08a03c844a8ca0cd20",
            "a75d2d93591a436ba212b62a01d94b51",
            "e10c651a8ed54bbd90c489061c75a46b",
            "7787ee96365d46579ffc645630e60150",
            "609315a06c5d439fbcd40e252e87c101",
            "30ad17a8953d4447836e780a23269727",
            "e7d96d4cf8fd4e27a412acad0114c86c",
            "3285b6a95afe4df69856c12491a2d739",
            "3f8e1b31b18449b6bdaeda32f93c4a53",
            "9bbde12f22ce4360adcbaf7f55d1b990",
            "25475e38431f42b982eeb288369a9dba",
            "6fcbcae9b164425ab151e569b79b4c83",
            "3c2b9d2480ca4ebd8ada945f7ec4e6d0",
            "4ee847b3f93a4e7b811bf4e9752dfee0",
            "ca182311576f415e9cc64ed4c2eac7aa",
            "7ff8ea40bd904f008acd39829b2b7c04",
            "1ae56a3813d9432ab135b06a61824a14",
            "be1de5a57bab4e3a99ef4eee6e69bd99",
            "551374414a3b471c9e42c5ce03f56b7e",
            "14a8105297004d41923eb5c1cdec5367",
            "77e41cd0c1b44389af2b0876bb6e919f",
            "90650f5799154083a1d1504491a8912f",
            "1c5766760aba43caa370937f56279397",
            "94a8b7cd60a943698a3981481a10551a",
            "8dfa6c848a9b487ba0fa7dab2704b47a",
            "e8528e67bd0246cf8d3809adc9a2dc86",
            "9e64df3888944732925ab1260c835e6b",
            "738e0d35d9fd4a15bbebdb1d404b4f7a",
            "98f56383e72b421f95a72cc01cf55c54",
            "5a1e834f550641c4818eb98b39f8d204",
            "2f46f5db91a144debbd69eabf9c14f6f",
            "55d797ca131941bcbace399a16741089",
            "39f37df33d37428183d25aafa7678d46",
            "0563cbd7ca1f4c9091a1044fd4fdcbf7",
            "b851b485cf4e4e258ca665090ea540ee",
            "c048546ed6024768acde97cb8eb91405",
            "e2b59f12cdbc4559b67d79b6af614c99",
            "fa11b2cd6b9f479791a2db5d956c5d32",
            "f281c01fa768493f944b1938bb891f41",
            "0024401bfb244c30974e472d47dc615b",
            "d722dae3e800471aa1817f969f0ed60a",
            "16b9b2b0d3b546ebb19d09a4a07710f0",
            "8143d8ff89354778973d78d1ff3bdc8d",
            "33863613c1ed4511bc7b343d9e903e59",
            "d47d5fc52f1341f1b204896fab2d979f",
            "bb3457aae2f24a29aa5582c465584084",
            "b0415522224945ab9ae417199db3ba2c",
            "d39646d768b046d290c61c448ee76cf6",
            "bda2b240e8ca4da6abfcc8d378ee0819",
            "d7ba5cfec3a14826ab98b8008f643820",
            "3a37a5d51e6e43728de23ecf1d655bfa",
            "5d1195272ad54af5979c1a2776c78b1d",
            "68e9cfeeaa9340359d6f55d20e7678f6",
            "44f141c2859a463ebf61eaa06b2ac365"
          ]
        },
        "outputId": "719acac1-7593-411f-fbee-03e888e4e702"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/12.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "979e875132624fbc85665f648b9a87e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating txt.done.data.utf8 split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c1e161946dc4e5fa0ca908303a1ddfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/453M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e06df394b14f1a96209c1b195d9cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fac0f3e80>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ef0a972dcfd4abfacd660902e52aed6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fac0f3e80>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8ee5553a67b4c0db2192bb358110a31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fa20b8790>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a14bc2fefe174d0987e8ab712fb52a8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fa20bbbe0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating other split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c6fbe0253cb426e952c00f951d1fd04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fa20bba90>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validated split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25475e38431f42b982eeb288369a9dba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fa20bb460>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating invalidated split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90650f5799154083a1d1504491a8912f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7a3fa20bbb20>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/64.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39f37df33d37428183d25aafa7678d46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating text split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33863613c1ed4511bc7b343d9e903e59"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Prepare Test Data for calculating Wer and CER\n",
        "\n",
        "import datasets\n",
        "# import the load_dataset function\n",
        "from datasets import load_dataset\n",
        "\n",
        "# specify the URL directory and the data files\n",
        "# load the dataset from the URL directory\n",
        "\n",
        "\n",
        "datasets.config.DEFAULT_MAX_BATCH_SIZE = 10\n",
        "dataset_1 = load_dataset(\"datadownload_iith.py\")\n",
        "dataset_2 = load_dataset(\"datadownload.py\")\n",
        "dataset_3 = load_dataset(\"graminVoiceDatadownload.py\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXPnPS-3AEXa",
        "outputId": "a367e078-d549-46a3-ab69-c61c55d55b3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    txt.done.data.utf8: Dataset({\n",
              "        features: ['path', 'audio', 'sentence'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Assuming dataset_3 is your DatasetDict\n",
        "# dataset_3 = ...\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 1000  # total number of rows in the dataset\n",
        "start_index = num_rows - 100\n",
        "\n",
        "# Select the last 100 rows\n",
        "dataset_1_last_100_rows = dataset_1['txt.done.data.utf8'].select(range(start_index, num_rows))\n",
        "\n",
        "# last_100_rows now contains the last 75 rows of the dataset"
      ],
      "metadata": {
        "id": "S_m018srYKIr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB8KANPKX_Dp",
        "outputId": "9cb10d8d-d670-4c9a-ffe5-bfff36b4ae33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 4630\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 3072\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 2416\n",
              "    })\n",
              "    other: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 3767\n",
              "    })\n",
              "    validated: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 10173\n",
              "    })\n",
              "    invalidated: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_2=dataset_2.remove_columns(['client_id', 'path', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'])"
      ],
      "metadata": {
        "id": "E6HMA0vFYSqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Assuming dataset_3 is your DatasetDict\n",
        "# dataset_3 = ...\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 100  # total number of rows in the dataset\n",
        "start_index = 0\n",
        "\n",
        "# Select the last 75 rows\n",
        "dataset_2_first_100_rows = dataset_2['test'].select(range(0, num_rows))\n",
        "\n",
        "# last_75_rows now contains the last 75 rows of the dataset\n"
      ],
      "metadata": {
        "id": "GJshdLvxYTpg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aSZRHLUYCnO",
        "outputId": "b61ddcc1-f2d4-42f9-c2be-2a01559435e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    text: Dataset({\n",
              "        features: ['path', 'audio', 'sentence'],\n",
              "        num_rows: 1032\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3=dataset_3.remove_columns(['path'])"
      ],
      "metadata": {
        "id": "XpSfUaWxYZ7j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Assuming dataset_3 is your DatasetDict\n",
        "# dataset_3 = ...\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 1032  # total number of rows in the dataset\n",
        "start_index = num_rows - 100\n",
        "\n",
        "# Select the last 100 rows\n",
        "dataset_3_last_100_rows = dataset_3['text'].select(range(start_index, num_rows))\n",
        "\n",
        "# last_75_rows now contains the last 75 rows of the dataset\n"
      ],
      "metadata": {
        "id": "fiBWaQ7zYb0s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combined_dataset = datasets.concatenate_datasets([dataset[\"train\"],dataset[\"validation\"],dataset[\"test\"], dataset[\"text\"],dataset[\"txt.done.data.utf8\"]])\n",
        "combined_dataset = datasets.concatenate_datasets([dataset_1_last_100_rows,dataset_2_first_100_rows,dataset_3_last_100_rows])"
      ],
      "metadata": {
        "id": "zWv8x_mtYjNn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, load_metric\n",
        "\n",
        "# Define the split ratios\n",
        "#train_split = 0.75  # 80% of the data\n",
        "test_wer_split = 0.90  # 80% of the data\n",
        "finetune_parmaters_split = 0.10  # 10% of the data\n",
        "\n",
        "# Compute the number of samples for each split\n",
        "num_samples = len(combined_dataset)\n",
        "num_train = int(test_wer_split * num_samples)\n",
        "num_test = num_samples - num_train# Remaining 10%\n",
        "\n",
        "# Split the combined dataset\n",
        "test_wer_split_dataset = combined_dataset.select(indices=list(range(num_train)))\n",
        "finetune_parmaters_split_dataset = combined_dataset.select(indices=list(range(num_train , num_samples)))\n",
        "\n",
        "# If you want to organize the split datasets in a DatasetDict for convenience:\n",
        "split_test_datasets = DatasetDict({\n",
        "    'test': test_wer_split_dataset,\n",
        "    'finetune': finetune_parmaters_split_dataset\n",
        "})\n",
        "\n",
        "# Verify the resulting datasets\n",
        "print(f'Train Dataset: {len(test_wer_split_dataset)} samples')\n",
        "print(f'Test Dataset: {len(finetune_parmaters_split_dataset)} samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9hr4teTYulj",
        "outputId": "323d2d91-5417-4b42-d7c6-5fdeea86b95d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: 270 samples\n",
            "Test Dataset: 30 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(split_test_datasets[\"finetune\"][1])\n",
        "print(split_test_datasets[\"test\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4Ag7em_Y_yA",
        "outputId": "5424c3da-ddef-4d9f-8159-2fd56b1f7fcc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'path': None, 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/67adca250279545403eae99b65a109a483020c860a12cc08a2c28c0cced51612/GV_Eval_3h/GV_Eval_3h/ZAudio/13-00155-06.mp3', 'array': array([-7.70203769e-06, -1.28522515e-07,  9.58610326e-06, ...,\n",
            "       -6.63560422e-06, -4.93867992e-06, -2.25788426e-06]), 'sampling_rate': 48000}, 'sentence': 'झारखण्ड में पिछले तीन चार दिनों से लगातार हो रही बारिश हो रही बारिश ने कई जिलों में काफी नुकसान पहुंचाया है ट्रेनें ट्रेनें सबसे प्रभावित हुई हैं', 'client_id': None, 'up_votes': None, 'down_votes': None, 'age': None, 'gender': None, 'accents': None, 'variant': None, 'locale': None, 'segment': None}\n",
            "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/b04225ba888d70832ffbdb4d63bbd8cba1570bdc3f400381ab06935ecb524fd9/iiit_hin/iiit_hin/Zwav/hin_0902.mp3', 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/b04225ba888d70832ffbdb4d63bbd8cba1570bdc3f400381ab06935ecb524fd9/iiit_hin/iiit_hin/Zwav/hin_0902.mp3', 'array': array([-1.85008743e-03, -2.78993463e-03, -3.55325127e-03, ...,\n",
            "        3.96938762e-04,  2.01676099e-04,  6.67182903e-05]), 'sampling_rate': 48000}, 'sentence': 'इस पर्वत पर एक सुंदर मंदिर बना हुआ', 'client_id': None, 'up_votes': None, 'down_votes': None, 'age': None, 'gender': None, 'accents': None, 'variant': None, 'locale': None, 'segment': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmZe8mxxkrHG"
      },
      "source": [
        "Evaluation Metrics on the Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#correct the sampling rate"
      ],
      "metadata": {
        "id": "Wm50URNVlxld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "T5Zpz_I3qpQM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class customDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
        "    It will drop the last few seconds of a very small portion of the utterances.\n",
        "    \"\"\"\n",
        "    original_sample_rate = 48000  # 48kHz\n",
        "    target_sample_rate = 16000    # 16kHz\n",
        "\n",
        "    def __init__(self, dataset, device=DEVICE):\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
        "        # assert sample_rate == 16000\n",
        "        # audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
        "        # mel = whisper.log_mel_spectrogram(audio)\n",
        "        audio = self.dataset[item]['audio']\n",
        "        sentence = self.dataset[item]['sentence']\n",
        "        path = audio['path']\n",
        "        original_sample_rate = 48000  # 48kHz\n",
        "        target_sample_rate = 16000    # 16kHz\n",
        "        resample_audio(path, path, original_sample_rate, target_sample_rate)\n",
        "        array = audio['array']\n",
        "        sampling_rate = audio['sampling_rate']\n",
        "        audio = whisper.load_audio(path)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "        return (mel, sentence)\n",
        "\n",
        "dataset = customDataset(split_test_datasets[\"finetune\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "comYI3DN-Ff_"
      },
      "outputs": [],
      "source": [
        "def decode_baseline(model, mel, beam_size):\n",
        "  \"\"\"\n",
        "    This function performs the transcription with Whisper to provide a baseline without LM fusion\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n",
        "\n",
        "def decode_deep_fusion(model, mel, beam_size, lm_path, lm_alpha):\n",
        "  \"\"\"\n",
        "    This function performs the deep fusion of the LM with Whisper during the beam search decoding step\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_alpha: A numerical value representing the weight assigned to the language model scores during deep fusion.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=beam_size,\n",
        "        patience=1.0, lm_path=lm_path, lm_alpha=lm_alpha, lm_beta=0.0,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n",
        "\n",
        "def decode_shallow_fusion_beam_search(model, mel, beam_size, lm_path, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful for inspecting the outputs with different lm_weights for finding the optimal value for lm_weight\n",
        "\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "    nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "    combined_score = [(text, (whisper_score) + (lm_score*lm_weight), (whisper_score), (lm_score)) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "    combined_score.sort(key=lambda t: t[1], reverse=True)\n",
        "    combined_scores.append(combined_score)\n",
        "\n",
        "\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = []\n",
        "  for datapoint in combined_scores:\n",
        "    combined_score = datapoint[0]\n",
        "    hyp, comb_score, w_score, lm_score = combined_score\n",
        "    result.append(hyp)\n",
        "  # result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_shallow_fusion_nbest(model, mel, best_of, lm_path, temperature, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (greedy decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - best_of: An integer specifying the number of best hypotheses to consider during decoding.\n",
        "    - lm_path: A string representing the path to the language model used for fusion.\n",
        "    - temperature: A numerical value indicating the temperature parameter used during sampling. Higher temperature corresponds to more variation in the n best list\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful when finding the optimal value for the lm_weight\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, best_of=best_of, return_nbest=True, without_timestamps=True, temperature=temperature, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "        nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "        normalized_scores = [(text,\n",
        "                              whisper_score / len(text.split()),\n",
        "                              lm_model.score(text) / len(text.split()))\n",
        "                             for text, whisper_score, _ in nbest_with_lm_score]\n",
        "        combined_score = [(text,\n",
        "                           (whisper_score ** 2) + (lm_weight * lm_score ** 2),\n",
        "                           whisper_score,\n",
        "                           lm_score)\n",
        "                          for text, whisper_score, lm_score in normalized_scores]\n",
        "        combined_score.sort(key=lambda t: t[1], reverse=False)\n",
        "        combined_scores.append(combined_score)\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = []\n",
        "  for datapoint in combined_scores:\n",
        "    combined_score = datapoint[0]\n",
        "    hyp, comb_score, w_score, lm_score = combined_score\n",
        "    result.append(hyp)\n",
        "  # result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result"
      ],
      "metadata": {
        "id": "CklLtkFkD8dE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hypotheses = []\n",
        "# references = []\n",
        "\n",
        "# lm_path = '/content/language_model_3p0.bin'\n",
        "# # # decoding parameters you can try playing around with to reach the optimal WER\n",
        "# beam_size = 20\n",
        "# lm_weight = 0.1\n",
        "# whisper_results_with_shallow_fusion_beam_search = {}\n",
        "\n",
        "# # audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# # audio = whisper.pad_or_trim(audio)\n",
        "# # mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # # decode_baseline decode_shallow_fusion_beam_search\n",
        "# # result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# # result\n",
        "\n",
        "# global audio_files\n",
        "# # Transcribe each audio file\n",
        "# for audio_file in audio_files:\n",
        "#     audio = whisper.load_audio(audio_file)\n",
        "#     audio = whisper.pad_or_trim(audio)\n",
        "#     mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "#     result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight,debug=True)\n",
        "#     whisper_results_with_shallow_fusion_beam_search[audio_file] = result\n",
        "\n",
        "# # Print the results\n",
        "# for audio_file, transcription in whisper_results_with_shallow_fusion_beam_search.items():\n",
        "#     print(f\"{audio_file}: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9HcFZh9vURd",
        "outputId": "a2e50884-85f7-4987-963d-c2d9a0be8eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('पूजा में', -1.1214643695137718, -0.43847634575583716, -6.829880237579346), ('उगेउगे सूरज छठ पूजा में', -2.1856764639577557, -0.16355369937035344, -20.221227645874023), ('उगे सूरज छठ पूजा में', -2.1871442061204176, -0.2553261976975661, -19.318180084228516), ('उगेुगे सूरज छठ पूजा में', -2.2670618764815793, -0.24493911189417686, -20.221227645874023), ('उगे�गे सूरज छठ पूजा में', -2.277782917022705, -0.2556601524353027, -20.221227645874023), ('उगे उगे सूरज छठ पूजा में', -2.5255433553649533, -0.007628011126672068, -25.179153442382812), ('उगे होगे सूरज छठ पूजा में', -2.6245084639518494, -0.22054613790204447, -24.039623260498047), ('ओगे उगे सूरज छठ पूजा में', -2.7583050143334176, -0.20635970946281187, -25.519453048706055), ('ओगे ओगे सूरज छठ पूजा में', -2.7975419444422567, -0.21156667893932712, -25.859752655029297), ('ऊगे ऊगे सूरज छठ पूजा में', -2.8386132917096543, -0.14008843514227098, -26.985248565673828)]]\n",
            "[[('हमारा नाम चंदन कुमार सिंघ्यार्म', -2.3871874144583036, -0.29216959982207324, -20.950178146362305), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट', -3.479957655856484, -0.0731335439180073, -34.068241119384766), ('हमारा नाम चंदन कुमार सिंह और हम राज्य से झारखंड स्टेट याम', -3.6335639357566833, -0.06302484273910522, -35.70539093017578), ('हमारा नाम चंदन कुमार सिंह और हम रांची से झारखंड स्टेट याम', -3.7821863174438475, -0.06424694061279297, -37.17939376831055), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम', -4.0825059617151975, -0.019522639571643265, -40.62983322143555), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट हैम', -4.117163666089375, -0.05236645539601644, -40.647972106933594), ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट याम', -4.144051449416114, -0.049279873488379304, -40.947715759277344), ('हमारा नाम चन्दन कुमार सिंह और हम राँची से झारखंड स्टेट हैम', -4.168357498919378, -0.06565287855804944, -41.02704620361328), ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट हैम', -4.181334042549134, -0.08474857807159424, -40.96585464477539), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट हाम', -4.2260877688725795, -0.09329472382863363, -41.32793045043945)]]\n",
            "[[('आज सुबह में हम थ्रा लेट से उठे हैं कल रात में लेट से सोयें', -4.878691261693051, -0.09045731393914473, -47.88233947753906), ('आज सुबह में हम थ्रा लेट से उठे हैं कल रात में लेट से सोये के', -4.883792477640613, -0.08440321067283893, -47.993892669677734), ('आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -5.1579641602256086, -0.052941729805686254, -51.05022430419922), ('आज सुबह में हम थ्रा लेट से उठें कर रात में लेट से सोयें', -5.295863515680487, -0.07515390569513494, -52.207096099853516), ('आज सुबह में हम थ्रा लेड से उठे हैं कल रात में लेड से सोयें', -5.406194163205331, -0.09106240356177614, -53.15131759643555), ('आज सुबह में हम थ्रा लेड से उठें कल रात में लेड से सोयें', -5.5346216028386905, -0.05152109319513494, -54.83100509643555), ('आज सुबह में हम थ्रा लेड से उठें कर रात में लेड से सोयें', -5.671910996870562, -0.07312292619185014, -55.98788070678711), ('हान आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -5.8230027659186, -0.07030386760317046, -57.5269889831543), ('हान आज सुबह में हम थ्रा लेड से उठें कल रात में लेड से सोयें', -6.197540431187071, -0.06676307217828159, -61.30777359008789), ('हान आज सुबह में हम थ्रा लेड से उठें कर रात में लेड से सोयें', -6.3353356673799714, -0.0888707473360259, -62.46464920043945)]]\n",
            "[[('भारत की वर्ड कप में हाथ से सारे भाग के बहुत ही दुःखित है', -4.217500662385372, -0.05566365677013732, -41.618370056152344), ('भारत की वर्ड कप में हार से सारे भाग के बहुत ही दुःखित है', -4.3780266250882836, -0.05062336581093924, -43.27403259277344), ('भारत की वर्डकप में हाथ से सारे भाग के बहुत ही दुःखित है', -4.411942392483092, -0.048568445339537504, -43.63373947143555), ('भारत की वर्ड कप में हार से सारे भाग के बहुत ही दुःखित हैं', -4.564751136512087, -0.20808800479821993, -43.56663131713867), ('भारत की वर्डकप में हार से सारे भाग के बहुत ही दुःखित है', -4.57140263744763, -0.042462055172239034, -45.289405822753906), ('भारत की वर्चअप में हार से सारे भाग के बहुत ही दुःखित है', -4.585530017551623, -0.05799171799107602, -45.27538299560547), ('भारत की वर्ड कप में हाज से सारे भाग के बहुत ही दुःखित है', -4.6186219165199685, -0.07521905397114001, -45.43402862548828), ('भारत की वर्डकप में हार से सारे भाग के बहुत ही दुःखित हैं', -4.763929671571966, -0.20572921686005174, -45.58200454711914), ('भारत की वर्डकप में हाज से सारे भाग के बहुत ही दुःखित है', -4.81731051394814, -0.0723703284012644, -47.44940185546875), ('भारत की वर्ट कप में हार से सारे भाग के बहुत ही दुःखित है', -4.9571540730340145, -0.08698233536311559, -48.701717376708984)]]\n",
            "[[('बिहार की', -0.8281438430150351, -0.1734227736790975, -6.547210693359375), ('बिहार की है', -1.661565620248968, -0.9374334161931818, -7.241322040557861), ('बिहार में', -1.7137202739715578, -1.2038267135620118, -5.098935604095459), ('बिहार के', -1.7805942058563233, -1.181722640991211, -5.988715648651123), ('बिहार से', -1.9424013137817382, -1.3323497772216797, -6.100515365600586), ('बिहार', -1.9642270496913365, -1.419480460030692, -5.447465896606445), ('बिस्तर', -2.2464224338531493, -1.6120414733886719, -6.343809604644775), ('बिधार की', -2.412798023223877, -1.189061737060547, -12.2373628616333), ('बिआर की', -2.528901047176785, -1.305164761013455, -12.2373628616333), ('की', -5.1751391887664795, -4.767616271972656, -4.075229167938232)]]\n",
            "/content/audio_1_1.wav: ['पूजा में']\n",
            "/content/audio_2_2.wav: ['हमारा नाम चंदन कुमार सिंघ्यार्म']\n",
            "/content/audio_3_3.wav: ['आज सुबह में हम थ्रा लेट से उठे हैं कल रात में लेट से सोयें']\n",
            "/content/audio_4_4.wav: ['भारत की वर्ड कप में हाथ से सारे भाग के बहुत ही दुःखित है']\n",
            "/content/audio_5_5.wav: ['बिहार की']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "best_of = 30\n",
        "temperature = 0.5\n",
        "lm_weight = .5\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "\n",
        "\n",
        "whisper_results_with_shallow_fusion_greedy_decoding = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # decode_baseline decode_shallow_fusion_beam_search\n",
        "# result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# result\n",
        "\n",
        "global audio_files\n",
        "# Transcribe each audio file\n",
        "for audio_file in audio_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=True)\n",
        "    whisper_results_with_shallow_fusion_greedy_decoding[audio_file] = result\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in whisper_results_with_shallow_fusion_greedy_decoding.items():\n",
        "    print(f\"{audio_file}: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkor9lKhwOXS",
        "outputId": "6e452fda-7de8-4304-e7e7-38407eaeefcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('उगे हुए सूरज छठ्ठ पूजा में', 9.68460177376984, -0.010432457222658046, -4.4010210037231445), ('उगे हुए सूरज छठ्ठ पूजा में', 9.684601773842996, -0.01043246072881362, -4.4010210037231445), ('उगे हुए सूरज छठ्ठ पूजा में', 9.684601773842996, -0.01043246072881362, -4.4010210037231445), ('उगे हुए सूरज छठ्ठ पूजा में', 9.684601773842996, -0.01043246072881362, -4.4010210037231445), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.538965508436862, -0.008155901091439382, -5.574746449788411), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.5389655084739, -0.008155903362092518, -5.574746449788411), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.5389655084739, -0.008155903362092518, -5.574746449788411), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.538965508649833, -0.008155914147694905, -5.574746449788411), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.538965508649833, -0.008155914147694905, -5.574746449788411), ('ऊगे हुगे सूरज छठ्ठ पूजा में', 15.538965508649833, -0.008155914147694905, -5.574746449788411)]]\n",
            "[[('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामारा', 6.551850140015205, -0.0036112150224317024, -3.6198997497558594), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामार', 6.634307836847172, -0.004460179729502338, -3.642605645315988), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामा', 6.637946057271309, -0.0031717262226781803, -3.6436070033482144), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामा', 6.637946057274583, -0.0031717267387357108, -3.6436070033482144), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामा', 6.637946057279493, -0.0031717275128220067, -3.6436070033482144), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेडियाम आए', 6.837448076422383, -0.005714460781642368, -3.697949545724051), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेडियाम है।', 7.912308174661193, -0.0038534200921350598, -3.978012902396066), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेडियाम है।', 7.912308174676193, -0.0038534220384091747, -3.978012902396066), ('हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेडियाम हैं!', 7.912308280566705, -0.0038671374320983884, -3.978012902396066), ('हमारनाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामार', 8.544397997275041, -0.005132153189393895, -4.133853325477014)]]\n",
            "[[('आज सुबह में हम थ्रा लेट से उठें, दर्दात में लेट से सोएं के', 7.62861140003162, -0.006034122762225923, -3.9060401916503906), ('आज सुबह में हम थरा लेट से उठें, दलराज में लेट से सोएं के', 7.632545655162424, -0.0075996779455927204, -3.9070418221609935), ('आज सुबह में हम थरे लीड से उठें, दरात में लीड से सोएं के', 8.394235577095085, -0.004725309963129005, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दरात में लीड से सोएं के', 8.394235577095085, -0.004725309963129005, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दरात में लीड से सोएं के', 8.394235577097959, -0.004725310267234335, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दिराद में लीड से सोएं के', 8.394240320493727, -0.005203071486186511, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दर्रात में लीड से सोएं के', 8.394253421066452, -0.006338179992337532, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दराव में लीड से सोएं के', 8.394256707661352, -0.006592353185017904, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दराव में लीड से सोएं के', 8.394256707661352, -0.006592353185017904, -4.097368240356445), ('आज सुबह में हम थरे लीड से उठें, दराव में लीड से सोएं के', 8.394256707661352, -0.006592353185017904, -4.097368240356445)]]\n",
            "[[('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखी थै।', 4.458044065674215, -0.002920954914416297, -2.9859790802001953), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखी थे।', 4.458049862281593, -0.003785311742787211, -2.9859790802001953), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237152183, -0.0005327625872147862, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237152183, -0.0005327625872147862, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.3407072371522215, -0.0005327626232950797, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.3407072371522215, -0.0005327626232950797, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237152799, -0.0005327631644994814, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237152799, -0.0005327631644994814, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237153875, -0.000532764174747698, -3.2682432447160994), ('भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है।', 5.340707237153875, -0.000532764174747698, -3.2682432447160994)]]\n",
            "[[('बिहार की स्थिति थोड़ी अच्छी नहीं है।', 5.8586906916348696, -0.005401413615156965, -3.4230575561523438), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858231602, -0.0009170111750258881, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858231602, -0.0009170111750258881, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858233275, -0.0009170120873418795, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858233275, -0.0009170120873418795, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.83657485823402, -0.0009170124928156536, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.83657485823402, -0.0009170124928156536, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.83657485823402, -0.0009170124928156536, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858234762, -0.0009170128982894275, -4.203944342476981), ('बिहार की स्थिति थोड़ी अच्छीन नहीं है।', 8.836574858234762, -0.0009170128982894275, -4.203944342476981)]]\n",
            "/content/audio_1_1.wav: ['उगे हुए सूरज छठ्ठ पूजा में']\n",
            "/content/audio_2_2.wav: ['हमारा नाम चंदन कुमार सिंह है, और हम रांची से हैं झारखंड स्टेट हामारा']\n",
            "/content/audio_3_3.wav: ['आज सुबह में हम थ्रा लेट से उठें, दर्दात में लेट से सोएं के']\n",
            "/content/audio_4_4.wav: ['भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखी थै।']\n",
            "/content/audio_5_5.wav: ['बिहार की स्थिति थोड़ी अच्छी नहीं है।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoding with Default whisper **"
      ],
      "metadata": {
        "id": "J6NqXssrHIOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model_orignal_whisper = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "2yTC3rutHwe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "best_of = 10\n",
        "temperature = 0.3\n",
        "lm_weight = 0.01\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_shallow_fusion_nbest(model_orignal_whisper, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "\n",
        "shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "#shallow_fusion_nbest_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hYkPWzmH1d3",
        "outputId": "4c744da6-25c4-4ac7-a710-62084d97337b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:11<00:00,  6.46s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import jiwer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to calculate WER and CER\n",
        "def compute_metrics(model, loader, beam_size, lm_weight, lm_path):\n",
        "    hypotheses = []\n",
        "    references = []\n",
        "\n",
        "    for mel, text in tqdm(loader):\n",
        "        result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight)\n",
        "        hypotheses.extend(result)\n",
        "        references.extend(text)\n",
        "\n",
        "    extra_chars = '‘’“”।'\n",
        "    reference = [text.translate(str.maketrans('', '', string.punctuation + extra_chars)) for text in references]\n",
        "    hypo = [text.translate(str.maketrans('', '', string.punctuation + extra_chars)) for text in hypotheses]\n",
        "\n",
        "    wer = jiwer.wer(reference, hypo)\n",
        "    cer = jiwer.cer(reference, hypo)\n",
        "    return wer, cer\n",
        "\n",
        "# Tuning parameters\n",
        "beam_sizes = [5, 10, 15, 20]\n",
        "lm_weights = [0.01, 0.05, 0.1, 0.15,0.2,0.3,0.4,0.5]\n",
        "\n",
        "best_wer = float('inf')\n",
        "best_params = {'beam_size': None, 'lm_weight': None}\n",
        "\n",
        "for beam_size in beam_sizes:\n",
        "    for lm_weight in lm_weights:\n",
        "        wer, cer = compute_metrics(model_orignal_whisper, loader, beam_size, lm_weight, lm_path)\n",
        "        print(f\"Beam size: {beam_size}, LM Weight: {lm_weight}, WER: {wer * 100:.2f} %, CER: {cer * 100:.2f} %\")\n",
        "\n",
        "        if wer < best_wer:\n",
        "            best_wer = wer\n",
        "            best_params['beam_size'] = beam_size\n",
        "            best_params['lm_weight'] = lm_weight\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"Best WER: {best_wer * 100:.2f} % with Beam Size: {best_params['beam_size']} and LM Weight: {best_params['lm_weight']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "habDRn3NI2YU",
        "outputId": "54167cf8-3519-43d4-c892-72c7b842cc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:37<00:00,  3.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.01, WER: 87.06 %, CER: 60.38 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:35<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.05, WER: 99.65 %, CER: 78.47 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:34<00:00,  3.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.1, WER: 90.91 %, CER: 65.59 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:36<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.15, WER: 89.16 %, CER: 67.42 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:34<00:00,  3.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.2, WER: 89.86 %, CER: 63.41 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:32<00:00,  2.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.3, WER: 90.21 %, CER: 66.36 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:32<00:00,  2.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.4, WER: 90.91 %, CER: 65.66 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:31<00:00,  2.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 5, LM Weight: 0.5, WER: 86.01 %, CER: 62.77 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:55<00:00,  5.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.01, WER: 82.52 %, CER: 58.62 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:52<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.05, WER: 82.17 %, CER: 59.47 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:53<00:00,  4.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.1, WER: 84.27 %, CER: 58.90 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:57<00:00,  5.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.15, WER: 82.52 %, CER: 58.90 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:58<00:00,  5.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.2, WER: 84.97 %, CER: 60.94 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:54<00:00,  5.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.3, WER: 81.82 %, CER: 57.85 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:59<00:00,  5.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.4, WER: 81.12 %, CER: 55.17 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:54<00:00,  4.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 10, LM Weight: 0.5, WER: 84.97 %, CER: 60.03 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:21<00:00,  7.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.01, WER: 84.97 %, CER: 63.27 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:24<00:00,  7.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.05, WER: 86.71 %, CER: 63.48 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:19<00:00,  7.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.1, WER: 85.66 %, CER: 64.18 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:16<00:00,  6.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.15, WER: 87.41 %, CER: 65.45 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:10<00:00,  6.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.2, WER: 86.36 %, CER: 67.21 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:25<00:00,  7.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.3, WER: 87.76 %, CER: 67.21 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:13<00:00,  6.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.4, WER: 86.01 %, CER: 66.71 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:14<00:00,  6.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 15, LM Weight: 0.5, WER: 86.01 %, CER: 66.85 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:41<00:00,  9.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.01, WER: 88.46 %, CER: 72.48 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:41<00:00,  9.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.05, WER: 87.06 %, CER: 67.35 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:41<00:00,  9.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.1, WER: 89.16 %, CER: 72.41 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:40<00:00,  9.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.15, WER: 86.71 %, CER: 68.12 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:41<00:00,  9.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.2, WER: 86.36 %, CER: 68.33 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:46<00:00,  9.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.3, WER: 87.06 %, CER: 70.16 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:43<00:00,  9.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.4, WER: 87.76 %, CER: 73.33 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:46<00:00,  9.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Weight: 0.5, WER: 89.16 %, CER: 72.27 %\n",
            "Best WER: 81.12 % with Beam Size: 10 and LM Weight: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZAPa4grISQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZMfw_kPIVXh",
        "outputId": "3b9e4d99-58e8-4ada-b714-a97d30518434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 159.79 %\n",
            "CER: 100.28 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzkjrcWnZTIE"
      },
      "source": [
        "# Decoding without LM as a baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pP3luWRsuxxh",
        "outputId": "769dc26e-0533-4c44-d889-6e717fe48f1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:53<00:00,  1.72s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-85404d11-34ab-4f89-bd35-bbafd89242b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हरियाणा मनोहरलाल खट्टर की कैबिनेट में गोपाल का...</td>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...</td>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...</td>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...</td>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मध्य प्रदेश चलती ट्रेन में युगती से रेप</td>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...</td>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>टॉम ने तो दरवाजा बंद तट नहीं किया</td>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>चैनल चार लगाइए</td>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद</td>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार</td>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>फोन पर पिता से इटली बात करते करते बेटे ने दे द...</td>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान</td>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि</td>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...</td>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>मुझे लगा मै यहाँ अकेला हूँ</td>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>दिनों केहिं जाल में फँसते भुजबल</td>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...</td>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>अपने बच्चों के लिए सम्पत्ति नहीं छोड़ेंगे बिल ...</td>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...</td>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>भखवान के भरोसे धार्मिक भीड</td>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके</td>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>मोदी युग में पीजेपी का प्रवेश</td>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय</td>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर</td>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>राजियाबाद लड़की की मिली लाश रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>दिल्ली येप के माह ने कार लोट की कोशिश डाइवर कु...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85404d11-34ab-4f89-bd35-bbafd89242b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85404d11-34ab-4f89-bd35-bbafd89242b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85404d11-34ab-4f89-bd35-bbafd89242b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3364cb88-9db3-4196-b645-10a1928163b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3364cb88-9db3-4196-b645-10a1928163b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3364cb88-9db3-4196-b645-10a1928163b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8c99f2c2-a016-4ea0-a3eb-874036eb0a89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('baseline_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c99f2c2-a016-4ea0-a3eb-874036eb0a89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('baseline_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   हरियाणा मनोहरलाल खट्टर की कैबिनेट में गोपाल का...   \n",
              "1   कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...   \n",
              "2   क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...   \n",
              "3   इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...   \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...   \n",
              "5             मध्य प्रदेश चलती ट्रेन में युगती से रेप   \n",
              "6   दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...   \n",
              "7                   टॉम ने तो दरवाजा बंद तट नहीं किया   \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...   \n",
              "9                                      चैनल चार लगाइए   \n",
              "10    आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद   \n",
              "11  घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार   \n",
              "12  फोन पर पिता से इटली बात करते करते बेटे ने दे द...   \n",
              "13     तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान   \n",
              "14                   कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि   \n",
              "15  मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...   \n",
              "16                         मुझे लगा मै यहाँ अकेला हूँ   \n",
              "17                    दिनों केहिं जाल में फँसते भुजबल   \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...   \n",
              "19  अपने बच्चों के लिए सम्पत्ति नहीं छोड़ेंगे बिल ...   \n",
              "20  कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...   \n",
              "21                         भखवान के भरोसे धार्मिक भीड   \n",
              "22      कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके   \n",
              "23                      मोदी युग में पीजेपी का प्रवेश   \n",
              "24     तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय   \n",
              "25     जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर   \n",
              "26           राजियाबाद लड़की की मिली लाश रेप की आशंका   \n",
              "27    जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया   \n",
              "28  दिल्ली येप के माह ने कार लोट की कोशिश डाइवर कु...   \n",
              "29  डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...   \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                            reference  \n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...  \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...  \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...  \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...  \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...  \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप  \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...  \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।  \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...  \n",
              "9                                    चैनल चार लगाइये।  \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी  \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल  \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान  \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...  \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे  \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...  \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।  \n",
              "17                    अपनों के ही जाल में फंसते भुजबल  \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...  \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...  \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...  \n",
              "21                        भगवान के भरोसे धार्मिक भीड़  \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके  \n",
              "23                      मोदी युग में बीजेपी का प्रवेश  \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय  \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...  \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 5\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_baseline(model, mel, beam_size)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "baseline_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "baseline_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVpt-nocar5T",
        "outputId": "bc5037d5-5df4-475d-effe-e6adb0c12e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WER: 37.59 %\n",
            "CER: 10.83 %\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wer = jiwer.wer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DrvdKNZZfV"
      },
      "source": [
        "# Decoding with LM deep fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "dEfO8QAbbdKO",
        "outputId": "422cf661-6683-4d1e-c49e-8b87e104ae5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:03<00:00, 81.6MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HisMIkZzYJjJ",
        "outputId": "7f80ab94-186d-4560-cdfb-9db2428de649"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [23:30<00:00, 45.51s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5e63133-994e-40ff-9a30-b234f87c1ea6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हरियाणा मनोहर लाल खट्टर की कैबिनेट में गोपाल क...</td>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...</td>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...</td>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...</td>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मध्य प्रदेश चलती ट्रेन में युगती से रेप</td>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...</td>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>टॉम ने तो दरवाजा बंद तट नहीं किया</td>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>चैनल चार लगाइए</td>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद</td>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार</td>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>फोन पर पिता से इटली बात करते करते बेटे ने दे द...</td>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान</td>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि</td>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...</td>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>मुझे लगा मैं यहाँ केला हूँ</td>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>दिनों केहिं जाल में फँसते भुजबल</td>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...</td>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...</td>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>भखवान के भरोसे धार्मिक भीड</td>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके</td>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>मोदी युग में पीजेपी का प्रवेश</td>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय</td>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर</td>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>राजियाबाद लड़की की मिली लाश रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>दिल्ली येप के माह ने कार लोट की कोशिश डायवर कु...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5e63133-994e-40ff-9a30-b234f87c1ea6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5e63133-994e-40ff-9a30-b234f87c1ea6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5e63133-994e-40ff-9a30-b234f87c1ea6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11c7d983-865e-40ab-892e-8297397bc99c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11c7d983-865e-40ab-892e-8297397bc99c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11c7d983-865e-40ab-892e-8297397bc99c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   हरियाणा मनोहर लाल खट्टर की कैबिनेट में गोपाल क...   \n",
              "1   कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...   \n",
              "2   क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...   \n",
              "3   इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...   \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...   \n",
              "5             मध्य प्रदेश चलती ट्रेन में युगती से रेप   \n",
              "6   दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...   \n",
              "7                   टॉम ने तो दरवाजा बंद तट नहीं किया   \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...   \n",
              "9                                      चैनल चार लगाइए   \n",
              "10    आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद   \n",
              "11  घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार   \n",
              "12  फोन पर पिता से इटली बात करते करते बेटे ने दे द...   \n",
              "13     तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान   \n",
              "14                   कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि   \n",
              "15  मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...   \n",
              "16                         मुझे लगा मैं यहाँ केला हूँ   \n",
              "17                    दिनों केहिं जाल में फँसते भुजबल   \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...   \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...   \n",
              "20  कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...   \n",
              "21                         भखवान के भरोसे धार्मिक भीड   \n",
              "22      कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके   \n",
              "23                      मोदी युग में पीजेपी का प्रवेश   \n",
              "24     तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय   \n",
              "25     जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर   \n",
              "26           राजियाबाद लड़की की मिली लाश रेप की आशंका   \n",
              "27    जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया   \n",
              "28  दिल्ली येप के माह ने कार लोट की कोशिश डायवर कु...   \n",
              "29  डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...   \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                            reference  \n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...  \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...  \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...  \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...  \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...  \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप  \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...  \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।  \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...  \n",
              "9                                    चैनल चार लगाइये।  \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी  \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल  \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान  \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...  \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे  \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...  \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।  \n",
              "17                    अपनों के ही जाल में फंसते भुजबल  \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...  \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...  \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...  \n",
              "21                        भगवान के भरोसे धार्मिक भीड़  \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके  \n",
              "23                      मोदी युग में बीजेपी का प्रवेश  \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय  \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...  \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_alpha = 0.2\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    # result = decode_baseline(model, mel, beam_size)\n",
        "    result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "deep_fusion_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "deep_fusion_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0DWNREhg6ol"
      },
      "source": [
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 15\n",
        "lm_alpha = 0.5\n",
        "\n",
        "WER: 37.24 %\n",
        "CER: 10.83 %\n",
        "\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 15\n",
        "lm_alpha = 1.5\n",
        "\n",
        "WER: 37.24 %\n",
        "CER: 10.83 %\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpu45C9BblyC",
        "outputId": "e3ebfdf2-d6c4-4fcc-bd58-78b7d87f3ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WER: 36.55 %\n",
            "CER: 10.76 %\n"
          ]
        }
      ],
      "source": [
        "wer = jiwer.wer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8jjEY_BZc0X"
      },
      "source": [
        "# Decoding with shallow fusion (Beam Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "V3FQ3GHMIq9h",
        "outputId": "899d9567-0d77-4722-c189-a94995716b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 199MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'language_model_3p0.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQvvnm2IYfK_",
        "outputId": "410b163a-07d7-427e-c536-d27a6acb0a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [01:55<00:00,  3.72s/it]\n"
          ]
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.05\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "    #exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lOP4glqbuEO",
        "outputId": "8e411809-2f8b-487f-f5e0-3bf434f4de3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 39.31 %\n",
            "CER: 23.23 %\n"
          ]
        }
      ],
      "source": [
        "import jiwer\n",
        "\n",
        "shallow_fusion_beam_search_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "wer = jiwer.wer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20hHgyUZjJk"
      },
      "source": [
        "# Decoding with shallow fusion (Best of N hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after tuning\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import jiwer\n",
        "\n",
        "# Function to calculate WER and CER\n",
        "def compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path):\n",
        "    hypotheses = []\n",
        "    references = []\n",
        "\n",
        "    for mel, text in tqdm(loader):\n",
        "        result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "        hypotheses.extend(result)\n",
        "        references.extend(text)\n",
        "\n",
        "    shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "\n",
        "    wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "    cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "    return wer, cer\n",
        "\n",
        "# Tuning parameters\n",
        "best_of_values = [5]\n",
        "temperature_values = [0.1,0.25,0.5,0.75,0.9]\n",
        "lm_weights = [0.1,0.25,0.5,0.75,0.9]\n",
        "\n",
        "best_wer = float('inf')\n",
        "best_params = {'best_of': None, 'temperature': None, 'lm_weight': None}\n",
        "\n",
        "for best_of in best_of_values:\n",
        "    for temperature in temperature_values:\n",
        "        for lm_weight in lm_weights:\n",
        "            wer, cer = compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path)\n",
        "            print(f\"Best of: {best_of}, Temperature: {temperature}, LM Weight: {lm_weight}, WER: {wer * 100:.2f} %, CER: {cer * 100:.2f} %\")\n",
        "\n",
        "            if wer < best_wer:\n",
        "                best_wer = wer\n",
        "                best_params['best_of'] = best_of\n",
        "                best_params['temperature'] = temperature\n",
        "                best_params['lm_weight'] = lm_weight\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"Best WER: {best_wer * 100:.2f} % with Best Of: {best_params['best_of']}, Temperature: {best_params['temperature']} and LM Weight: {best_params['lm_weight']}\")\n"
      ],
      "metadata": {
        "id": "wQvigSWQcux2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca5d8a4-dd0e-45fd-ce71-fedc76270cd9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.1, WER: 15.43 %, CER: 8.12 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.25, WER: 15.95 %, CER: 8.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.5, WER: 16.34 %, CER: 9.05 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.75, WER: 15.95 %, CER: 8.86 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.9, WER: 15.30 %, CER: 8.57 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.1, WER: 15.43 %, CER: 8.65 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.25, WER: 15.30 %, CER: 8.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.5, WER: 15.82 %, CER: 8.62 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.75, WER: 16.21 %, CER: 8.99 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.9, WER: 16.73 %, CER: 9.26 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.1, WER: 16.47 %, CER: 9.78 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.25, WER: 16.34 %, CER: 9.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.5, WER: 17.38 %, CER: 10.15 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.75, WER: 18.81 %, CER: 10.55 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.9, WER: 18.16 %, CER: 10.94 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.1, WER: 17.77 %, CER: 10.31 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.25, WER: 18.42 %, CER: 10.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.5, WER: 19.33 %, CER: 10.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.75, WER: 19.84 %, CER: 10.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.9, WER: 20.62 %, CER: 11.60 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.1, WER: 21.40 %, CER: 11.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.25, WER: 19.46 %, CER: 11.02 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.5, WER: 20.62 %, CER: 12.37 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.75, WER: 19.84 %, CER: 11.66 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.9, WER: 20.49 %, CER: 11.34 %\n",
            "Best WER: 15.30 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best WER: 23.45 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.1\n",
        "Best WER: 15.30 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.9\n",
        "**bold text****bold text**"
      ],
      "metadata": {
        "id": "Gvk9SpZTE6v4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vvti3DsAYSXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from tqdm import tqdm\n",
        "# import jiwer\n",
        "\n",
        "# # Function to calculate WER and CER\n",
        "# def compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path):\n",
        "#     hypotheses = []\n",
        "#     references = []\n",
        "\n",
        "#     for mel, text in tqdm(loader):\n",
        "#         result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "#         hypotheses.extend(result)\n",
        "#         references.extend(text)\n",
        "\n",
        "#     shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "\n",
        "#     wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "#     cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "#     return wer, cer\n",
        "\n",
        "# # Tuning parameters\n",
        "# best_of_values = [5, 10, 15]\n",
        "# temperature_values = [0.2, 0.3, 0.4]\n",
        "# lm_weights = [0.01, 0.05, 0.1,0.2,0.3,0.4,0.5]\n",
        "\n",
        "# best_wer = float('inf')\n",
        "# best_params = {'best_of': None, 'temperature': None, 'lm_weight': None}\n",
        "\n",
        "# for best_of in best_of_values:\n",
        "#     for temperature in temperature_values:\n",
        "#         for lm_weight in lm_weights:\n",
        "#             wer, cer = compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path)\n",
        "#             print(f\"Best of: {best_of}, Temperature: {temperature}, LM Weight: {lm_weight}, WER: {wer * 100:.2f} %, CER: {cer * 100:.2f} %\")\n",
        "\n",
        "#             if wer < best_wer:\n",
        "#                 best_wer = wer\n",
        "#                 best_params['best_of'] = best_of\n",
        "#                 best_params['temperature'] = temperature\n",
        "#                 best_params['lm_weight'] = lm_weight\n",
        "\n",
        "# # Print the best parameters\n",
        "# print(f\"Best WER: {best_wer * 100:.2f} % with Best Of: {best_params['best_of']}, Temperature: {best_params['temperature']} and LM Weight: {best_params['lm_weight']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNEYrVOlcvk3",
        "outputId": "bb6acb1a-dde2-4596-a0e6-3ccd61229c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:30<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.01, WER: 35.63 %, CER: 18.61 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:31<00:00,  2.64s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.05, WER: 36.18 %, CER: 19.26 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.1, WER: 36.07 %, CER: 19.21 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.2, WER: 36.91 %, CER: 18.99 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.3, WER: 36.18 %, CER: 19.22 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.4, WER: 36.51 %, CER: 19.34 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.2, LM Weight: 0.5, WER: 36.80 %, CER: 19.37 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:30<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.01, WER: 36.40 %, CER: 19.64 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:31<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.05, WER: 37.06 %, CER: 19.89 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.1, WER: 36.99 %, CER: 19.51 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:31<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.2, WER: 37.98 %, CER: 20.83 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.3, WER: 37.17 %, CER: 20.24 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:30<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.4, WER: 37.54 %, CER: 20.59 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:29<00:00,  2.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.3, LM Weight: 0.5, WER: 38.01 %, CER: 20.35 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:31<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.01, WER: 39.52 %, CER: 21.70 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:30<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.05, WER: 38.34 %, CER: 20.75 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:30<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.1, WER: 39.08 %, CER: 21.39 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:31<00:00,  2.64s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.2, WER: 38.45 %, CER: 20.85 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:32<00:00,  2.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.3, WER: 39.52 %, CER: 21.29 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:32<00:00,  2.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.4, WER: 39.59 %, CER: 21.56 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [04:33<00:00,  2.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 5, Temperature: 0.4, LM Weight: 0.5, WER: 39.11 %, CER: 21.16 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:53<00:00,  4.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.01, WER: 38.93 %, CER: 20.69 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:52<00:00,  4.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.05, WER: 39.48 %, CER: 21.75 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.1, WER: 39.52 %, CER: 21.53 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.2, WER: 39.30 %, CER: 21.49 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.3, WER: 39.44 %, CER: 21.63 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:52<00:00,  4.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.4, WER: 38.97 %, CER: 21.28 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.2, LM Weight: 0.5, WER: 39.88 %, CER: 22.03 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:55<00:00,  4.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.01, WER: 39.48 %, CER: 21.50 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:59<00:00,  4.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.05, WER: 39.26 %, CER: 21.39 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.1, WER: 38.89 %, CER: 21.05 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:55<00:00,  4.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.2, WER: 39.22 %, CER: 21.30 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:56<00:00,  4.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.3, WER: 39.52 %, CER: 21.75 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:55<00:00,  4.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.4, WER: 39.44 %, CER: 22.04 %\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [06:54<00:00,  4.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best of: 10, Temperature: 0.3, LM Weight: 0.5, WER: 39.15 %, CER: 21.79 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [06:56<00:00,  4.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.01, WER: 38.97 %, CER: 21.01 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [06:57<00:00,  4.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.05, WER: 38.60 %, CER: 20.55 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [07:00<00:00,  4.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.1, WER: 37.98 %, CER: 20.93 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [06:55<00:00,  4.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.2, WER: 39.30 %, CER: 21.58 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [06:57<00:00,  4.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.3, WER: 39.48 %, CER: 21.64 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [06:56<00:00,  4.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.4, WER: 39.04 %, CER: 21.05 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [07:01<00:00,  4.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 10, Temperature: 0.4, LM Weight: 0.5, WER: 39.19 %, CER: 21.92 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:24<00:00,  5.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.01, WER: 39.04 %, CER: 21.62 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:27<00:00,  5.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.05, WER: 38.97 %, CER: 21.62 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:25<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.1, WER: 39.74 %, CER: 21.88 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:28<00:00,  5.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.2, WER: 39.66 %, CER: 21.92 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:25<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.3, WER: 39.63 %, CER: 22.18 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:27<00:00,  5.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.4, WER: 39.04 %, CER: 21.14 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:25<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.2, LM Weight: 0.5, WER: 39.37 %, CER: 21.68 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:30<00:00,  5.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.01, WER: 39.11 %, CER: 21.34 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:31<00:00,  5.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.05, WER: 39.41 %, CER: 22.05 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:29<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.1, WER: 38.97 %, CER: 21.21 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:29<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.2, WER: 39.55 %, CER: 21.95 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:36<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.3, WER: 39.41 %, CER: 21.77 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:29<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.4, WER: 38.64 %, CER: 21.16 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:30<00:00,  5.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.3, LM Weight: 0.5, WER: 39.19 %, CER: 21.72 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:32<00:00,  5.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.01, WER: 38.97 %, CER: 21.75 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:33<00:00,  5.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.05, WER: 39.08 %, CER: 21.84 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:38<00:00,  5.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.1, WER: 39.85 %, CER: 22.05 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:32<00:00,  5.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.2, WER: 39.52 %, CER: 21.51 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:31<00:00,  5.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.3, WER: 38.67 %, CER: 20.81 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:36<00:00,  5.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.4, WER: 39.66 %, CER: 22.25 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [09:32<00:00,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 15, Temperature: 0.4, LM Weight: 0.5, WER: 38.67 %, CER: 21.42 %\n",
            "Best WER: 35.63 % with Best Of: 5, Temperature: 0.2 and LM Weight: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = customDataset(split_test_datasets[\"test\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "fHGsv2Nort6Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "#best_of = 10\n",
        "#temperature = 0.3\n",
        "#lm_weight = 0.01\n",
        "#WER: 24.31 % , CER: 10.69 %\n",
        "\n",
        "#best_of = 30 temperature = 0.5 lm_weight = .5 WER: 20.00 % CER: 6.89 %\n",
        "#Best WER: 23.45 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.1\n",
        "best_of = 5\n",
        "temperature = 0.1\n",
        "lm_weight = 0.9\n",
        "\n",
        "#Best Of: 5, Temperature: 0.2 and LM Weight: 0.01\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    hypotheses.extend(decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False))\n",
        "    references.extend(text)\n",
        "\n",
        "\n",
        "shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "#shallow_fusion_nbest_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KV7bMFSRDAlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc985bf-75a2-4d01-c694-c9ab89188f41"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [06:15<00:00,  1.39s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "STboVmzyilu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437cdde1-cedc-41a8-f7c5-adb60d248536"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 7.03 %\n",
            "CER: 3.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "graminVoice : WER: 30.07 %\n",
        "CER: 14.57 %"
      ],
      "metadata": {
        "id": "wwYAKwAUbFV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IIITB\n",
        "WER: 28.24 %\n",
        "CER: 18.93 %"
      ],
      "metadata": {
        "id": "oylUlXOjY1pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "firefox : WER: 30.69 %\n",
        "CER: 11.48 % with\n",
        "best_of = 5\n",
        "temperature = 0.9\n",
        "lm_weight = 0.75"
      ],
      "metadata": {
        "id": "KgOK1LfgXKOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "L81Lrd3iCycc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_chars = '‘’“”।'\n",
        "reference = [text.translate(str.maketrans('', '', string.punctuation + extra_chars)) for text in shallow_fusion_nbest_df[\"reference\"].to_list()]\n",
        "hypo = [text.translate(str.maketrans('', '', string.punctuation + extra_chars)) for text in shallow_fusion_nbest_df[\"hypothesis\"].to_list()]"
      ],
      "metadata": {
        "id": "q_K3wbY9J0T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-eJUWX5wKysM",
        "outputId": "2ca062b8-16a3-4648-c6db-912197617007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'भारतवर्ष के उत्तरी राज्य उत्तर प्रदेश का एक नगर है'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypo[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XOz8Lr1sK5hx",
        "outputId": "19f96166-ff9a-4081-e4af-41b4020a0491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'भारत वर्ष के उत्तरी राज्य उत्तर प्रदेश का एक नगर है'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBnxUSwUbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a8ca6a-0fde-4405-e569-f26946e89c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 28.24 %\n",
            "CER: 18.72 %\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(reference,hypo)\n",
        "cer = jiwer.cer(reference,hypo)\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(reference,hypo)\n",
        "cer = jiwer.cer(reference,hypo)\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2d4mG9EArKD",
        "outputId": "192160c2-1828-4926-8c1d-2baf2c5e08b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 26.67 %\n",
            "CER: 19.05 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(reference,hypo)\n",
        "cer = jiwer.cer(reference,hypo)\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evl6HvIdF8ER",
        "outputId": "4cdd1d67-3b1f-4680-9aba-768f0ff5b17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 37.41 %\n",
            "CER: 18.30 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkA9HqG-nkvq"
      },
      "source": [
        "# **Pointer 7 ## Final code t o push our model to hugging face **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gratepG_lcQP"
      },
      "outputs": [],
      "source": [
        "##Code to push the final model to hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYFfgqeJY2_"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"language\": \"hi\",\n",
        "    \"model_name\": \"Whisper integrated LM 2011\",  # a 'pretty' name for our model\n",
        "    \"finetuned_from\": \"openai/whisper-medium\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": \"hf-asr-leaderboard\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "09E9_ZIjJesT",
        "outputId": "775aebba-7f12-4e13-9cdf-41b2ed78d45f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a10d0a24e70c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Whisper' object has no attribute 'push_to_hub'"
          ]
        }
      ],
      "source": [
        "model.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKtFtijYJmbi"
      },
      "source": [
        "**##Inferences of model vs BenchMarkModels -wave2wec and GoogleUSM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF8NmdKLKDpZ"
      },
      "source": [
        "**##Orignal  Whisper Model without any integration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlk1fACOKBaL",
        "outputId": "73acdef2-593f-494a-9047-b3479be40622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231106)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of audio files\n",
        "audio_files = [\n",
        "    \"/content/audio_1_1.wav\",\n",
        "    \"/content/audio_2_2.wav\",\n",
        "    \"/content/audio_3_3.wav\",\n",
        "    \"/content/audio_4_4.wav\",\n",
        "    \"/content/audio_5_5.wav\"\n",
        "]"
      ],
      "metadata": {
        "id": "qDI7xPq9s3D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4f2gCnpLG23",
        "outputId": "f8346961-3691-4a6c-d8f8-d300f8b7827c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/audio_1.wav:  उगे उगे सुद़ज चध पुजा में\n",
            "/content/audio_2.wav:  अमाना नाम चंदिन कमार स्टिंग है, और हम राची से चारकंच्टेड है, आमार.\n",
            "/content/audio_3.wav:  आँ आँ आँ आँ सुबवाय में हम तुर लेट सुट हैं तर आप में लेट सुँएके\n",
            "/content/audio_4.wav:  बाहरत की वल्कुप में हाँसे सारे बहाग के बहुती दुखित है.\n",
            "/content/audio_5.wav:  बिहार की श्थेती तोडी अच्छी नहीं हैं\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model_orignal_whisper = whisper.load_model(\"small\")  # Choose model size as needed\n",
        "\n",
        "\n",
        "\n",
        "# Dictionary to hold results\n",
        "orignal_whisper_results = {}\n",
        "\n",
        "# Transcribe each audio file\n",
        "for audio_file in audio_files:\n",
        "    result = model_orignal_whisper.transcribe(audio_file, language=\"hi\")\n",
        "    orignal_whisper_results[audio_file] = result[\"text\"]\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in orignal_whisper_results.items():\n",
        "    print(f\"{audio_file}: {transcription}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiu-YU40Jtam"
      },
      "source": [
        "[link text](https://)**##Orignal Integrated Whisper Model without fusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jZwwkj6cUDyd",
        "outputId": "69c22e37-d278-4534-a945-cb39dc190338"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inferencing using audio files\n",
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.05\n",
        "# Dictionary to hold results\n",
        "orignal_whisper_results_without_fusion = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "# result = whisper.decode(model, mel, options)\n",
        "# baseline = result.text\n",
        "# baseline\n",
        "\n",
        "# Transcribe each audio file\n",
        "for audio_file in audio_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    options = whisper.DecodingOptions(fp16=False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    baseline = result.text\n",
        "\n",
        "    original_whisper_results_without_fusion[audio_file] = baseline\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in original_whisper_results_without_fusion.items():\n",
        "    print(f\"{audio_file}: {transcription}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with shallow fusion and beam search**"
      ],
      "metadata": {
        "id": "k0vV7a8Kpnon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "a1bjiBonW5KE",
        "outputId": "da2eb320-fc21-47bd-fcdf-02cb364804b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.190035629272461, -3.0971128290349785, -3.387331008911133, -2.975449244181315, -3.098282814025879, -3.413821220397949, -3.4439942042032876, -3.385819435119629, -3.4123096466064453, -3.4189205169677734]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bce7a9e32242>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_mel_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# decode_baseline decode_shallow_fusion_beam_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_shallow_fusion_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8724ba735ef7>\u001b[0m in \u001b[0;36mdecode_shallow_fusion_beam_search\u001b[0;34m(model, mel, beam_size, lm_path, lm_weight, debug)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# combined_score = [(text, whisper_score + lm_score*lm_weight, whisper_score, lm_score) for text, whisper_score, lm_score in nbest_with_lm_score]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# combined_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         combined_score = [(text, whisper_score + lm_weight * lm_score_normalized, whisper_score, lm_score_normalized)\n\u001b[0m\u001b[1;32m     71\u001b[0m                           for (text, whisper_score, lm_score_normalized) in zip(nbest_with_lm_score, lm_scores_normalized)]\n\u001b[1;32m     72\u001b[0m         \u001b[0mcombined_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8724ba735ef7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# combined_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         combined_score = [(text, whisper_score + lm_weight * lm_score_normalized, whisper_score, lm_score_normalized)\n\u001b[0;32m---> 71\u001b[0;31m                           for (text, whisper_score, lm_score_normalized) in zip(nbest_with_lm_score, lm_scores_normalized)]\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mcombined_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mcombined_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ],
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.1\n",
        "whisper_results_with_shallow_fusion_beam_search = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # decode_baseline decode_shallow_fusion_beam_search\n",
        "# result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# result\n",
        "\n",
        "global audio_files\n",
        "# Transcribe each audio file\n",
        "for audio_file in audio_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight,debug=True)\n",
        "    whisper_results_with_shallow_fusion_beam_search[audio_file] = result\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in whisper_results_with_shallow_fusion_beam_search.items():\n",
        "    print(f\"{audio_file}: {transcription}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with shallow fusion and greedy decoding:**"
      ],
      "metadata": {
        "id": "oEKn50DSpuO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "best_of = 30\n",
        "temperature = 0.88\n",
        "lm_weight = .4\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "\n",
        "\n",
        "whisper_results_with_shallow_fusion_greedy_decoding = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # decode_baseline decode_shallow_fusion_beam_search\n",
        "# result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# result\n",
        "\n",
        "global audio_files\n",
        "# Transcribe each audio file\n",
        "for audio_file in audio_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=True)\n",
        "    whisper_results_with_shallow_fusion_greedy_decoding[audio_file] = result\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in whisper_results_with_shallow_fusion_greedy_decoding.items():\n",
        "    print(f\"{audio_file}: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Xp3eU7jIp3",
        "outputId": "18da01da-7200-4e2b-8518-75a8a50281c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('उगे उगे सूरज छठ पूजा में', -25.187070309635132, -0.00791686725231909, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070309635132, -0.00791686725231909, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070313480593, -0.007916871097780043, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070313480593, -0.007916871097780043, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070313480593, -0.007916871097780043, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070321171515, -0.00791687878870195, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070332227215, -0.00791688984440219, -25.179153442382812), ('उगे उगे सूरज छठ पूजा में', -25.187070332227215, -0.00791688984440219, -25.179153442382812), ('उगे हुगे सूरज छठ पूजा में', -26.154199738055468, -0.05797590687870979, -26.096223831176758), ('ऊगे ऊगे सूरज छठ पूजा में', -27.12588281016196, -0.1406342444881316, -26.985248565673828)]]\n",
            "[[('हमारा नाम चन्दन कुमार सिंह और हम राज्य से झारखंड स्टेट याम', -36.15852384879941, -0.07405882194393971, -36.08446502685547), ('हमारा नाम चंदन कुमार सिंह और हम रांची से झारखंड स्टेट क्याम है', -40.31335506741963, -0.16762218778095547, -40.14573287963867), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट�ॅम', -40.36088155527584, -0.263915765480917, -40.09696578979492), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम', -40.649619424929384, -0.01978620349383745, -40.62983322143555), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम', -40.64961942883789, -0.019786207402338746, -40.62983322143555), ('हमारा नाम चन्दन कुमार सिंह और हम राँची से झारखंड स्टेट याम', -41.04195422895493, -0.03304691083969608, -41.008907318115234), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेड याम', -44.67113215024354, -0.0840387969720559, -44.587093353271484), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम हर', -44.73227225409614, -0.13475333319769967, -44.59751892089844), ('हमारा नाम चंदन कुमार सिंह और हम राँची से हैं झारखंड स्टेट हाम', -44.88321541982984, -0.12934731680249412, -44.753868103027344), ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेक्ट हैम', -46.05162205234651, -0.2002083255398658, -45.85141372680664)]]\n",
            "[[('आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -51.10411265546625, -0.053888351267034354, -51.05022430419922), ('आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -51.104112668470904, -0.05388836427168413, -51.05022430419922), ('आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -51.10411267714067, -0.05388837294145064, -51.05022430419922), ('खान आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें', -56.396351672835266, -0.05143437547198797, -56.34491729736328), ('खान आज सुबह में हम थ्रा लेट से उठें कल रात्मलीट से सोयें', -57.780391793502005, -0.17866144682231702, -57.60173034667969), ('खान आज सुबह में हम थ्रा लेड से उठें कल रात में लेड से सोयें', -60.1691999314195, -0.04349802712262687, -60.125701904296875), ('खान आज सुबह में हम थ्रा लेड से उठें कल रात में लेड से सोयें', -60.16919994758347, -0.043498043286598335, -60.125701904296875), ('हान आज सुबह में हम थ्रा लेड से उठें कल रात में लेड से सोयें', -61.37422353234784, -0.06644994225995295, -61.30777359008789), ('हान आज सुबह में हम थ्रा लेड से उठे हैं कर रात में लेड से सोये के', -62.1210850105911, -0.12239345175320984, -61.99869155883789), ('खान आज सुबह में हम थ्रोर लेड से उठें कल रात में लेड से सोएं कें', -62.63230738564143, -0.18317637367854042, -62.44913101196289)]]\n",
            "[[('भारत की वर्ल्ड कप में हार से सारे भाग के बहुत ही दुःखित है', -42.27827598719761, -0.038522264053081644, -42.23975372314453), ('भारत की वर्ड कप में हार से सारे भाग के बहुत ही दुःखित है', -43.323139590876444, -0.04910699810300555, -43.27403259277344), ('भारत की वर्चअप में हाथ से सारे भाग के बहुत ही दुःखित है', -43.68340777528697, -0.0636911309998611, -43.61971664428711), ('भारत की वर्डकप में हाथ से सारे भाग के बहुत ही दुःखित है', -43.68377898032205, -0.05003950888650459, -43.63373947143555), ('भारत की वर्डकप में हाथ से सारे भाग के बहुत ही दुःखित है', -43.68377899705318, -0.050039525617632946, -43.63373947143555), ('भारत की वर्ण्डकप में हाथ से सारे भाग के बहुत ही दुःखित है', -43.70750427246094, -0.08778762817382812, -43.61971664428711), ('भारत की वर्चअप में हार से सारे भाग के बहुत ही दुःखित है', -45.33130660809969, -0.05592361249421772, -45.27538299560547), ('भारत की वर्चरप में हार से सारे भाग के बहुत ही दुःखित है', -45.432978766305105, -0.1575957706996373, -45.27538299560547), ('भारत की वर्डकप में हाज से सारे भाग के बहुत ही दुःखित है', -47.5225329148142, -0.07313105934544613, -47.44940185546875), ('भारत की वर्ट कप में हार से सारे भाग के बहुत ही दुखित है', -48.91063195687753, -0.19489175302010994, -48.71574020385742)]]\n",
            "[[('बिहार की', -6.71892589992947, -0.17171520657009548, -6.547210693359375), ('बिहार की स्थिति थोड़ी अच्छी नहीं है', -14.810094497142694, -0.025625846324822843, -14.784468650817871), ('बिहार की स्थिति थोड़ी अच्छी नहीं है', -14.810094517010908, -0.025625866193037767, -14.784468650817871), ('बिहार की स्थिति थोड़ी अच्छी नहीं है', -14.810094523124206, -0.025625872306334667, -14.784468650817871), ('बिहार की स्थिति थोड़ी अच्छी नहीं हैं', -15.005605149269105, -0.100026535987854, -14.90557861328125), ('बिहार की स्थिति थोड़ी अच्छी नही है', -18.747635643733176, -0.0302169730788783, -18.717418670654297), ('बिहार की स्थिति थोड़ी अच्छी नही है', -18.747635643733176, -0.0302169730788783, -18.717418670654297), ('बिहार की स्थिति थोड़ी अच्छी नही है', -18.747635643733176, -0.0302169730788783, -18.717418670654297), ('बिहार की स्थिति थोड़ी अच्छी नही है', -18.747635662555695, -0.030216991901397705, -18.717418670654297), ('बिहार की स्थिति थुड़ी अच्छी नही है', -24.7092640094268, -0.11489984316703601, -24.594364166259766)]]\n",
            "/content/audio_1.wav: ['उगे उगे सूरज छठ पूजा में']\n",
            "/content/audio_2.wav: ['हमारा नाम चन्दन कुमार सिंह और हम राज्य से झारखंड स्टेट याम']\n",
            "/content/audio_3.wav: ['आज सुबह में हम थ्रा लेट से उठें कल रात में लेट से सोयें']\n",
            "/content/audio_4.wav: ['भारत की वर्ल्ड कप में हार से सारे भाग के बहुत ही दुःखित है']\n",
            "/content/audio_5.wav: ['बिहार की']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ofgIloKYdf"
      },
      "source": [
        "**##Orignal Wave2wec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hXopFc9cSJj",
        "outputId": "a582763e-a286-455a-852e-d0adedceed71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:733: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*******************wave 2 wec transcription***************** \n",
            "CHAMMUSHAA U CHACHA TRU I'L SHAR\n"
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "# Function to read and preprocess the audio file\n",
        "def speech_file_to_array_fn(path):\n",
        "    speech_array, sampling_rate = sf.read(path)\n",
        "    return speech_array\n",
        "\n",
        "# Function to perform inference\n",
        "def asr_transcript(audio_file):\n",
        "    # Load and preprocess the audio\n",
        "    speech = speech_file_to_array_fn(audio_file)\n",
        "    input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    # Get predicted IDs and decode them to text\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = tokenizer.batch_decode(predicted_ids)\n",
        "\n",
        "    return transcription[0]\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"/content/audio.wav\"\n",
        "\n",
        "# Perform inference and print the result\n",
        "print(\"*******************wave 2 wec transcription***************** \")\n",
        "print(asr_transcript(audio_file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jpnOwYUKc15"
      },
      "source": [
        "**Orignal Google USM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "uDfTKL4PeFSy",
        "outputId": "872d629c-0dd1-4433-bb49-4a032f3eb2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-speech\n",
            "  Downloading google_cloud_speech-2.22.0-py2.py3-none-any.whl (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/275.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/275.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.61.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.59.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.5.0)\n",
            "Installing collected packages: google-cloud-speech\n",
            "Successfully installed google-cloud-speech-2.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Google USM\n",
        "\n",
        "!pip install google-cloud-speech\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqDGYN2IfwI"
      },
      "source": [
        "##Google USM Transcrption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW125a12CNY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drivedownloaduplaod-eed71df0371c.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV9bEQ9f52tW",
        "outputId": "8f509d7e-d231-456c-976a-fd0adf2d5610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.8.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import librosa\n",
        "# import soundfile as sf\n",
        "\n",
        "# # Load the audio file\n",
        "# audio, sr = librosa.load('/content/audio_5.wav', sr=48000)  # Load with original sample rate (48kHz)\n",
        "\n",
        "# # Resample to 16kHz\n",
        "# audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "\n",
        "# # Save the resampled audio\n",
        "# sf.write('/content/audio_5_5.wav', audio_resampled, 16000)\n"
      ],
      "metadata": {
        "id": "XmHAWIjf54zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/audio_1.wav'\n",
        "output_file = '/content/audio_1_1.wav'\n",
        "original_sample_rate = 48000  # 48kHz\n",
        "target_sample_rate = 16000    # 16kHz"
      ],
      "metadata": {
        "id": "h3bwNZadEw6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resample_audio(input_file, output_file, original_sample_rate, target_sample_rate)\n"
      ],
      "metadata": {
        "id": "VHtTIEgqEr37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S58lF2odEu9x",
        "outputId": "1176d86b-c14f-488d-b7a8-a22ba3735b6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/audio_1_1.flac'>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Load the WAV file\n",
        "wav_audio = AudioSegment.from_file(\"/content/audio_1_1.wav\", format=\"wav\")\n",
        "\n",
        "# Export as FLAC\n",
        "wav_audio.export(\"/content/audio_1_1.flac\", format=\"flac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsdZEHzrePRj",
        "outputId": "3ffb4829-b0eb-4e5a-825c-89b64d5ffc55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"उदयवीर सूरज छठ पूजा में\",\n",
            "          \"confidence\": 0.80075234\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"4.800s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"5s\",\n",
            "  \"requestId\": \"2022486015774079337\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJmdj8Tx8YP2",
        "outputId": "b252cd9e-5e1b-4411-fe59-6558cbe64a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"मेरा नाम चंदन कुमार सिंह है और हम रांची से झारखंड स्टेट काम है\",\n",
            "          \"confidence\": 0.84342927\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"6.750s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"7s\",\n",
            "  \"requestId\": \"3225024303261540763\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzj8MXQC8fmQ",
        "outputId": "a573dc0a-9f8a-4a61-cf60-bf47bc10750d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"आज आज सुबह में हम फेवरेट स्वीट हैं कल रात में लेट सोए थे\",\n",
            "          \"confidence\": 0.80344194\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"7.350s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"8s\",\n",
            "  \"requestId\": \"2199201602030567921\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAinRafn8mBh",
        "outputId": "0e947bea-863e-473b-88f5-6d7b94ba1902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"भारत की वर्ल्ड कप में हाथ से सारे भाग के बहुत ही दुखित है\",\n",
            "          \"confidence\": 0.8286048\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"6.830s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"7s\",\n",
            "  \"requestId\": \"3756998355448913141\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saVNaPNc8s7p",
        "outputId": "c57fe8f9-5f1b-4d71-ca9f-d0595cb85d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"बिहार की स्थिति थोड़ी अच्छी नहीं है\",\n",
            "          \"confidence\": 0.65068185\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"7.370s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"8s\",\n",
            "  \"requestId\": \"5686012418812165510\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट हैम',"
      ],
      "metadata": {
        "id": "4LMRTYILlyJY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "150486309a0540b0a51a96664f78aba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "24c1c8f49f5a43eab9b1b9f9f0a12fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273a08df24d343a7a227d09b9e23ebb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b858b805f54292a322d13611833c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd766dafea94135862b6e9e0d9876cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f065f61e9e1443a85aee518670a4fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "style": "IPY_MODEL_e543d211badc4d41bd944df904ce0317",
            "value": true
          }
        },
        "455bae593a3240d9ba064c213a90ece9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4928327c81124c60bd8e3aca15942167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7390656d2d4240969f6202876d1a57c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a0a08417de42e88bdf8ffc693f42b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b595673f6a4db4a47a25e88ebc2d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_981bc86f56014362942f1fad9d5fe00c",
            "value": "Token is valid (permission: write)."
          }
        },
        "773b457557fd4352a317068d87fa4eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5806a46c454e0c9c3f1ca5f70d4279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455bae593a3240d9ba064c213a90ece9",
            "placeholder": "​",
            "style": "IPY_MODEL_ba5939381af044029e254989149974db",
            "value": "Connecting..."
          }
        },
        "8536aa41d17347508a262bbc9693b7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75a0a08417de42e88bdf8ffc693f42b6",
              "IPY_MODEL_bb853deecb594dad80ae466afa531d75",
              "IPY_MODEL_920da0787e654f6bb9a0c76cc88f0f5c",
              "IPY_MODEL_bbb0d45741c8401b819941a9eda1c1a7"
            ],
            "layout": "IPY_MODEL_150486309a0540b0a51a96664f78aba7"
          }
        },
        "920da0787e654f6bb9a0c76cc88f0f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7390656d2d4240969f6202876d1a57c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "981bc86f56014362942f1fad9d5fe00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f33f70e05d4897aac484cb940392d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1471db6c574235ac5967dd80734786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9c06e19a154517b4ff46c7a52d29d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed79d83bbe84ba5aa53f601588c4ee8",
            "placeholder": "​",
            "style": "IPY_MODEL_28b858b805f54292a322d13611833c33",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "aed79d83bbe84ba5aa53f601588c4ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b805718a8b76423386511730e0fdeaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b595673f6a4db4a47a25e88ebc2d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba507efc55c145419acdec6f0fb62b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773b457557fd4352a317068d87fa4eef",
            "placeholder": "​",
            "style": "IPY_MODEL_b805718a8b76423386511730e0fdeaff",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ba5939381af044029e254989149974db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba67e8ff964d4073b870e1200a87fd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d6ef36d77a09460d82ce46f28df66665",
            "style": "IPY_MODEL_c16fa1150d12439688fa21af50d995c7",
            "tooltip": ""
          }
        },
        "bb853deecb594dad80ae466afa531d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f33f70e05d4897aac484cb940392d4",
            "placeholder": "​",
            "style": "IPY_MODEL_4928327c81124c60bd8e3aca15942167",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "bbb0d45741c8401b819941a9eda1c1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273a08df24d343a7a227d09b9e23ebb4",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd766dafea94135862b6e9e0d9876cf",
            "value": "Login successful"
          }
        },
        "c16fa1150d12439688fa21af50d995c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d6ef36d77a09460d82ce46f28df66665": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e543d211badc4d41bd944df904ce0317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0885c2a4abd4fe6902ca4f7aba7b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f96cd823f757434997f49f4b2c7d2a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab1471db6c574235ac5967dd80734786",
            "placeholder": "​",
            "style": "IPY_MODEL_ff114fffeab840c6a8fab1662d1dddd7",
            "value": ""
          }
        },
        "ff114fffeab840c6a8fab1662d1dddd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b37d0c9652b46d9bc8b217c08f1bd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6cb6986cf094da88e6bd72086c32c51",
              "IPY_MODEL_2021abeaecb94bd7a7eb0cf6aef386af",
              "IPY_MODEL_92c560cefd5745cf984ba6f3aef599a7"
            ],
            "layout": "IPY_MODEL_41fd740b76e64ea0a6f60a73f5a43458"
          }
        },
        "e6cb6986cf094da88e6bd72086c32c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbdb5749b25745cd96a89d5901fba6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_fc61e213b7e0476097af539110e8f606",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "2021abeaecb94bd7a7eb0cf6aef386af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8834384af04762bda88e03db6d933f",
            "max": 967122759,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9dd1179d205455d8c28bab58dbb7476",
            "value": 967122759
          }
        },
        "92c560cefd5745cf984ba6f3aef599a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc6e4d43e9b4d86bbb984d4f756539c",
            "placeholder": "​",
            "style": "IPY_MODEL_78b73b96a00a4d15b1471208cd1b8527",
            "value": " 967M/967M [00:37&lt;00:00, 26.4MB/s]"
          }
        },
        "41fd740b76e64ea0a6f60a73f5a43458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdb5749b25745cd96a89d5901fba6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc61e213b7e0476097af539110e8f606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8834384af04762bda88e03db6d933f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9dd1179d205455d8c28bab58dbb7476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dc6e4d43e9b4d86bbb984d4f756539c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b73b96a00a4d15b1471208cd1b8527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806080cba50b42b8922fd85ad9b9e836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ee8e22d71d64547b448d55cf413c4fe",
              "IPY_MODEL_21f43337225e4ec5bd0bad2944493929",
              "IPY_MODEL_30c1f4e66d95487bae98a1209cc8a818"
            ],
            "layout": "IPY_MODEL_5c48a0a1f752470687e8dd09e1533fd5"
          }
        },
        "3ee8e22d71d64547b448d55cf413c4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ad19f44bf34038822d84b7f9dbe0d5",
            "placeholder": "​",
            "style": "IPY_MODEL_41335379ccbb4437b885881d7ffae38f",
            "value": "config.json: 100%"
          }
        },
        "21f43337225e4ec5bd0bad2944493929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21a5d30dc6648fb85aecc748dd095ea",
            "max": 1967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee95e491eafb4df298c4cf35b29268e3",
            "value": 1967
          }
        },
        "30c1f4e66d95487bae98a1209cc8a818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48eb3725ef29428493bf82df67d84931",
            "placeholder": "​",
            "style": "IPY_MODEL_e3cd6001976a4b0caa36136a79cbe66b",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "5c48a0a1f752470687e8dd09e1533fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ad19f44bf34038822d84b7f9dbe0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41335379ccbb4437b885881d7ffae38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b21a5d30dc6648fb85aecc748dd095ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee95e491eafb4df298c4cf35b29268e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48eb3725ef29428493bf82df67d84931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cd6001976a4b0caa36136a79cbe66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a537c524a04a6dbd62faae16b5f6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33fb0f90cec544b2ab4452a7ea76d193",
              "IPY_MODEL_e0b70b7bb2e24d7d9e06054aba10ded6",
              "IPY_MODEL_4c02e2870df7437093e6601f0b694e2f"
            ],
            "layout": "IPY_MODEL_84e9ea63d8b24d63991e1e44c2b24c6e"
          }
        },
        "33fb0f90cec544b2ab4452a7ea76d193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c00fbc3423f4737bd80dab52d9abd26",
            "placeholder": "​",
            "style": "IPY_MODEL_6ce0f28e3bde4018acb474c7b17570e4",
            "value": "model.safetensors: 100%"
          }
        },
        "e0b70b7bb2e24d7d9e06054aba10ded6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8202a50b6444b37bd498e8056aaaa81",
            "max": 966995080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_246249c995594d8bab5506e4db1ea99f",
            "value": 966995080
          }
        },
        "4c02e2870df7437093e6601f0b694e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca02d5f3bea94c598ab9d6e8e354d7b5",
            "placeholder": "​",
            "style": "IPY_MODEL_500f0ae930d24c52ae169286b4a76ecb",
            "value": " 967M/967M [00:22&lt;00:00, 43.8MB/s]"
          }
        },
        "84e9ea63d8b24d63991e1e44c2b24c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c00fbc3423f4737bd80dab52d9abd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce0f28e3bde4018acb474c7b17570e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8202a50b6444b37bd498e8056aaaa81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246249c995594d8bab5506e4db1ea99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca02d5f3bea94c598ab9d6e8e354d7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500f0ae930d24c52ae169286b4a76ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6768953395749bbbb9e38679ea2798b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_886318f846884f2599bfc8f729e6bff9",
              "IPY_MODEL_14394d3948c7441f9683a64f1a7d42ed",
              "IPY_MODEL_6ac1f734c1fa481eb845a0a7a8784de4"
            ],
            "layout": "IPY_MODEL_07fc379f8d124c1eb61eb4c4c96c087e"
          }
        },
        "886318f846884f2599bfc8f729e6bff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d03f4bf262479dad370427b3bf5ec4",
            "placeholder": "​",
            "style": "IPY_MODEL_e5f17fd3383f4746b22e79d96873d011",
            "value": "generation_config.json: 100%"
          }
        },
        "14394d3948c7441f9683a64f1a7d42ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63203d11435b4786a68c6700459408bf",
            "max": 3837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f1941380a174f27a56b99ee1f757d31",
            "value": 3837
          }
        },
        "6ac1f734c1fa481eb845a0a7a8784de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b01fce9cc84fc8b3a84d0b2c0693d9",
            "placeholder": "​",
            "style": "IPY_MODEL_840809356c1d4b4c88db70984ce585d4",
            "value": " 3.84k/3.84k [00:00&lt;00:00, 323kB/s]"
          }
        },
        "07fc379f8d124c1eb61eb4c4c96c087e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d03f4bf262479dad370427b3bf5ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f17fd3383f4746b22e79d96873d011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63203d11435b4786a68c6700459408bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1941380a174f27a56b99ee1f757d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42b01fce9cc84fc8b3a84d0b2c0693d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840809356c1d4b4c88db70984ce585d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979e875132624fbc85665f648b9a87e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81170fe84f6b4fba9272357af4e16925",
              "IPY_MODEL_52d677cc98b74d1fad58f15bbfc8e20a",
              "IPY_MODEL_fa1ae95c7ce243be94ef6ddbde0dc8b8"
            ],
            "layout": "IPY_MODEL_58536d4db90d4444bceac430ebd31d8a"
          }
        },
        "81170fe84f6b4fba9272357af4e16925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_053c927f36354a53a152ab23ec693ec0",
            "placeholder": "​",
            "style": "IPY_MODEL_edb675e244df4c68bcb7048bc001cefa",
            "value": "Downloading data: 100%"
          }
        },
        "52d677cc98b74d1fad58f15bbfc8e20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a60000f2094bd6876125b5477fdada",
            "max": 12463616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_230ba208ed774d6894238621da7b2db4",
            "value": 12463616
          }
        },
        "fa1ae95c7ce243be94ef6ddbde0dc8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1862d8ae289f4e6bb66b0164a43aa688",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf4f7f9c4114a738893729a9b2911e1",
            "value": " 12.5M/12.5M [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "58536d4db90d4444bceac430ebd31d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "053c927f36354a53a152ab23ec693ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb675e244df4c68bcb7048bc001cefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a60000f2094bd6876125b5477fdada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230ba208ed774d6894238621da7b2db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1862d8ae289f4e6bb66b0164a43aa688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf4f7f9c4114a738893729a9b2911e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1e161946dc4e5fa0ca908303a1ddfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d609396bb7d24763b99aba7fce03982e",
              "IPY_MODEL_0c1b68df0ceb4b71af740d6ec957769e",
              "IPY_MODEL_480d12f85b9e4bb3afcdb928088ed10a"
            ],
            "layout": "IPY_MODEL_89c07ccb0ca844f483535687af2ff187"
          }
        },
        "d609396bb7d24763b99aba7fce03982e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854156701c2b4b648adf713aba345c47",
            "placeholder": "​",
            "style": "IPY_MODEL_470a61e298f645ee86cdbb21e07d56fb",
            "value": "Generating txt.done.data.utf8 split: "
          }
        },
        "0c1b68df0ceb4b71af740d6ec957769e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea561cfbe004907bd1fe0f7746abd71",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdddcbfae5614387809db477218d7db9",
            "value": 1
          }
        },
        "480d12f85b9e4bb3afcdb928088ed10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1508e0451600433ca863124c575e99d0",
            "placeholder": "​",
            "style": "IPY_MODEL_a03095e4886c4bbdbc44f395a71958df",
            "value": " 1000/0 [00:00&lt;00:00, 1906.97 examples/s]"
          }
        },
        "89c07ccb0ca844f483535687af2ff187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854156701c2b4b648adf713aba345c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470a61e298f645ee86cdbb21e07d56fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea561cfbe004907bd1fe0f7746abd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bdddcbfae5614387809db477218d7db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1508e0451600433ca863124c575e99d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03095e4886c4bbdbc44f395a71958df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e06df394b14f1a96209c1b195d9cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27d13e0e5b184bd4a0dc672cf107af52",
              "IPY_MODEL_fca7eaa031ba4a1b9f385e3fb41d5790",
              "IPY_MODEL_fbd3c1674b2f4e76bcb2e7692c2ad10c"
            ],
            "layout": "IPY_MODEL_d3edaa1efc4841e493f993bec8af1e35"
          }
        },
        "27d13e0e5b184bd4a0dc672cf107af52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a4907162a8a4b7ca0eebe90fb66c94f",
            "placeholder": "​",
            "style": "IPY_MODEL_254066cc6112408394d64f41fdffd936",
            "value": "Downloading data: 100%"
          }
        },
        "fca7eaa031ba4a1b9f385e3fb41d5790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e95c75ab434bd19a80f583c27ad80d",
            "max": 452581888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe6e3b7dd2147b3a9207fc1bea6e15a",
            "value": 452581888
          }
        },
        "fbd3c1674b2f4e76bcb2e7692c2ad10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e13c66fc02f40fbb988fec5e2836d6b",
            "placeholder": "​",
            "style": "IPY_MODEL_c15e21009aad48d0921251a972028ffc",
            "value": " 453M/453M [00:18&lt;00:00, 31.5MB/s]"
          }
        },
        "d3edaa1efc4841e493f993bec8af1e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4907162a8a4b7ca0eebe90fb66c94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254066cc6112408394d64f41fdffd936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5e95c75ab434bd19a80f583c27ad80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe6e3b7dd2147b3a9207fc1bea6e15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e13c66fc02f40fbb988fec5e2836d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15e21009aad48d0921251a972028ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef0a972dcfd4abfacd660902e52aed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed47061b191448fc89834ebabbb408a2",
              "IPY_MODEL_0f238c9460a244369dfbef5db1199cee",
              "IPY_MODEL_e48b1604bd0c4a729fec0a6d33a8c959"
            ],
            "layout": "IPY_MODEL_a75494fbb4394af8b794031950d9fa0b"
          }
        },
        "ed47061b191448fc89834ebabbb408a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a0357d202f41f58eb631ff8eb2fd3b",
            "placeholder": "​",
            "style": "IPY_MODEL_a24c1c896dd448cc82ddc16fd5ea9fa6",
            "value": "Generating train split: "
          }
        },
        "0f238c9460a244369dfbef5db1199cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3639d15728fa4b95bddcdc0d20e428a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5c3edf8376a48a9b52b84ecb34b65c1",
            "value": 1
          }
        },
        "e48b1604bd0c4a729fec0a6d33a8c959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5c371605cf4ba4a8783ed96c12fb29",
            "placeholder": "​",
            "style": "IPY_MODEL_95d535810eb2432388ed5c73dbb495e0",
            "value": " 4630/0 [00:02&lt;00:00, 1803.36 examples/s]"
          }
        },
        "a75494fbb4394af8b794031950d9fa0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a0357d202f41f58eb631ff8eb2fd3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24c1c896dd448cc82ddc16fd5ea9fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3639d15728fa4b95bddcdc0d20e428a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f5c3edf8376a48a9b52b84ecb34b65c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb5c371605cf4ba4a8783ed96c12fb29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d535810eb2432388ed5c73dbb495e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ee5553a67b4c0db2192bb358110a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a50685284b644c4b0d91b8376e67f61",
              "IPY_MODEL_196c3e63aafd406a8a2b8f69fb858cd2",
              "IPY_MODEL_9f013b618d3d4ab99d2fedfa14e23600"
            ],
            "layout": "IPY_MODEL_72d96bae804b4083a60ca335063f1623"
          }
        },
        "3a50685284b644c4b0d91b8376e67f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c9ea6c2ebd49b6901e0e2981f5ab4b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d2157036de4a8b860a51cf6366fe17",
            "value": "Generating test split: "
          }
        },
        "196c3e63aafd406a8a2b8f69fb858cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10167ae3c0b3409a823befcc054d742c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69ecc9797b84462e8ffb86f8dc28cabe",
            "value": 1
          }
        },
        "9f013b618d3d4ab99d2fedfa14e23600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d75737f462b4a0daf1d75d5d7fea58f",
            "placeholder": "​",
            "style": "IPY_MODEL_763fb4b9b45843e880ef34a6752d8d23",
            "value": " 3072/0 [00:02&lt;00:00, 1266.27 examples/s]"
          }
        },
        "72d96bae804b4083a60ca335063f1623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c9ea6c2ebd49b6901e0e2981f5ab4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d2157036de4a8b860a51cf6366fe17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10167ae3c0b3409a823befcc054d742c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69ecc9797b84462e8ffb86f8dc28cabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d75737f462b4a0daf1d75d5d7fea58f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763fb4b9b45843e880ef34a6752d8d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a14bc2fefe174d0987e8ab712fb52a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6604430fd9446e78102a5daf2273bda",
              "IPY_MODEL_ed8f13e567bc4569b0be12525822b4f7",
              "IPY_MODEL_3c14ab46888d4bbda2ae91986a70d948"
            ],
            "layout": "IPY_MODEL_1a75cdb54dec46439bbe71bc8ff6a93f"
          }
        },
        "e6604430fd9446e78102a5daf2273bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d94de758d74c01aa2f55a0ee5cfc01",
            "placeholder": "​",
            "style": "IPY_MODEL_de9420358f6d421b84a0366fa51e9565",
            "value": "Generating validation split: "
          }
        },
        "ed8f13e567bc4569b0be12525822b4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ab465bb89540c79d84f9de33b29d63",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5867b57a731b43de824842b1adf62e19",
            "value": 1
          }
        },
        "3c14ab46888d4bbda2ae91986a70d948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_017e70c733fc4203a6e0ee81e19fa395",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb61eda82a74419a4584b0ca01f0330",
            "value": " 2416/0 [00:01&lt;00:00, 1159.98 examples/s]"
          }
        },
        "1a75cdb54dec46439bbe71bc8ff6a93f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d94de758d74c01aa2f55a0ee5cfc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9420358f6d421b84a0366fa51e9565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ab465bb89540c79d84f9de33b29d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5867b57a731b43de824842b1adf62e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "017e70c733fc4203a6e0ee81e19fa395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb61eda82a74419a4584b0ca01f0330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c6fbe0253cb426e952c00f951d1fd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13a8f8aaa37a4b08a03c844a8ca0cd20",
              "IPY_MODEL_a75d2d93591a436ba212b62a01d94b51",
              "IPY_MODEL_e10c651a8ed54bbd90c489061c75a46b"
            ],
            "layout": "IPY_MODEL_7787ee96365d46579ffc645630e60150"
          }
        },
        "13a8f8aaa37a4b08a03c844a8ca0cd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609315a06c5d439fbcd40e252e87c101",
            "placeholder": "​",
            "style": "IPY_MODEL_30ad17a8953d4447836e780a23269727",
            "value": "Generating other split: "
          }
        },
        "a75d2d93591a436ba212b62a01d94b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d96d4cf8fd4e27a412acad0114c86c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3285b6a95afe4df69856c12491a2d739",
            "value": 1
          }
        },
        "e10c651a8ed54bbd90c489061c75a46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f8e1b31b18449b6bdaeda32f93c4a53",
            "placeholder": "​",
            "style": "IPY_MODEL_9bbde12f22ce4360adcbaf7f55d1b990",
            "value": " 3767/0 [00:02&lt;00:00, 2286.91 examples/s]"
          }
        },
        "7787ee96365d46579ffc645630e60150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609315a06c5d439fbcd40e252e87c101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ad17a8953d4447836e780a23269727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d96d4cf8fd4e27a412acad0114c86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3285b6a95afe4df69856c12491a2d739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f8e1b31b18449b6bdaeda32f93c4a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbde12f22ce4360adcbaf7f55d1b990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25475e38431f42b982eeb288369a9dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fcbcae9b164425ab151e569b79b4c83",
              "IPY_MODEL_3c2b9d2480ca4ebd8ada945f7ec4e6d0",
              "IPY_MODEL_4ee847b3f93a4e7b811bf4e9752dfee0"
            ],
            "layout": "IPY_MODEL_ca182311576f415e9cc64ed4c2eac7aa"
          }
        },
        "6fcbcae9b164425ab151e569b79b4c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff8ea40bd904f008acd39829b2b7c04",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae56a3813d9432ab135b06a61824a14",
            "value": "Generating validated split: "
          }
        },
        "3c2b9d2480ca4ebd8ada945f7ec4e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1de5a57bab4e3a99ef4eee6e69bd99",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551374414a3b471c9e42c5ce03f56b7e",
            "value": 1
          }
        },
        "4ee847b3f93a4e7b811bf4e9752dfee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a8105297004d41923eb5c1cdec5367",
            "placeholder": "​",
            "style": "IPY_MODEL_77e41cd0c1b44389af2b0876bb6e919f",
            "value": " 10173/0 [00:04&lt;00:00, 1718.85 examples/s]"
          }
        },
        "ca182311576f415e9cc64ed4c2eac7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff8ea40bd904f008acd39829b2b7c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae56a3813d9432ab135b06a61824a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be1de5a57bab4e3a99ef4eee6e69bd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "551374414a3b471c9e42c5ce03f56b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14a8105297004d41923eb5c1cdec5367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e41cd0c1b44389af2b0876bb6e919f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90650f5799154083a1d1504491a8912f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c5766760aba43caa370937f56279397",
              "IPY_MODEL_94a8b7cd60a943698a3981481a10551a",
              "IPY_MODEL_8dfa6c848a9b487ba0fa7dab2704b47a"
            ],
            "layout": "IPY_MODEL_e8528e67bd0246cf8d3809adc9a2dc86"
          }
        },
        "1c5766760aba43caa370937f56279397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e64df3888944732925ab1260c835e6b",
            "placeholder": "​",
            "style": "IPY_MODEL_738e0d35d9fd4a15bbebdb1d404b4f7a",
            "value": "Generating invalidated split: "
          }
        },
        "94a8b7cd60a943698a3981481a10551a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f56383e72b421f95a72cc01cf55c54",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a1e834f550641c4818eb98b39f8d204",
            "value": 1
          }
        },
        "8dfa6c848a9b487ba0fa7dab2704b47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f46f5db91a144debbd69eabf9c14f6f",
            "placeholder": "​",
            "style": "IPY_MODEL_55d797ca131941bcbace399a16741089",
            "value": " 757/0 [00:01&lt;00:00, 532.57 examples/s]"
          }
        },
        "e8528e67bd0246cf8d3809adc9a2dc86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e64df3888944732925ab1260c835e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738e0d35d9fd4a15bbebdb1d404b4f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98f56383e72b421f95a72cc01cf55c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5a1e834f550641c4818eb98b39f8d204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f46f5db91a144debbd69eabf9c14f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d797ca131941bcbace399a16741089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39f37df33d37428183d25aafa7678d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0563cbd7ca1f4c9091a1044fd4fdcbf7",
              "IPY_MODEL_b851b485cf4e4e258ca665090ea540ee",
              "IPY_MODEL_c048546ed6024768acde97cb8eb91405"
            ],
            "layout": "IPY_MODEL_e2b59f12cdbc4559b67d79b6af614c99"
          }
        },
        "0563cbd7ca1f4c9091a1044fd4fdcbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa11b2cd6b9f479791a2db5d956c5d32",
            "placeholder": "​",
            "style": "IPY_MODEL_f281c01fa768493f944b1938bb891f41",
            "value": "Downloading data: 100%"
          }
        },
        "b851b485cf4e4e258ca665090ea540ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0024401bfb244c30974e472d47dc615b",
            "max": 64410112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d722dae3e800471aa1817f969f0ed60a",
            "value": 64410112
          }
        },
        "c048546ed6024768acde97cb8eb91405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b9b2b0d3b546ebb19d09a4a07710f0",
            "placeholder": "​",
            "style": "IPY_MODEL_8143d8ff89354778973d78d1ff3bdc8d",
            "value": " 64.4M/64.4M [00:02&lt;00:00, 32.3MB/s]"
          }
        },
        "e2b59f12cdbc4559b67d79b6af614c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa11b2cd6b9f479791a2db5d956c5d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f281c01fa768493f944b1938bb891f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0024401bfb244c30974e472d47dc615b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d722dae3e800471aa1817f969f0ed60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16b9b2b0d3b546ebb19d09a4a07710f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8143d8ff89354778973d78d1ff3bdc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33863613c1ed4511bc7b343d9e903e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d47d5fc52f1341f1b204896fab2d979f",
              "IPY_MODEL_bb3457aae2f24a29aa5582c465584084",
              "IPY_MODEL_b0415522224945ab9ae417199db3ba2c"
            ],
            "layout": "IPY_MODEL_d39646d768b046d290c61c448ee76cf6"
          }
        },
        "d47d5fc52f1341f1b204896fab2d979f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda2b240e8ca4da6abfcc8d378ee0819",
            "placeholder": "​",
            "style": "IPY_MODEL_d7ba5cfec3a14826ab98b8008f643820",
            "value": "Generating text split: "
          }
        },
        "bb3457aae2f24a29aa5582c465584084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a37a5d51e6e43728de23ecf1d655bfa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1195272ad54af5979c1a2776c78b1d",
            "value": 1
          }
        },
        "b0415522224945ab9ae417199db3ba2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e9cfeeaa9340359d6f55d20e7678f6",
            "placeholder": "​",
            "style": "IPY_MODEL_44f141c2859a463ebf61eaa06b2ac365",
            "value": " 1032/0 [00:01&lt;00:00, 646.16 examples/s]"
          }
        },
        "d39646d768b046d290c61c448ee76cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda2b240e8ca4da6abfcc8d378ee0819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ba5cfec3a14826ab98b8008f643820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a37a5d51e6e43728de23ecf1d655bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5d1195272ad54af5979c1a2776c78b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68e9cfeeaa9340359d6f55d20e7678f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f141c2859a463ebf61eaa06b2ac365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}