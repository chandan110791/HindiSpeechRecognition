{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandan110791/HindiSpeechRecognition/blob/main/Whisper_LM_fusion_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtnWp1Z9NIrh"
      },
      "source": [
        "# Fusing LM with Whisper for lower WER\n",
        "\n",
        "To enhance the accuracy of Whisper's beam-search decoding, we aim to integrate Byte Pair Encoding (BPE) language model (LM) scores with the scores of generated tokens. This fusion strategy aims to reduce the Word Error Rate (WER) by leveraging the linguistic information from the BPE-level LM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWD69559NPaz"
      },
      "source": [
        "#1 POC: Standalone Execution of the Language Model and Testing integration with whisper\n",
        "\n",
        "\n",
        "\n",
        "We aim to effectively do a short POC if we can integrate a pre-trained language model (LM) with the Whisper framework .\n",
        "\n",
        "Language Model Specification: KenLM is a library that efficiently estimates and evaluates n-gram language models, commonly used in natural language processing for tasks like speech recognition and machine translation. Detailed information about KenLM can be found here.[KenLM](https://github.com/kpu/kenlm)\n",
        "\n",
        "Task: We Develop code to operationalize an existing LM independently. The code should be capable of evaluating and scoring any given input sequence.\n",
        "\n",
        "Selected Model for Implementation: The model chosen for this task is the Riva ASR Hindi Language Model, available for reference and download at the following NVIDIA NGC link: Riva ASR Hindi LM.(https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n",
        "\n",
        "The goal of this step is to validate the standalone functionality of the chosen LM, ensuring its readiness for subsequent integration with the Whisper system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN5ZcXEbPFgD"
      },
      "source": [
        "### 1.1:Download and build the KenLM toolkit library packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOD5vBabeTED",
        "outputId": "e245aa24-055e-4895-e543-8bc2052c8c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-13 11:27:39--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 480.36K  1.67MB/s    in 0.3s    \n",
            "\n",
            "2023-11-13 11:27:40 (1.67 MB/s) - written to stdout [491888/491888]\n",
            "\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.3s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 50%] Built target probing_hash_table_benchmark\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 57%] Built target kenlm_filter\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 75%] Built target fragment\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 77%] Built target query\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 86%] Built target kenlm_benchmark\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 91%] Built target kenlm_builder\n",
            "[ 92%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 96%] Built target phrase_table_vocab\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "build_binary  filter\tkenlm_benchmark  phrase_table_vocab\t       query\n",
            "count_ngrams  fragment\tlmplz\t\t probing_hash_table_benchmark\n"
          ]
        }
      ],
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz\n",
        "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
        "!ls kenlm/build/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C3lwRxNebYv",
        "outputId": "e2f9d66a-0bcc-4f1f-ab47-43bffd8fe3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184345 sha256=6cc9a5db8180947baa0ae0b8fd35c040b77ff8e307bf437b2fafd6295101aa79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9az3r8uo/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr61mDKxZru1"
      },
      "source": [
        "### 1.2 We now Download the Hindi n-gram language model from Nvidia which can be found [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n",
        "\n",
        "This will be used for fusion with Whisper.\n",
        "I am downloading the  binary version to a shareable location in my Gdrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "NU0mgmnmhsxe",
        "outputId": "6484130f-7253-4276-9d29-58098fb08827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 147MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LXkmNaklfx",
        "outputId": "151e2382-782e-41f4-8c8d-316b4fa00a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "import kenlm\n",
        "model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(model.order))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "❗❗**Restart the runtime after running abvoe cell** ❗❗\n"
      ],
      "metadata": {
        "id": "AltSNI85L5v2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fo71Q-qbfuU",
        "outputId": "a853e9f9-0f9d-4ed4-eb86-a3fae25a457d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-20.935253143310547 -21.663846969604492\n"
          ]
        }
      ],
      "source": [
        "# Below are 2 pairs of sentences that sound exactly the same in hindi but one of them is incorrect (lexically or semantically)\n",
        "# Generated using Bing Chat\n",
        "book_correct = \"मुझे यह किताब पसंद है।\"\n",
        "book_incorrect = \"मुझे यह किताब पसन्द है।\"\n",
        "\n",
        "correct_score = model.score(book_correct)\n",
        "incorrect_score = model.score(book_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First one is right and we get better score for first sentance"
      ],
      "metadata": {
        "id": "coeoNfVGMGZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDslvQ98bhFd",
        "outputId": "335af234-ca71-441e-f1c2-d51c10524ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-19.827430725097656 -22.76061248779297\n"
          ]
        }
      ],
      "source": [
        "sings_correct = \"वह बहुत अच्छा गाता है।\"\n",
        "sings_incorrect = \"वह बहुत अच्छा घाता है।\"\n",
        "\n",
        "\n",
        "correct_score = model.score(sings_correct)\n",
        "incorrect_score = model.score(sings_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First one is right and we get better score for first sentance"
      ],
      "metadata": {
        "id": "XZEn4ByJMRrY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43gXFE7Sg8kU",
        "outputId": "86667dff-df12-4421-d17b-1d376ffebb01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.2548329\t<s> दोनों ही झल्लाये\n",
            "-0.2760634\t<s> चौधरी के अशुभचिंतकों\n",
            "-0.04973512\tडालियों पर बैठी शुकमंडली\n",
            "-0.07060567\tमनुष्यों को उन्हें बेमुरौवत\n",
            "-0.049646165\tऔर कड़क कर बोलेमेरी\n",
            "-0.04038189\tनिराश हो कर कहानहीं\n",
            "-0.08863469\tपड़ते ही वह अव्यवस्थितचित्त\n",
            "-0.19321889\tदोनों पक्षों से सवालजवाब\n",
            "-0.051110353\tझगड़ू साहु ने कहासमझू\n",
            "-0.20675866\tकरें तो उनकी भलमनसी\n",
            "-0.04876329\tनीति को सराहता थाइसे\n",
            "-0.06436408\t<s> मित्रता की मुरझायी\n",
            "-0.23735626\tकी गहराई से उपजतें\n",
            "-0.17502813\tपूर्णता की ओर बढातें\n",
            "-0.18197767\tजहाँ से अच्छा हिन्दोसिताँ\n",
            "-0.04437429\tहैं इसकी यह गुलसिताँ\n",
            "-0.06926097\tसंतरी हमारा वह पासबाँ\n",
            "-0.09434804\tजिनके दम से रश्कएजनाँ\n",
            "\n",
            "\\end\\\n"
          ]
        }
      ],
      "source": [
        "# inspect the last 20 lines inside the LM source\n",
        "!tail -20 language_model_3p0.arpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQA6huWockMP"
      },
      "outputs": [],
      "source": [
        "# some useful KenLM commands for future reference\n",
        "# generate binary\n",
        "# !kenlm/build/bin/build_binary dataset_tokenized_3gram.arpa dataset_tokenized_3gram.binary\n",
        "# create a new LM\n",
        "# !kenlm/build/bin/lmplz -o 3 --text dataset_tokenized.txt --arpa dataset_tokenized_3gram.arpa --discount_fallback\n",
        "# !tail -20 dataset_tokenized_3gram.arpa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGlHlhrffpHT"
      },
      "source": [
        "### 1.3 Integrating the LM with Whisper\n",
        "\n",
        "We have modified the decoder of whisper to allow for deep/shallow fusion and exposed it to be  expermented for the performance  via beam and greedy search approach for LM integration.\n",
        "\n",
        "Below we would be downloading the whisper code modified to be tested here ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKmnxRsofoXu",
        "outputId": "b9938565-d8e9-4d25-e8c4-7262cabc01c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m7.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m963.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=799894 sha256=5cd706d6cdee8f6830cf056e88a1d63ee3addf9ed9f5475756fcf6de1929ec39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wakv1z_z/wheels/7e/59/d2/1662a1f0ae2217e2cd01935b4ac823b4eade5c382bed87a164\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=e3f1120ba7d88a2773bd61ab328bf198c9f34c030eacff15beb2c74d23a483f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai-whisper\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28qXwUAIhQmA"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import kenlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h061i7Dhaeq",
        "outputId": "d6884838-d9bf-4a41-bef8-d78b259d8cfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 112MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWRBxk5khiKQ",
        "outputId": "a95ab83a-f2f9-4e97-cd17-cfa061aa7d15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\n",
            "To: /content/sample.wav\n",
            "100%|██████████| 197k/197k [00:00<00:00, 77.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOZKw5wGlNWm"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd1uG_bTTeSC"
      },
      "outputs": [],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDH0eYJ8TkU4"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmbBreqNX3IX"
      },
      "source": [
        "### 1.4 Baseline Whisper Transcription\n",
        "Without nbest or LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LFz_dwKdlXyR",
        "outputId": "37969971-4d76-4717-f7c7-53447af2d18c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uew0igzbYPO"
      },
      "source": [
        "##### 1.4.1 Decoding with LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wAsYJNj3blQO",
        "outputId": "222b37f8-62be-4e2b-b86a-c7b1917097c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:04<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding the LM\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVX9bKV9BaR"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=5,\n",
        "        patience=1.0, lm_path=\"/content/language_model_3p0.bin\", lm_alpha=1.0, lm_beta=0.0,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "decoding_withLM = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BPtkRefB-FUv",
        "outputId": "7bd1f8b6-1eb1-4066-f59d-95a6917af9aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoding_withLM.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzCM2xRb28i"
      },
      "source": [
        "##### 1.4.2 Decoding with nbest (beam search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF6AnpXkb5XM",
        "outputId": "a314a338-bb04-440b-c8ff-48efabf24b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45291578358617324\n",
            "ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45523316981428763\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है. -0.47296941078315347\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं -0.48318856449450476\n",
            "ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है -0.46669308344523114\n"
          ]
        }
      ],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "nbest = whisper.decode(model, mel, options)\n",
        "\n",
        "\n",
        "for candidate in nbest:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J38npjnkcDW7"
      },
      "source": [
        "##### 1.4.3 Adding LM rescoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23wLneazBit1",
        "outputId": "072daaa5-d1c2-4466-fa8d-f91450ef2d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(lm_model.order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAdRnI_UBzWJ",
        "outputId": "44cedf0d-4d24-4c0d-fdfe-6cd16a271c6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45291578358617324,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45523316981428763,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.',\n",
              "  -0.47296941078315347,\n",
              "  -44.10427474975586),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं',\n",
              "  -0.48318856449450476,\n",
              "  -37.30411148071289),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.46669308344523114,\n",
              "  -37.54087829589844)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "nbest_with_lm_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUBQ-WVCCH1N",
        "outputId": "7b430fe5-3f6c-4549-a8a0-955bf8efc6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8135461623093178),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8158635485374321),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है', -0.8421018664042155),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं', -0.8562296793016337),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.', -0.9140121582807121)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh5OtW5kz7gU"
      },
      "source": [
        "##### 1.4.4 Decoding with nbest (best of N hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rof-6s_mykVX"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, best_of=10, return_nbest=True, without_timestamps=True, temperature=0.3, language=\"hi\")\n",
        "nbest_best_of_n_hyp = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuDcmFH106lC",
        "outputId": "cded2418-b2e9-4e0f-c99f-a6d14937f715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45742596898760113\n",
            "ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है -0.5202431113032971\n",
            "ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है -0.5065439448637121\n",
            "ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey. -0.9538334877260269\n",
            "ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है -0.5101523081461589\n",
            "ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है -0.4865361798194147\n",
            "ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है -0.49694071144893254\n",
            "ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है -0.5291237149919782\n",
            "ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है -0.5426437135726686\n",
            "ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है -0.49345003325363684\n"
          ]
        }
      ],
      "source": [
        "for candidate in nbest_best_of_n_hyp:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOXOEofa2ZAe",
        "outputId": "980fca20-e1d0-4608-9c31-8ed779ab9a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45742596898760113,\n",
              "  -35.82866668701172),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है',\n",
              "  -0.5202431113032971,\n",
              "  -49.43550491333008),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -0.5065439448637121,\n",
              "  -54.91597366333008),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -0.9538334877260269,\n",
              "  -81.96270751953125),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है',\n",
              "  -0.5101523081461589,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.4865361798194147,\n",
              "  -46.603515625),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है',\n",
              "  -0.49694071144893254,\n",
              "  -49.201133728027344),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है',\n",
              "  -0.5291237149919782,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.5426437135726686,\n",
              "  -42.747047424316406),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है',\n",
              "  -0.49345003325363684,\n",
              "  -50.678977966308594)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest_best_of_n_hyp]\n",
        "nbest_with_lm_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIuqEbJ-2d-k",
        "outputId": "bb2afb82-8baa-45ec-a4cd-c152175916cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8157126358577182),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.9525713360694148),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.9701141878158327),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है', -0.976416384379069),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है', -0.9889520487292061),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है', -0.9953877912248883),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है', -1.0002398129167227),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है', -1.014598160436598),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -1.0557036814970129),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -1.7734605629213394)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores_bestofNSampling = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores_bestofNSampling.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores_bestofNSampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcAl6kVkuSSw"
      },
      "source": [
        "#2 ***Demonstration of Fusion of Fine tuned Whisper-LM ***\n",
        "\n",
        "Till this point , we have successfully accomplished two critical phases in our project: Firstly, fine-tuning the Whisper model on our specific dataset, and secondly, preparing Whisper for language model (LM) integration, followed by thorough testing of this integration. We are now poised to amalgamate these advancements to formulate our finalized model.\n",
        "\n",
        "## The next sections include:\n",
        "- Importing a finetuned huggingface model to our codebase\n",
        "- Running the evaluation of the 4 decoding variants on the imported dataset\n",
        "- Computing the WER and CER for each of the decoding variants\n",
        "\n",
        "## The decoding strategies are:\n",
        "1. baseline decoding without LM\n",
        "2. Deep fusion of the LM with the token probabilities during beam search decoding\n",
        "3. Shallow fusion by rescoring the N best candidates generated through beam search\n",
        "4. Shallow fusion by rescoring the N best candidates generated through greedy decoding using best of N sampling\n",
        "\n",
        "(Our current focus involves conducting a series of experiments to ascertain the optimal decoding strategies approached on a designated test subset. Upon identifying the most effective approach based on WER performance metrics, we will proceed to fine-tune the hyperparameters specific to best approach, aiming to achieve the most efficient and accurate outcomes.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Download required libraries"
      ],
      "metadata": {
        "id": "UxGmYTTjUVs8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRMuGzF1WX8",
        "outputId": "b5d357e2-75de-4ba2-f8f6-3c0d3a56fc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m7.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=799899 sha256=4f3e5c2779b1175e0b322a103f5e3bac7ef60f3cc469ef82da3add3dbb2ec7b1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-562wxpom/wheels/7e/59/d2/1662a1f0ae2217e2cd01935b4ac823b4eade5c382bed87a164\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=da4957485c3286a3da565a4e53271c75da691c94e345e4983efb6225e58bf3a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m744.8 kB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184304 sha256=cefb05a05fc9f2cf4151a9c8e9800719642fb27e41b9e3fd5fa07864c9fdde43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f43vc9_8/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-5pur_c7o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-5pur_c7o\n",
            "  Resolved https://github.com/huggingface/transformers to commit 7b6324e18ee1b43d130a381fedddeb2b544e9e1a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.36.0.dev0-py3-none-any.whl size=8119958 sha256=494a4b3790c0e6f6f5b6b703eea004bced8b47e883ef9959f0cfd80d2e9f8c4a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p6tzhh4e/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.0.dev0\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.5.2\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.7.1-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=ebe1eff2dc11e23db7f8e161ba4c15753ac828e15fdf087897f3ead22ead3578\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.7.1 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 orjson-3.9.10 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ],
      "source": [
        "#Downloading the required libraries\n",
        "\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install transformers\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "# !pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Otxfl9LTGNej",
        "outputId": "6f09bf9f-fc73-441f-ec47-1584c5c16811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 156MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'language_model_3p0.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXpUd4OoS3y"
      },
      "source": [
        "###2.2 We prepare our  whisper model finetune with batches of hindi dataset to be integrated with LM .\n",
        "\n",
        "We have trained the model and pushed to hugging face platform . We would be downloading from there and integrate with our updated whisper with custom decoder ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d9dbfbf1620d49a697c7176bf80071b3",
            "0b993933e17b4ec685c97e33ca92893a",
            "11c5ffddb2774d39af67ce808ea80171",
            "dfdd9f91092a40b48296d247c12812a0",
            "d46ed3c9f09a43f1979be4ba973af7e8",
            "91184721dd1a4fa5a3f0604623d885fb",
            "020a541beaa34c9e8a6fa0e7695360fb",
            "4f0d7b6125a5412f9fa9c52075690351",
            "6c943bdc937c4ca29fc3ebfcf2ba8764",
            "9a4e80a53fa04db49f877012e056c57f",
            "d3af644b6fb24a578f820e174a776dda"
          ]
        },
        "id": "kMDX0Asjuc4e",
        "outputId": "3592bb49-ceae-4da5-ee06-3bf97b0677d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9dbfbf1620d49a697c7176bf80071b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/pytorch_model.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Download the model\n",
        "\n",
        "import whisper\n",
        "import kenlm\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "import torch\n",
        "import jiwer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "# using pickle to serialize the map_dict\n",
        "import pickle\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "filename = \"pytorch_model.bin\"\n",
        "\n",
        "\n",
        "#hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-firefox\", filename=filename, local_dir=\"/content/\")\n",
        "#hf_hub_download(repo_id=\"sanchit-gandhi/whisper-small-hi\", filename=filename, local_dir=\"/content/\")\n",
        "hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-graminVoice\", filename=filename, local_dir=\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3vqObGaMSt9"
      },
      "outputs": [],
      "source": [
        "##We define function to import the model after doing some validation checks ex: state dictionary of model .\n",
        "\n",
        "# to enable verbose printing of exceptions (+ layers matching name)\n",
        "DEBUG = True\n",
        "\n",
        "# set to True if your custom model has been trained using DDP (multi-gpu)\n",
        "# as in my case, in the custom HF model, keys have a prefix (model.)\n",
        "# it should come from the fact that I have trained on a milti-gpu machine, using DDP\n",
        "DDP_TRAINED = True\n",
        "\n",
        "# if DDP we have to add a prefix to match with the HF state_dict\n",
        "if DDP_TRAINED:\n",
        "    PREFIX = \"model.\"\n",
        "else:\n",
        "    PREFIX = \"\"\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "# the device where you're running this code\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# the name of the file with your fine-tuned model\n",
        "FINETUNED_MODEL = \"pytorch_model.bin\"\n",
        "\n",
        "# the name of the file for the serialized map_dict\n",
        "# a different name, to avoid overwrite it\n",
        "FILE_DICT = MODEL_SIZE + \"_map_dict05.pkl\"  ## rename this filename from map_dict05.pkl to something else like  map_dict06.pkl , in case you run it again and again as already the model would be stored with this filename and an error with referring to model might occur\n",
        "\n",
        "def import_hf_model(finetuned_model, model_size, device, file_dict, debug=True):\n",
        "\n",
        "  def has_numbers(inputString):\n",
        "      return any(char.isdigit() for char in inputString)\n",
        "\n",
        "  # next functions are used to make sanity checks for the mappings\n",
        "\n",
        "  # get if it is encoder or decoder\n",
        "  def extract_function(key_name):\n",
        "      # encoder or decoder is the first part of the key\n",
        "      first_part = key_name.split(\".\")[0]\n",
        "\n",
        "      key_func = None\n",
        "      if first_part in [\"enconder\", \"decoder\"]:\n",
        "          key_func = first_part\n",
        "\n",
        "      return key_func\n",
        "\n",
        "  def extract_layer_num(key_name):\n",
        "      # layer num is the third piece\n",
        "      layer_num = None\n",
        "\n",
        "      if has_numbers(key_name):\n",
        "          layer_num = key_name.split(\".\")[2]\n",
        "\n",
        "      return layer_num\n",
        "\n",
        "  # check that the two keys are for layers\n",
        "  # with the same function\n",
        "  # (both encoder or both decoder)\n",
        "  # and have the same layer number\n",
        "  # this way we are super-safe (I think)\n",
        "  def sanity_check(key1, key2):\n",
        "      is_ok = True\n",
        "\n",
        "      # check same func (encoder or decoder)\n",
        "      func1 = extract_function(key1)\n",
        "      func2 = extract_function(key2)\n",
        "\n",
        "      if func1 != func2:\n",
        "          print(f\"Warning: layers seem to have different functions: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      # check same layer_num\n",
        "      layer1 = extract_layer_num(key1)\n",
        "      layer2 = extract_layer_num(key2)\n",
        "\n",
        "      if layer1 != layer2:\n",
        "          print(f\"Warning: layers seem to have different numbers: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      return is_ok\n",
        "\n",
        "  if not os.path.isfile(file_dict):\n",
        "    # Vanilla means: not custom trained\n",
        "    print()\n",
        "    print(\"Loading vanilla Whisper model\")\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "    print(\"Loading vanilla HF Model\")\n",
        "    hugging_face_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        \"openai/whisper-\" + model_size\n",
        "    ).to(device)\n",
        "\n",
        "    # extract state-dict from both\n",
        "    state_d_openai = model.state_dict()\n",
        "    state_d_huggingface = hugging_face_model.model.state_dict()\n",
        "\n",
        "    # build the mapping between keys...\n",
        "    map_dict = {}\n",
        "    print(\"Matching layers...\")\n",
        "\n",
        "    # for every layer in OpenAI model\n",
        "    n_sanity_ok = 0\n",
        "\n",
        "    #\n",
        "    # here we're considering the cartesian product of the two state dict and try to match\n",
        "    # rules applied:\n",
        "    # 1. the two layers have the same shape\n",
        "    # 2. the two layer have the same parameters' values\n",
        "    # 3. we apply sanity check (see function above)\n",
        "    #\n",
        "    for k in tqdm(state_d_openai):\n",
        "        # find a layer in the HF model, check with j\n",
        "        for j in state_d_huggingface:\n",
        "            # where parameters have same shape and same values\n",
        "            if state_d_huggingface[j].shape == state_d_openai[k].shape:\n",
        "                if torch.all(torch.eq(state_d_huggingface[j], state_d_openai[k])).item():\n",
        "                    # found, register the mapping\n",
        "                    map_dict[k] = j\n",
        "                    # make some check and eventually print a warning\n",
        "                    if sanity_check(k, j) == True:\n",
        "                        n_sanity_ok += 1\n",
        "\n",
        "                        # if you enable thsi print you can see the name of the layer\n",
        "                        # chosen in the match and you will se that they have the same functions\n",
        "                        if debug:\n",
        "                            print(k, j)\n",
        "\n",
        "                    break\n",
        "\n",
        "\n",
        "    # check if we have matched every entry\n",
        "    print(\"Check if we have matched every entry in state_dict...\")\n",
        "    print()\n",
        "    print(f\"Number of keys: {len(map_dict.keys())}\")\n",
        "    assert len(map_dict.keys()) == len(state_d_openai.keys()), \"The match is not complete !\"\n",
        "\n",
        "    print(f\"Number of sanity_check ok: {n_sanity_ok}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Match is complete !!!\")\n",
        "    print()\n",
        "\n",
        "\n",
        "    # serialize the map_dict to file\n",
        "    print(\"Serializing map_dict...\")\n",
        "\n",
        "    with open(file_dict, \"wb\") as f:\n",
        "        pickle.dump(map_dict, f)\n",
        "        f.close()\n",
        "\n",
        "    print(f\"map_dict saved as: {file_dict}...\")\n",
        "    print()\n",
        "\n",
        "  else:\n",
        "    # loading with match keys\n",
        "    # restart from pickle file\n",
        "    print(\"Reloading map_dict...\")\n",
        "    print()\n",
        "    with open(file_dict, \"rb\") as f:\n",
        "        map_dict = pickle.load(f)\n",
        "\n",
        "  # loading fine-tuned dict\n",
        "  print(\"Loading fine tuned dict...\")\n",
        "\n",
        "  # added map_location to handle the fact that the custom model has been trained on GPU\n",
        "  state_dict_finetuned = torch.load(finetuned_model, map_location=torch.device(device))\n",
        "\n",
        "  print(state_dict_finetuned.keys())\n",
        "  # build the state_dict to be used\n",
        "  # take the key name from standard (OpenAI) and the value from finetuned (HF)\n",
        "  print(\"Rebuild the state dict...\")\n",
        "  new_state_dict = {}\n",
        "  n_except = 0\n",
        "  for k in tqdm(map_dict.keys()):\n",
        "      try:\n",
        "        # You must add \"model.\" if you have used DDP in custom training\n",
        "        # see DDP_TRAINED above\n",
        "        # PREFIX is added to a HF fine-tuned 8with DDP). It is not in vanulla HF models\n",
        "        new_state_dict[k] = state_dict_finetuned[PREFIX + map_dict[k]]\n",
        "      except Exception as ex:\n",
        "        n_except += 1\n",
        "\n",
        "        if debug:\n",
        "            print(\"exception\")\n",
        "            print(PREFIX + map_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  msg_err = f\"Rebuild state dict failed, {n_except} pick failed\"\n",
        "  assert n_except == 0, msg_err\n",
        "\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(\"Loading the final model...\")\n",
        "  model.load_state_dict(new_state_dict)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "6c4b754c910c4e82abaa9818cea25827",
            "5e057ed8e9d8483d82c22aa04eb1da6f",
            "aafd20e5307b4219ab68771ad64234b4",
            "4da88e6d50524d4687bc230b026c1b67",
            "3a25f187d31b481e81df928e5cece90f",
            "6b1c7db967fe4be4ba0bab6af503b48d",
            "587d9632dabb41afbcf4683a85beed57",
            "452c6d1dc5b443f98d6664ddea5fffff",
            "92e8fdc2f84b407a9459606a5361b3ff",
            "0e59633001d844518c7ff17b9520c58b",
            "f8a90c593ccc454fb452015581463c34",
            "fbdc1387613a4f98b8b3c7d47b499585",
            "8cb6909cca1340089a786e99b5eac46b",
            "e7f6cde221e34fb3bd7168dcbed88b95",
            "04c5aa8989d04b6db87c6d5d02c9fe31",
            "71c0515309114b64877f145a41d62f60",
            "32b1032f0a474cedabbfb2bff2837df9",
            "f2e76e8459e04ba6a7ba28f63a295cf6",
            "ba96771636574e2b902449dfd7a392ea",
            "3071cad79909425eb9c17d28b3f4c71e",
            "2e7ce1e867004d8bb604cf52db1d2cd2",
            "e2ac25180a7e43938a6830aeece0ed79",
            "474bd86cd7cc487abc15cb1bcb43fa8c",
            "0eba231871654fac92c5eab5c2d1b30f",
            "73f61a4eb15f485bb800a14a55ea3ff5",
            "7ede266ab2cf44eb9210c23f54304f13",
            "b9747e58922c49ffa248a94819d83a09",
            "2464cb6e239740c990cdaf257bcbeafc",
            "032282b431194fc89f6fb2523316bab1",
            "52da4d83c83e4ebcbff787f442c489a2",
            "e7adf0b5c6484c4d9779f64974b1acdb",
            "e21f1cb0e47b45639278811f9076e859",
            "49a3262a46de42b9b5cf66f1332b0c97"
          ]
        },
        "id": "gCxqmfBJvE__",
        "outputId": "97366de1-e5f8-4756-dda0-81c3dd2ce600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading vanilla Whisper model\n",
            "Loading vanilla HF Model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c4b754c910c4e82abaa9818cea25827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbdc1387613a4f98b8b3c7d47b499585"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.84k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "474bd86cd7cc487abc15cb1bcb43fa8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching layers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:01<00:00, 275.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if we have matched every entry in state_dict...\n",
            "\n",
            "Number of keys: 479\n",
            "Number of sanity_check ok: 479\n",
            "\n",
            "Match is complete !!!\n",
            "\n",
            "Serializing map_dict...\n",
            "map_dict saved as: small_map_dict05.pkl...\n",
            "\n",
            "Loading fine tuned dict...\n",
            "odict_keys(['model.encoder.conv1.weight', 'model.encoder.conv1.bias', 'model.encoder.conv2.weight', 'model.encoder.conv2.bias', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layer_norm.weight', 'model.encoder.layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layer_norm.weight', 'model.decoder.layer_norm.bias', 'proj_out.weight'])\n",
            "Rebuild the state dict...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:00<00:00, 1265955.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the final model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = import_hf_model(finetuned_model=FINETUNED_MODEL, debug= False, model_size=MODEL_SIZE, device=DEVICE, file_dict=FILE_DICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4eGVNxPC5U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19242bc9-0a97-48cd-81fb-f58040e4bced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Whisper(\n",
              "  (encoder): AudioEncoder(\n",
              "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): TextDecoder(\n",
              "    (token_embedding): Embedding(51865, 768)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (cross_attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "## Displaying  model architecture\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8536aa41d17347508a262bbc9693b7f8",
            "ba507efc55c145419acdec6f0fb62b2e",
            "f96cd823f757434997f49f4b2c7d2a04",
            "3f065f61e9e1443a85aee518670a4fa7",
            "ba67e8ff964d4073b870e1200a87fd4c",
            "ab9c06e19a154517b4ff46c7a52d29d4",
            "150486309a0540b0a51a96664f78aba7",
            "773b457557fd4352a317068d87fa4eef",
            "b805718a8b76423386511730e0fdeaff",
            "ab1471db6c574235ac5967dd80734786",
            "ff114fffeab840c6a8fab1662d1dddd7",
            "24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "e543d211badc4d41bd944df904ce0317",
            "d6ef36d77a09460d82ce46f28df66665",
            "c16fa1150d12439688fa21af50d995c7",
            "aed79d83bbe84ba5aa53f601588c4ee8",
            "28b858b805f54292a322d13611833c33",
            "7d5806a46c454e0c9c3f1ca5f70d4279",
            "455bae593a3240d9ba064c213a90ece9",
            "ba5939381af044029e254989149974db",
            "75a0a08417de42e88bdf8ffc693f42b6",
            "bb853deecb594dad80ae466afa531d75",
            "920da0787e654f6bb9a0c76cc88f0f5c",
            "bbb0d45741c8401b819941a9eda1c1a7",
            "b8b595673f6a4db4a47a25e88ebc2d4e",
            "981bc86f56014362942f1fad9d5fe00c",
            "a0f33f70e05d4897aac484cb940392d4",
            "4928327c81124c60bd8e3aca15942167",
            "7390656d2d4240969f6202876d1a57c7",
            "f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "273a08df24d343a7a227d09b9e23ebb4",
            "3dd766dafea94135862b6e9e0d9876cf"
          ]
        },
        "id": "rasFuIlSix6U",
        "outputId": "32a54d14-6a4d-4a6a-803d-dd495eb93801"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8536aa41d17347508a262bbc9693b7f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# #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\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGPaVW4glVi"
      },
      "source": [
        "###2.2  Preparing the Test Data. Below approach is followed:\n",
        "- We combine the unused data from common voice+IIITB+GraminVoice and form a test dataset .\n",
        "- Then , we use a subset of that unseen data to examine performance of Decoding startegies\n",
        "- Once the best strategy is found , we fine tune the hypermeter to use the best decoder approach with optimal params\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VwhKrCShjPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "87eb53498bc343dcbfd83a09b0dffabc",
            "f99611bb13cf48978f4528abe35c94ca",
            "8aaaa39b4ea7480180d87baba74d9f57",
            "6272a6a5629043eda1053d431274e311",
            "fef0b24d0dca40afb97fb1a7dfecda9c",
            "219f999ff1e94f459715a5d27a209889",
            "1eb6c7cc83e04ef28d3588aea44b8968",
            "3df54bd2301f48d38c3cd1ba57a8862b",
            "91e313e5d1c148249be2da0090fdadbb",
            "f1736f1f8f0746759724d1bf596c43ab",
            "bfdabc82cf3d4ee08de3b15eabee8683",
            "05cb9b0b58cc4958a1a0768ed5c0bf45",
            "9f4d4bac262c4647be909b8b99bcd80c",
            "2c3d02d94ab34bddb128b2054b0a7a06",
            "bdeba3611e0a4f5eb999ca74e0871df7",
            "7a317f9b94bb49b69edaa6a93231ddec",
            "261ceb3cf8c2433192c47829653e47bf",
            "22c9ab8413414a7b8152971d43cb6859",
            "60a7ea7bd571491d8ac144458d4c7250",
            "fc3bb2339b894e43adf92198cacbe7aa",
            "39079201a5704207b09282801a3f9ac8",
            "da1e977bfc7d45d08307e64ea191fddd",
            "07064292c8374a69874cef5799adeb58",
            "b048f0b5247d4eb18f2af761236b9697",
            "0b3aa4beac1c41d1be4e1b131f08c47b",
            "cef8a2e7e98c432fa7d77a090a56aad8",
            "c179f2c779ab45189d68fcc499df31fb",
            "087f6c3f571446edbd58375140e4e145",
            "4386a4e3defa430caa888ee9e2ff6175",
            "09a0ed0d39aa4991b453cd5a1f91a4e9",
            "d89d53a21c3948b1b7d9a36991439f67",
            "5c1fdc97875f4ad58d714a2c8b6d4268",
            "fad1ebded3794fb6bd3c7966f6b23b5b",
            "00118bd7f6a34c4cbd607eca312e413d",
            "616c5731cf374615b9a94d0333d1982a",
            "32897cad5b2d4592820e1a86bc1e72c8",
            "f547ce81afab403a8c1ab01ad6e82318",
            "7994120056a74fe4bc219a8f78b1740a",
            "cea200594f1b4291a74eebf7bd1e6fc9",
            "c7958d371e1144a7a4b67fea63fc934d",
            "bebf678d96964ccab9cb17a36a4f5ac9",
            "04fce5d2833e421683b8328e395bd301",
            "bc062c4900374d2bafc7f90d7b3da848",
            "b4e25b4c8370487db868604b5f53c8ae",
            "1d24f54fef5c4ad9963147941eb2f69c",
            "ffe1b371614c4a5ba639ec7c171d2e5f",
            "71f00ab808fd4216a62d614086fe051f",
            "3ae501affe274bfa8c6d26f06095e200",
            "7ffd3c08117249bda123e7e7dcd88e06",
            "9986fa2d15964d28898a999386dc2f5f",
            "2aa7c8d3874947e2b91f66d21156ad2e",
            "9bf4ecf375db423ab1f6f0cedfc24f11",
            "cbc7dff7162d4001b5964fa6e220cc95",
            "d18a1b07b3cb4a20ac612258ad3d6c20",
            "e7c95420e4524c17bac3c0a8ff99b025",
            "8a7129fb3759426caf0594b784343c3d",
            "172c631c808a498189335756360f9a24",
            "d1181ccb86724ff2ada86c4153fa6f74",
            "3a56f5099a294e8da9750d22001cae3f",
            "230facabdb1849c2a4fde6c91fb97702",
            "910f883c0bbb42999d61d956db2b7e52",
            "9ab78da65bd747b885561af5840edc0d",
            "6f9d9157e87448c7b522015d2b5e3493",
            "4b0cedcdd5484a06aec442aa3030390d",
            "6d2f237c1ee14a2c9ca6fa92858a73b7",
            "48a7fd0dcaa84a40adefc955353aa20e",
            "aaf6d9d7bcb74b5d9ee1a0a73da49e5c",
            "99ad30c7759f491c95b3e3686e9b3071",
            "60732c3ac6c4402fa8731f9a708e9200",
            "af4dbf58e83a440f9442dd4e4f034863",
            "5d01dd31f18f4638ba0bb425e2d743ab",
            "71d2d28fcc184059b0a24eba3b680e81",
            "94f2c41a7d6a4216b68d2622b90bd716",
            "8d123379f7274e46ab6f4a5b756a3d94",
            "2309f10ace0043e8bc236cc39497dc5c",
            "fc24501c7cbc4b689918ee10fcb2ed73",
            "274c71e215974fa9862eecf3b1316a58",
            "a9c004db91c14668b6088f46bf4a5713",
            "fa07060e87d241e3a0bc72c88ce972d1",
            "c5e366786d5a48c28ca6aef685b170d6",
            "14979eeec8fe4f958f624abe2e412d1c",
            "92e48ad23618430e8ba1c14e7b4be4bd",
            "0e8e7dcd3b73497c8192e3b825f2a1ab",
            "94386c405bac4094b5403dc6d2089ad7",
            "78a0f45790704bddb20e0fc6cc021dc7",
            "c69acf080f82494684b13bc5c84452df",
            "4af3e5b75b1748fa8303a0ba7174f004",
            "d7cfa195350146dab26f287393dcbfdf",
            "c2f0e7459b3f4518acd80910b02afbed",
            "4589c89b3e384b3aab6affcb4b5a9646",
            "1863f9c325f541a0931687a706b629c4",
            "1bc5efda55e14142a5a41d30d94ed812",
            "06812d1505914993883714be78553c45",
            "544df24dd87b4fcfac0e72d2d2392ec3",
            "133f88f9c0354ca5b72f0d2b257bc066",
            "2fb5096705a14975aa572cf9fbf7c351",
            "3be399d6e661428b8894be3e24885d3e",
            "af47caeca8de46a4bc0c00d7bb801211",
            "7d0989dc083545c0a9359b8925e67718",
            "b224bd3a49f440609e72aca8de29027a",
            "be68a86b2dc54123b9f78ed758b03e8d",
            "478527a4b44045c4a40a10b9f6d14442",
            "90424414e2ef4d8f887e5210b7a36aa1",
            "75ec815dbc7b43d2907d12db3a69e8b7",
            "7c8d9bbfabe043a6a5a55fb4c7b44344",
            "3e868311faf3404ba92058692f423388",
            "215d8c849e5b489b9a988e09a8007c8b",
            "9e892f8799ce487bb72662b2ab072d9d",
            "3930002b623642e192df0c8a2f0bd9c6",
            "bcbf9018c3494890bf9b6071e6fa1eb4",
            "9a7eb09f2fec48d8a4d8b2eb5b446bfa",
            "1eb4a998c85d44668a03d278e107d24e",
            "4f47de6f12c04e4fb9f4f1d7033b12bb",
            "b954e1b5a2674aaf8c8e9f7b68028342",
            "ae2d94211b1640e98aaf13a6186ebca6",
            "5443dde30ac04b44b1a39df4f405ff07",
            "2f0f74eb25d94762babba0e46dc15509",
            "ee7e248ce43c46898151e6957b07105e",
            "249f126300b148b4862c4038a2e74ef9",
            "91f8c9822e68489aaf66d2a1ef4fbff1",
            "97f2557a8aff4fdba5b45b42c169c6a5"
          ]
        },
        "outputId": "d11c6927-1d84-496a-8420-22a476003264"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/12.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87eb53498bc343dcbfd83a09b0dffabc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating txt.done.data.utf8 split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05cb9b0b58cc4958a1a0768ed5c0bf45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/453M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07064292c8374a69874cef5799adeb58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d743cd0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00118bd7f6a34c4cbd607eca312e413d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d743cd0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d24f54fef5c4ad9963147941eb2f69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d7ce860>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a7129fb3759426caf0594b784343c3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d7cc910>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating other split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaf6d9d7bcb74b5d9ee1a0a73da49e5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d7ce980>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validated split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9c004db91c14668b6088f46bf4a5713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d7ce3b0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating invalidated split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2f0e7459b3f4518acd80910b02afbed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<datasets.download.download_manager.ArchiveIterable object at 0x7bac6d7ceb00>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/64.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b224bd3a49f440609e72aca8de29027a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating text split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a7eb09f2fec48d8a4d8b2eb5b446bfa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Prepare Test Data for calculating Wer and CER\n",
        "\n",
        "import datasets\n",
        "# import the load_dataset function\n",
        "from datasets import load_dataset\n",
        "\n",
        "# specify the URL directory and the data files\n",
        "# load the dataset from the URL directory\n",
        "\n",
        "\n",
        "datasets.config.DEFAULT_MAX_BATCH_SIZE = 10\n",
        "dataset_1 = load_dataset(\"datadownload_iith.py\") ##IIITB data\n",
        "dataset_2 = load_dataset(\"datadownload.py\") ### CV data\n",
        "dataset_3 = load_dataset(\"graminVoiceDatadownload.py\") ##GraminVoice data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the number of rows of audio\n",
        "dataset_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXPnPS-3AEXa",
        "outputId": "a367e078-d549-46a3-ab69-c61c55d55b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    txt.done.data.utf8: Dataset({\n",
              "        features: ['path', 'audio', 'sentence'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last_100_rows now contains the last 100 rows of the dataset , these are unseen data .\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 1000  # total number of rows in the dataset\n",
        "start_index = num_rows - 100\n",
        "\n",
        "# Select the last 100 rows\n",
        "dataset_1_last_100_rows = dataset_1['txt.done.data.utf8'].select(range(start_index, num_rows))\n",
        "\n"
      ],
      "metadata": {
        "id": "S_m018srYKIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the number of rows of audio\n",
        "dataset_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB8KANPKX_Dp",
        "outputId": "9cb10d8d-d670-4c9a-ffe5-bfff36b4ae33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 4630\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 3072\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 2416\n",
              "    })\n",
              "    other: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 3767\n",
              "    })\n",
              "    validated: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 10173\n",
              "    })\n",
              "    invalidated: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_2=dataset_2.remove_columns(['client_id', 'path', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment'])"
      ],
      "metadata": {
        "id": "E6HMA0vFYSqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last_100_rows now contains the last 100 rows of the dataset , these are unseen data .\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 100  # total number of rows in the dataset\n",
        "start_index = 0\n",
        "\n",
        "# Select the last 100 rows\n",
        "dataset_2_first_100_rows = dataset_2['test'].select(range(0, num_rows))\n",
        "\n"
      ],
      "metadata": {
        "id": "GJshdLvxYTpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the number of rows of audio\n",
        "dataset_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aSZRHLUYCnO",
        "outputId": "b61ddcc1-f2d4-42f9-c2be-2a01559435e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    text: Dataset({\n",
              "        features: ['path', 'audio', 'sentence'],\n",
              "        num_rows: 1032\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3=dataset_3.remove_columns(['path'])"
      ],
      "metadata": {
        "id": "XpSfUaWxYZ7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last_100_rows now contains the last 100 rows of the dataset , these are unseen data .\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "# Calculate the start index for the last 75 rows\n",
        "num_rows = 1032  # total number of rows in the dataset\n",
        "start_index = num_rows - 100\n",
        "\n",
        "# Select the last 100 rows\n",
        "dataset_3_last_100_rows = dataset_3['text'].select(range(start_index, num_rows))\n",
        "\n"
      ],
      "metadata": {
        "id": "fiBWaQ7zYb0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combined_dataset = datasets.concatenate_datasets([dataset[\"train\"],dataset[\"validation\"],dataset[\"test\"], dataset[\"text\"],dataset[\"txt.done.data.utf8\"]])\n",
        "combined_dataset = datasets.concatenate_datasets([dataset_1_last_100_rows,dataset_2_first_100_rows,dataset_3_last_100_rows])"
      ],
      "metadata": {
        "id": "zWv8x_mtYjNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have combine test data from three sources . We split them into two sections one for examining the best decoding approaches , fine tuning hyper paramaters for the same [finetune_parmaters_split_dataset] and another for calculating final WER on the unseen data using the decoding strategy [test_wer_split_dataset]"
      ],
      "metadata": {
        "id": "PX1jzKw-Xkrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, load_metric\n",
        "\n",
        "# Define the split ratios\n",
        "\n",
        "test_wer_split = 0.90  # 80% of the data\n",
        "finetune_parmaters_split = 0.10  # 10% of the data\n",
        "\n",
        "# Compute the number of samples for each split\n",
        "num_samples = len(combined_dataset)\n",
        "num_train = int(test_wer_split * num_samples)\n",
        "num_test = num_samples - num_train# Remaining 10%\n",
        "\n",
        "# Split the combined dataset\n",
        "test_wer_split_dataset = combined_dataset.select(indices=list(range(num_train)))\n",
        "finetune_parmaters_split_dataset = combined_dataset.select(indices=list(range(num_train , num_samples)))\n",
        "\n",
        "# If you want to organize the split datasets in a DatasetDict for convenience:\n",
        "split_test_datasets = DatasetDict({\n",
        "    'test': test_wer_split_dataset,\n",
        "    'finetune': finetune_parmaters_split_dataset\n",
        "})\n",
        "\n",
        "# Verify the resulting datasets\n",
        "print(f'Train Dataset: {len(test_wer_split_dataset)} samples')\n",
        "print(f'Test Dataset: {len(finetune_parmaters_split_dataset)} samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9hr4teTYulj",
        "outputId": "21e79366-521e-401c-fcb7-f101058e4b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: 270 samples\n",
            "Test Dataset: 30 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(split_test_datasets[\"finetune\"][1])\n",
        "print(split_test_datasets[\"test\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4Ag7em_Y_yA",
        "outputId": "5424c3da-ddef-4d9f-8159-2fd56b1f7fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'path': None, 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/67adca250279545403eae99b65a109a483020c860a12cc08a2c28c0cced51612/GV_Eval_3h/GV_Eval_3h/ZAudio/13-00155-06.mp3', 'array': array([-7.70203769e-06, -1.28522515e-07,  9.58610326e-06, ...,\n",
            "       -6.63560422e-06, -4.93867992e-06, -2.25788426e-06]), 'sampling_rate': 48000}, 'sentence': 'झारखण्ड में पिछले तीन चार दिनों से लगातार हो रही बारिश हो रही बारिश ने कई जिलों में काफी नुकसान पहुंचाया है ट्रेनें ट्रेनें सबसे प्रभावित हुई हैं', 'client_id': None, 'up_votes': None, 'down_votes': None, 'age': None, 'gender': None, 'accents': None, 'variant': None, 'locale': None, 'segment': None}\n",
            "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/b04225ba888d70832ffbdb4d63bbd8cba1570bdc3f400381ab06935ecb524fd9/iiit_hin/iiit_hin/Zwav/hin_0902.mp3', 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/b04225ba888d70832ffbdb4d63bbd8cba1570bdc3f400381ab06935ecb524fd9/iiit_hin/iiit_hin/Zwav/hin_0902.mp3', 'array': array([-1.85008743e-03, -2.78993463e-03, -3.55325127e-03, ...,\n",
            "        3.96938762e-04,  2.01676099e-04,  6.67182903e-05]), 'sampling_rate': 48000}, 'sentence': 'इस पर्वत पर एक सुंदर मंदिर बना हुआ', 'client_id': None, 'up_votes': None, 'down_votes': None, 'age': None, 'gender': None, 'accents': None, 'variant': None, 'locale': None, 'segment': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct the sampling rate from 48Khz to **16Khz**"
      ],
      "metadata": {
        "id": "Wm50URNVlxld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Audio\n",
        "\n",
        "split_test_datasets = split_test_datasets.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "id": "CY5ESBkfTdBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5Zpz_I3qpQM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class customDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
        "    It will drop the last few seconds of a very small portion of the utterances.\n",
        "    \"\"\"\n",
        "    original_sample_rate = 48000  # 48kHz\n",
        "    target_sample_rate = 16000    # 16kHz\n",
        "\n",
        "    def __init__(self, dataset, device=DEVICE):\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
        "        # assert sample_rate == 16000\n",
        "        # audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
        "        # mel = whisper.log_mel_spectrogram(audio)\n",
        "        audio = self.dataset[item]['audio']\n",
        "        sentence = self.dataset[item]['sentence']\n",
        "        path = audio['path']\n",
        "        # original_sample_rate = 48000  # 48kHz\n",
        "        # target_sample_rate = 16000    # 16kHz\n",
        "        # resample_audio(path, path, original_sample_rate, target_sample_rate)\n",
        "        array = audio['array']\n",
        "        sampling_rate = audio['sampling_rate']\n",
        "        audio = whisper.load_audio(path)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "        return (mel, sentence)\n",
        "\n",
        "dataset = customDataset(split_test_datasets[\"finetune\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3 Functions of diferent decoding staregies . We have provided comments for their usage along with params explanation"
      ],
      "metadata": {
        "id": "MKpV_pw2YWMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comYI3DN-Ff_"
      },
      "outputs": [],
      "source": [
        "def decode_baseline(model, mel, beam_size):\n",
        "  \"\"\"\n",
        "    This function performs the transcription with Whisper to provide a baseline without LM fusion\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decode_deep_fusion(model, mel, beam_size, lm_path, lm_alpha):\n",
        "  \"\"\"\n",
        "    This function performs the deep fusion of the LM with Whisper during the beam search decoding step\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_alpha: A numerical value representing the weight assigned to the language model scores during deep fusion.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=beam_size,\n",
        "        patience=0.7, lm_path=lm_path, lm_alpha=lm_alpha, lm_beta=0.1,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "eeTv2yWQY4f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decode_shallow_fusion_beam_search(model, mel, beam_size, lm_path, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful for inspecting the outputs with different lm_weights for finding the optimal value for lm_weight\n",
        "\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "    nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "    combined_score = [(text, (whisper_score) + (lm_score*lm_weight), (whisper_score), (lm_score)) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "    combined_score.sort(key=lambda t: t[1], reverse=True)\n",
        "    combined_scores.append(combined_score)\n",
        "\n",
        "\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = []\n",
        "  for datapoint in combined_scores:\n",
        "    combined_score = datapoint[0]\n",
        "    hyp, comb_score, w_score, lm_score = combined_score\n",
        "    result.append(hyp)\n",
        "  # result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "6Kx2eqBEY64c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_shallow_fusion_nbest(model, mel, best_of, lm_path, temperature, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (greedy decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - best_of: An integer specifying the number of best hypotheses to consider during decoding.\n",
        "    - lm_path: A string representing the path to the language model used for fusion.\n",
        "    - temperature: A numerical value indicating the temperature parameter used during sampling. Higher temperature corresponds to more variation in the n best list\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful when finding the optimal value for the lm_weight\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, best_of=best_of, return_nbest=True, without_timestamps=True, temperature=temperature, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "        nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "        normalized_scores = [(text,\n",
        "                              whisper_score / len(text.split()),\n",
        "                              lm_model.score(text) / len(text.split()))\n",
        "                             for text, whisper_score, _ in nbest_with_lm_score]\n",
        "        combined_score = [(text,\n",
        "                           (whisper_score ** 2) + (lm_weight * lm_score ** 2),\n",
        "                           whisper_score,\n",
        "                           lm_score)\n",
        "                          for text, whisper_score, lm_score in normalized_scores]\n",
        "        combined_score.sort(key=lambda t: t[1], reverse=False)\n",
        "        combined_scores.append(combined_score)\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = []\n",
        "  for datapoint in combined_scores:\n",
        "    combined_score = datapoint[0]\n",
        "    hyp, comb_score, w_score, lm_score = combined_score\n",
        "    result.append(hyp)\n",
        "  # result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result"
      ],
      "metadata": {
        "id": "CklLtkFkD8dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4 ***Decoding with Default whisper and note down its WER  ***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6NqXssrHIOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxKrxNhWGxh2",
        "outputId": "195d3573-ba8e-40d3-cd4e-34ec48479cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231106)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# Load the model whisper small model\n",
        "model_orignal_whisper = whisper.load_model(\"small\")  # Choose model size as needed\n",
        "\n",
        "# for mel, text in tqdm(loader):\n",
        "#     # results = model.decode(mels, options)\n",
        "#     # hypotheses.extend([result.text for result in results])\n",
        "#     result = decode_baseline(model_orignal_whisper, mel, beam_size) # Is this okay ?\n",
        "#     hypotheses.extend(result)\n",
        "#     references.extend(text)\n",
        "\n",
        "# Transcribe each audio file\n",
        "# Initialize empty lists for hypotheses and references\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# Transcribe each audio file\n",
        "for index in range(len(split_test_datasets[\"finetune\"])):\n",
        "    # Get the path to the audio file\n",
        "    #print(index)\n",
        "    audio_file_path = split_test_datasets[\"finetune\"][\"audio\"][index][\"path\"]\n",
        "    #print(audio_file_path)\n",
        "    # Transcribe the audio file\n",
        "    result = model_orignal_whisper.transcribe(audio_file_path, language=\"hi\")[\"text\"]\n",
        "    # Append the transcription (hypothesis) and the reference\n",
        "    hypotheses.append(result)\n",
        "    references.append(split_test_datasets[\"finetune\"][\"sentence\"][index])\n",
        "\n",
        "baseline_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "baseline_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "ziq2kz42FD8R",
        "outputId": "890302e0-44b7-4db2-f657-06459f499738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0    दीपक कुमार आरे मुँगीर मोबाईवानी के माधिल से ब...   \n",
              "1    तकन में पिष्ले तींचाज लिनो से लगतार हो रही भा...   \n",
              "2    बीज पोरीवाले इस मैज की तारीख से नाराज है बीची...   \n",
              "3    इसका खामयाज खामयाजा हम लोग तो भुगती रहे हैं स...   \n",
              "4    अद्रूक्ने लागा तो लोग समाज लगतार बड़ाव लाने म...   \n",
              "5    शुषे राखम लेग तीटाखार नहीं खुश ठागी नहीं बरी ...   \n",
              "6    वही चे तुले, ये ना ना दुप तुप रब यागा वाँप प्...   \n",
              "7                      जिहीड देख्ले कोग्ली लगें लाड़।   \n",
              "8    अखिरिजने की बुल्डि यह तिबारा गजे जिल्ठे ते दो...   \n",
              "9    उस्टिक्रादे पाएंगे इसिम्युने जरीज प्जरीव रजात...   \n",
              "10   योंवश्वखंड़ूं शिएंगाश्वखंड़ूंदे वुख्खराच्वंका...   \n",
              "11   अजिकल मिशन को भी खखुबी जांक्या में पिरोया दिस...   \n",
              "12                                 ütün cylinder oil.   \n",
              "13   यह आपके लिए बूँईष्टर्ट्गी जबिएद, वहुँईग यह सु...   \n",
              "14   जंपागी दिएकोच चर्चा मुझ्पर्ठ अगी चर्चा मुझ्पर...   \n",
              "15   रीठरेगेally like Grody Nakandarse शुःकbling a...   \n",
              "16                      इसे दिएड शाम्तर जानाखते हो गा   \n",
              "17   अपना वो अपना वो अपना वो अपना वो अपना वो अपना ...   \n",
              "18   आर समय, आर जुखो अदाखर सुख अप इश्मिज्योंगी और ...   \n",
              "19   तर्मजेशकी जित्रीवी लुँ प्राफीव हैं तिख एर नोव...   \n",
              "20   पाड़ं कर में को लेकर आम लोगों लेगरुख्ता में य...   \n",
              "21   वोंगी कतालュ हो जांगी से खुत both are not acco...   \n",
              "22   अख्यारुद तुजे सच्वरीद आख्यारुद के आम्द्टे, जै...   \n",
              "23   नुखर जोदा मैं जन्बाद अवर मिलिया स्विको तुश्वि...   \n",
              "24   ग़िब भज्जे को द़ी पोषर में मिंनेगे खारं पोस्प...   \n",
              "25   नवस्काँ सदा मैं मुबाल मेरिया तुरीपोटर खुष्टी ...   \n",
              "26    Hind create efforts cust on the development ...   \n",
              "27   नावस्काद खुजाम लिए जन्बाद मुवाई मेर्याषे लिए ...   \n",
              "28   बतानाते ह Aufgabe को हुईं जारन हमोंने लिक्लाह...   \n",
              "29   यह यह तेख़़़ बहुड़ों तेख़ा बार नगागी जाएगी और...   \n",
              "\n",
              "                                            reference  \n",
              "0   दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...  \n",
              "1   झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...  \n",
              "2   विरोधियों के बीच होने वाले इस मैच की तारीख से ...  \n",
              "3   इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...  \n",
              "4   कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...  \n",
              "5   छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...  \n",
              "6   वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...  \n",
              "7                     भीड़ देखने को मिल रही है धन्यवाद  \n",
              "8    में की बोली गयी है कि बारह बजे दिन से से दो ब...  \n",
              "9   उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...  \n",
              "10   प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...  \n",
              "11   मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...  \n",
              "12  आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...  \n",
              "13   की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...  \n",
              "14  जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...  \n",
              "15  प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...  \n",
              "16                          विधायक सांसद जाना तय होगा  \n",
              "17  अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...  \n",
              "18  हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...  \n",
              "19  एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...  \n",
              "20  पालन करने को लेकर आम लोगों में जागरूकता नहीं य...  \n",
              "21  वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...  \n",
              "22  हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...  \n",
              "23  नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...  \n",
              "24  गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...  \n",
              "25  नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...  \n",
              "26  की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...  \n",
              "27  नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...  \n",
              "28  इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...  \n",
              "29  इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1041d40f-c09c-413a-bbe8-f6022154dd2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>दीपक कुमार आरे मुँगीर मोबाईवानी के माधिल से ब...</td>\n",
              "      <td>दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>तकन में पिष्ले तींचाज लिनो से लगतार हो रही भा...</td>\n",
              "      <td>झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बीज पोरीवाले इस मैज की तारीख से नाराज है बीची...</td>\n",
              "      <td>विरोधियों के बीच होने वाले इस मैच की तारीख से ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इसका खामयाज खामयाजा हम लोग तो भुगती रहे हैं स...</td>\n",
              "      <td>इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अद्रूक्ने लागा तो लोग समाज लगतार बड़ाव लाने म...</td>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>शुषे राखम लेग तीटाखार नहीं खुश ठागी नहीं बरी ...</td>\n",
              "      <td>छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>वही चे तुले, ये ना ना दुप तुप रब यागा वाँप प्...</td>\n",
              "      <td>वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>जिहीड देख्ले कोग्ली लगें लाड़।</td>\n",
              "      <td>भीड़ देखने को मिल रही है धन्यवाद</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अखिरिजने की बुल्डि यह तिबारा गजे जिल्ठे ते दो...</td>\n",
              "      <td>में की बोली गयी है कि बारह बजे दिन से से दो ब...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>उस्टिक्रादे पाएंगे इसिम्युने जरीज प्जरीव रजात...</td>\n",
              "      <td>उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>योंवश्वखंड़ूं शिएंगाश्वखंड़ूंदे वुख्खराच्वंका...</td>\n",
              "      <td>प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>अजिकल मिशन को भी खखुबी जांक्या में पिरोया दिस...</td>\n",
              "      <td>मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ütün cylinder oil.</td>\n",
              "      <td>आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>यह आपके लिए बूँईष्टर्ट्गी जबिएद, वहुँईग यह सु...</td>\n",
              "      <td>की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>जंपागी दिएकोच चर्चा मुझ्पर्ठ अगी चर्चा मुझ्पर...</td>\n",
              "      <td>जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>रीठरेगेally like Grody Nakandarse शुःकbling a...</td>\n",
              "      <td>प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>इसे दिएड शाम्तर जानाखते हो गा</td>\n",
              "      <td>विधायक सांसद जाना तय होगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>अपना वो अपना वो अपना वो अपना वो अपना वो अपना ...</td>\n",
              "      <td>अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>आर समय, आर जुखो अदाखर सुख अप इश्मिज्योंगी और ...</td>\n",
              "      <td>हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>तर्मजेशकी जित्रीवी लुँ प्राफीव हैं तिख एर नोव...</td>\n",
              "      <td>एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>पाड़ं कर में को लेकर आम लोगों लेगरुख्ता में य...</td>\n",
              "      <td>पालन करने को लेकर आम लोगों में जागरूकता नहीं य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>वोंगी कतालュ हो जांगी से खुत both are not acco...</td>\n",
              "      <td>वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>अख्यारुद तुजे सच्वरीद आख्यारुद के आम्द्टे, जै...</td>\n",
              "      <td>हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>नुखर जोदा मैं जन्बाद अवर मिलिया स्विको तुश्वि...</td>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ग़िब भज्जे को द़ी पोषर में मिंनेगे खारं पोस्प...</td>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>नवस्काँ सदा मैं मुबाल मेरिया तुरीपोटर खुष्टी ...</td>\n",
              "      <td>नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Hind create efforts cust on the development ...</td>\n",
              "      <td>की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>नावस्काद खुजाम लिए जन्बाद मुवाई मेर्याषे लिए ...</td>\n",
              "      <td>नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>बतानाते ह Aufgabe को हुईं जारन हमोंने लिक्लाह...</td>\n",
              "      <td>इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>यह यह तेख़़़ बहुड़ों तेख़ा बार नगागी जाएगी और...</td>\n",
              "      <td>इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1041d40f-c09c-413a-bbe8-f6022154dd2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1041d40f-c09c-413a-bbe8-f6022154dd2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1041d40f-c09c-413a-bbe8-f6022154dd2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fca96f82-62c6-41eb-9e78-72bd0924345c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fca96f82-62c6-41eb-9e78-72bd0924345c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fca96f82-62c6-41eb-9e78-72bd0924345c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8223c3b2-65f1-4cc5-b059-2ff2d7cb3f8f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('baseline_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8223c3b2-65f1-4cc5-b059-2ff2d7cb3f8f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('baseline_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wer = jiwer.wer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G63e2Y36Saw4",
        "outputId": "afeb2bb3-9c1e-4bd5-e71b-8f560717f623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 92.87 %\n",
            "CER: 65.01 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# Load the model whisper large\n",
        "model_orignal_whisper = whisper.load_model(\"large\")  # Choose model size as needed\n",
        "\n",
        "# for mel, text in tqdm(loader):\n",
        "#     # results = model.decode(mels, options)\n",
        "#     # hypotheses.extend([result.text for result in results])\n",
        "#     result = decode_baseline(model_orignal_whisper, mel, beam_size) # Is this okay ?\n",
        "#     hypotheses.extend(result)\n",
        "#     references.extend(text)\n",
        "\n",
        "# Transcribe each audio file\n",
        "# Initialize empty lists for hypotheses and references\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# Transcribe each audio file\n",
        "for index in range(len(split_test_datasets[\"finetune\"])):\n",
        "    # Get the path to the audio file\n",
        "    #print(index)\n",
        "    audio_file_path = split_test_datasets[\"finetune\"][\"audio\"][index][\"path\"]\n",
        "    #print(audio_file_path)\n",
        "    # Transcribe the audio file\n",
        "    result = model_orignal_whisper.transcribe(audio_file_path, language=\"hi\")[\"text\"]\n",
        "    # Append the transcription (hypothesis) and the reference\n",
        "    hypotheses.append(result)\n",
        "    references.append(split_test_datasets[\"finetune\"][\"sentence\"][index])\n",
        "\n",
        "baseline_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "baseline_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nkTw6g7dTBDl",
        "outputId": "94abf380-8bac-4b37-8715-a1240c2c2262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:34<00:00, 90.2MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0    दीपक कुमार आरे मुंगीर मोबाइल वानी के माध्यम स...   \n",
              "1    पिछले तीन चार दिनों से लगतार हो रही बारिश थी,...   \n",
              "2    प्रदियों के बीच होने वाले इस मैच की तारीग से ...   \n",
              "3    इसका खाम्याज खाम्याजा हम लोग तो भूगत ही रहे ह...   \n",
              "4    कड़ी में और यह सिलसिला अब रुकने वाला नहीं है ...   \n",
              "5    छोटे रखम छेत की पकड़ नहीं पहुँचता है। इस बड़ी...   \n",
              "6    वहीं छेत्र में लेना नदमेश ने सप्राब्य शाय वाप...   \n",
              "7                जीहिर देखने को अगली नहीं है मैंने आप   \n",
              "8    अखिर में भूली गई है कि बारा वज़े दिन से दो वज...   \n",
              "9    कुछ सिख्रा दे पाएंगे। इसलिए उन्हें गरीड पर गर...   \n",
              "10   जिवान फर्कन देवों, जिवान राव फर्कन देवों, खरा...   \n",
              "11   विशर्जन शांतिपुर्ण वव्वातावन में कराने के लिए...   \n",
              "12   अदत्तर् रूता जमालपूर के मिश्याजलन, चेनोइमे रा...   \n",
              "13   जिन्हारा के ही गुई सर की ज़रिय है वहीं इस विज...   \n",
              "14   जनता की रिपोर्ट चर्जा मंस्तर अचिकरमन मुझ्च कर...   \n",
              "15   परखन विशास पर अधिकारी घटनाच्छा सब्ब और अच्छान...   \n",
              "16                      दिवाय इस काम तक रहना पहन होगा   \n",
              "17   अपना मकान शर्ट जो सरकों जर्में कर बना चुके है...   \n",
              "18   हर समय हर जुख को अदा कर सुख और इश्लिजी थी और ...   \n",
              "19   पर जिसकी जितनी भी लोग वाकियों हैं तो तेरे मोब...   \n",
              "20   पालं करने को लेकर आम लोगों में जागरुपता नहीं ...   \n",
              "21   वनों की कताई हो जाने से फुद्धवाके अभाव में स्...   \n",
              "22   अश्यारों की देखा खरीद आत्रणबाद के अंत जैसे एक...   \n",
              "23   नमस्कार शोड़ता हूँ मैं जनवार दोरी मुझे रिपोर्...   \n",
              "24   गरीब बच्चे को सही पोषण नहीं मिलने के कारण पॉष...   \n",
              "25   नमस्कार सज़ाजा मैं मोबाइल मेडिया जुरीपोटर खुश...   \n",
              "26   कि सरकारी सार्यालयों में बढ़ते द्रास्ताजार का...   \n",
              "27   नमस्कार सुरुदा में धन्बाद मोबाई मेडिया से रिप...   \n",
              "28   इसी के साथ बताना चाहता हूँ कि कोई ज्ञान नहीं ...   \n",
              "29   इसके साथ ये तो एक गोड़ों के साथ भारा नपाली जा...   \n",
              "\n",
              "                                            reference  \n",
              "0   दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...  \n",
              "1   झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...  \n",
              "2   विरोधियों के बीच होने वाले इस मैच की तारीख से ...  \n",
              "3   इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...  \n",
              "4   कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...  \n",
              "5   छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...  \n",
              "6   वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...  \n",
              "7                     भीड़ देखने को मिल रही है धन्यवाद  \n",
              "8    में की बोली गयी है कि बारह बजे दिन से से दो ब...  \n",
              "9   उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...  \n",
              "10   प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...  \n",
              "11   मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...  \n",
              "12  आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...  \n",
              "13   की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...  \n",
              "14  जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...  \n",
              "15  प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...  \n",
              "16                          विधायक सांसद जाना तय होगा  \n",
              "17  अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...  \n",
              "18  हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...  \n",
              "19  एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...  \n",
              "20  पालन करने को लेकर आम लोगों में जागरूकता नहीं य...  \n",
              "21  वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...  \n",
              "22  हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...  \n",
              "23  नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...  \n",
              "24  गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...  \n",
              "25  नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...  \n",
              "26  की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...  \n",
              "27  नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...  \n",
              "28  इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...  \n",
              "29  इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-016727ad-b9b4-4a08-aaf9-f6eda688d37e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>दीपक कुमार आरे मुंगीर मोबाइल वानी के माध्यम स...</td>\n",
              "      <td>दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>पिछले तीन चार दिनों से लगतार हो रही बारिश थी,...</td>\n",
              "      <td>झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>प्रदियों के बीच होने वाले इस मैच की तारीग से ...</td>\n",
              "      <td>विरोधियों के बीच होने वाले इस मैच की तारीख से ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इसका खाम्याज खाम्याजा हम लोग तो भूगत ही रहे ह...</td>\n",
              "      <td>इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है ...</td>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>छोटे रखम छेत की पकड़ नहीं पहुँचता है। इस बड़ी...</td>\n",
              "      <td>छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>वहीं छेत्र में लेना नदमेश ने सप्राब्य शाय वाप...</td>\n",
              "      <td>वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>जीहिर देखने को अगली नहीं है मैंने आप</td>\n",
              "      <td>भीड़ देखने को मिल रही है धन्यवाद</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अखिर में भूली गई है कि बारा वज़े दिन से दो वज...</td>\n",
              "      <td>में की बोली गयी है कि बारह बजे दिन से से दो ब...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>कुछ सिख्रा दे पाएंगे। इसलिए उन्हें गरीड पर गर...</td>\n",
              "      <td>उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>जिवान फर्कन देवों, जिवान राव फर्कन देवों, खरा...</td>\n",
              "      <td>प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>विशर्जन शांतिपुर्ण वव्वातावन में कराने के लिए...</td>\n",
              "      <td>मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>अदत्तर् रूता जमालपूर के मिश्याजलन, चेनोइमे रा...</td>\n",
              "      <td>आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>जिन्हारा के ही गुई सर की ज़रिय है वहीं इस विज...</td>\n",
              "      <td>की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>जनता की रिपोर्ट चर्जा मंस्तर अचिकरमन मुझ्च कर...</td>\n",
              "      <td>जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>परखन विशास पर अधिकारी घटनाच्छा सब्ब और अच्छान...</td>\n",
              "      <td>प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>दिवाय इस काम तक रहना पहन होगा</td>\n",
              "      <td>विधायक सांसद जाना तय होगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>अपना मकान शर्ट जो सरकों जर्में कर बना चुके है...</td>\n",
              "      <td>अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>हर समय हर जुख को अदा कर सुख और इश्लिजी थी और ...</td>\n",
              "      <td>हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>पर जिसकी जितनी भी लोग वाकियों हैं तो तेरे मोब...</td>\n",
              "      <td>एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>पालं करने को लेकर आम लोगों में जागरुपता नहीं ...</td>\n",
              "      <td>पालन करने को लेकर आम लोगों में जागरूकता नहीं य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>वनों की कताई हो जाने से फुद्धवाके अभाव में स्...</td>\n",
              "      <td>वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>अश्यारों की देखा खरीद आत्रणबाद के अंत जैसे एक...</td>\n",
              "      <td>हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>नमस्कार शोड़ता हूँ मैं जनवार दोरी मुझे रिपोर्...</td>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पॉष...</td>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>नमस्कार सज़ाजा मैं मोबाइल मेडिया जुरीपोटर खुश...</td>\n",
              "      <td>नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>कि सरकारी सार्यालयों में बढ़ते द्रास्ताजार का...</td>\n",
              "      <td>की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>नमस्कार सुरुदा में धन्बाद मोबाई मेडिया से रिप...</td>\n",
              "      <td>नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>इसी के साथ बताना चाहता हूँ कि कोई ज्ञान नहीं ...</td>\n",
              "      <td>इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>इसके साथ ये तो एक गोड़ों के साथ भारा नपाली जा...</td>\n",
              "      <td>इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-016727ad-b9b4-4a08-aaf9-f6eda688d37e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-016727ad-b9b4-4a08-aaf9-f6eda688d37e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-016727ad-b9b4-4a08-aaf9-f6eda688d37e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29f93d99-8512-47fb-9d5e-d203000a644f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29f93d99-8512-47fb-9d5e-d203000a644f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29f93d99-8512-47fb-9d5e-d203000a644f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fc8348e0-7c65-47a2-a0c4-993943787aa7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('baseline_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc8348e0-7c65-47a2-a0c4-993943787aa7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('baseline_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "beam_size = 5\n",
        "# Load the model\n",
        "model = whisper.load_model(\"small\")  # Choose model size as needed\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_baseline(model, mel, beam_size) # Is this okay ?\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "# Transcribe each audio file\n",
        "# Initialize empty lists for hypotheses and references\n",
        "# hypotheses = []\n",
        "# references = []\n",
        "\n",
        "# Transcribe each audio file\n",
        "# for index in range(len(split_test_datasets[\"finetune\"])):\n",
        "#     # Get the path to the audio file\n",
        "#     #print(index)\n",
        "#     audio_file_path = split_test_datasets[\"finetune\"][\"audio\"][index][\"path\"]\n",
        "#     #print(audio_file_path)\n",
        "#     # Transcribe the audio file\n",
        "#     result = model_orignal_whisper.transcribe(audio_file_path, language=\"hi\")[\"text\"]\n",
        "#     # Append the transcription (hypothesis) and the reference\n",
        "#     hypotheses.append(result)\n",
        "#     references.append(split_test_datasets[\"finetune\"][\"sentence\"][index])\n",
        "\n",
        "baseline_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "baseline_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-ZXOvouddhf",
        "outputId": "00a57cf6-ffa0-4a12-ac7a-9e27405f6735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:21<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   दीपक कुमार आरे मुँगीर मोबाईल्वानी के माद्यम से...   \n",
              "1   अखन में पिष्ले तीं चार दिनो से लगतार हो रही बा...   \n",
              "2   बीज पुने वाले इस मैज की तारीक से नाराज है बीची...   \n",
              "3   इसका खाम्याज खाम्याजा हम लोग तो भुगती रहे हैं ...   \n",
              "4   कडी में. और यह सिल सला अप रुकने वाला नहीं कुकी...   \n",
              "5   चोषे याच्कम लेए ती पचा लिए नहीं कोईश्ठारे लिए ...   \n",
              "6   वही से तो लेग, ये ना नादूमे से चप्रा बर्षारी व...   \n",
              "7                  दिहिड देखने कोपने लाईजे, ना लेवाँ.   \n",
              "8   अप्रिर में की बूली गई है कि पारा वोजे जिंद से ...   \n",
              "9   उस्द्रा दे पाएंगे इसिए उने गरीख ते गरीख रजाते ...   \n",
              "10  तुम्सर्खंड़। तुम्सर्खंड़। तुम्सर्खंड़। तुम्सर्...   \n",
              "11  भी शर्जन शांची पुद लवादा वन ने ख्रानि के लिए म...   \n",
              "12  अदक्त्रोटां जमाल्पूर् सिंच्या जलंग, जमाल्पूर् ...   \n",
              "13  यह आपके ही बीश्वर्ठी जेंगे है, उरहीं इस विज़्ा...   \n",
              "14  जंपार्टी दिएपोट चर्टा मंस्पार्ट अकी चर्टमन मुँ...   \n",
              "15  पर्खन दिखाखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखख...   \n",
              "16                        भी राध शाम्तर जानाखतर होगा.   \n",
              "17                             अपने अपना मुँँँँँँँँँँ   \n",
              "18  और समय, और जुख को अदार कर शुख अफिष्नुची और आगे...   \n",
              "19  ये प्रे वी लोग बाखियो है, ये प्रे मवाल वानी शे...   \n",
              "20  पालं कर में को लेकर आम लोगो में जाग रुखता में ...   \n",
              "21  वाई प्र्दुशन का सल्से जाडा हसर वाई प्र्दुशन का...   \n",
              "22  अख्यारुकि देखर खरीज आख्यार बाद के हमस्तें। अख्...   \n",
              "23  नुक्री दिलाने के नामपर यूर्ट लेज़ागी करने कारु...   \n",
              "24  गरी भज्जे को सही पोषर में मिलने के चारन पोषकी ...   \n",
              "25                         जीले के 1250 प्राष्मी किसा   \n",
              "26  सर्कारी स्वार्यालें में बड़के द्राष्टाचाल का म...   \n",
              "27  नावस्कार स्वोजाम लिजन्बाद मुवाई मेरिया से लिए ...   \n",
              "28  तिशीको साथ से बतानाचाता हूँ की कोई जान नहीं अख...   \n",
              "29  विस्ते साथ यह सो एक वोड़ोग साथ बारंग गाए जाएगी...   \n",
              "\n",
              "                                            reference  \n",
              "0   दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...  \n",
              "1   झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...  \n",
              "2   विरोधियों के बीच होने वाले इस मैच की तारीख से ...  \n",
              "3   इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...  \n",
              "4   कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...  \n",
              "5   छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...  \n",
              "6   वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...  \n",
              "7                     भीड़ देखने को मिल रही है धन्यवाद  \n",
              "8    में की बोली गयी है कि बारह बजे दिन से से दो ब...  \n",
              "9   उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...  \n",
              "10   प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...  \n",
              "11   मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...  \n",
              "12  आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...  \n",
              "13   की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...  \n",
              "14  जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...  \n",
              "15  प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...  \n",
              "16                          विधायक सांसद जाना तय होगा  \n",
              "17  अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...  \n",
              "18  हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...  \n",
              "19  एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...  \n",
              "20  पालन करने को लेकर आम लोगों में जागरूकता नहीं य...  \n",
              "21  वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...  \n",
              "22  हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...  \n",
              "23  नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...  \n",
              "24  गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...  \n",
              "25  नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...  \n",
              "26  की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...  \n",
              "27  नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...  \n",
              "28  इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...  \n",
              "29  इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0da4cb1a-662f-4930-8f16-7aa4ee922745\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>दीपक कुमार आरे मुँगीर मोबाईल्वानी के माद्यम से...</td>\n",
              "      <td>दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अखन में पिष्ले तीं चार दिनो से लगतार हो रही बा...</td>\n",
              "      <td>झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बीज पुने वाले इस मैज की तारीक से नाराज है बीची...</td>\n",
              "      <td>विरोधियों के बीच होने वाले इस मैच की तारीख से ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इसका खाम्याज खाम्याजा हम लोग तो भुगती रहे हैं ...</td>\n",
              "      <td>इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कडी में. और यह सिल सला अप रुकने वाला नहीं कुकी...</td>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चोषे याच्कम लेए ती पचा लिए नहीं कोईश्ठारे लिए ...</td>\n",
              "      <td>छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>वही से तो लेग, ये ना नादूमे से चप्रा बर्षारी व...</td>\n",
              "      <td>वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>दिहिड देखने कोपने लाईजे, ना लेवाँ.</td>\n",
              "      <td>भीड़ देखने को मिल रही है धन्यवाद</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अप्रिर में की बूली गई है कि पारा वोजे जिंद से ...</td>\n",
              "      <td>में की बोली गयी है कि बारह बजे दिन से से दो ब...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>उस्द्रा दे पाएंगे इसिए उने गरीख ते गरीख रजाते ...</td>\n",
              "      <td>उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>तुम्सर्खंड़। तुम्सर्खंड़। तुम्सर्खंड़। तुम्सर्...</td>\n",
              "      <td>प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>भी शर्जन शांची पुद लवादा वन ने ख्रानि के लिए म...</td>\n",
              "      <td>मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>अदक्त्रोटां जमाल्पूर् सिंच्या जलंग, जमाल्पूर् ...</td>\n",
              "      <td>आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>यह आपके ही बीश्वर्ठी जेंगे है, उरहीं इस विज़्ा...</td>\n",
              "      <td>की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>जंपार्टी दिएपोट चर्टा मंस्पार्ट अकी चर्टमन मुँ...</td>\n",
              "      <td>जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>पर्खन दिखाखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखखख...</td>\n",
              "      <td>प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>भी राध शाम्तर जानाखतर होगा.</td>\n",
              "      <td>विधायक सांसद जाना तय होगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>अपने अपना मुँँँँँँँँँँ</td>\n",
              "      <td>अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>और समय, और जुख को अदार कर शुख अफिष्नुची और आगे...</td>\n",
              "      <td>हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ये प्रे वी लोग बाखियो है, ये प्रे मवाल वानी शे...</td>\n",
              "      <td>एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>पालं कर में को लेकर आम लोगो में जाग रुखता में ...</td>\n",
              "      <td>पालन करने को लेकर आम लोगों में जागरूकता नहीं य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>वाई प्र्दुशन का सल्से जाडा हसर वाई प्र्दुशन का...</td>\n",
              "      <td>वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>अख्यारुकि देखर खरीज आख्यार बाद के हमस्तें। अख्...</td>\n",
              "      <td>हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>नुक्री दिलाने के नामपर यूर्ट लेज़ागी करने कारु...</td>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>गरी भज्जे को सही पोषर में मिलने के चारन पोषकी ...</td>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जीले के 1250 प्राष्मी किसा</td>\n",
              "      <td>नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>सर्कारी स्वार्यालें में बड़के द्राष्टाचाल का म...</td>\n",
              "      <td>की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>नावस्कार स्वोजाम लिजन्बाद मुवाई मेरिया से लिए ...</td>\n",
              "      <td>नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>तिशीको साथ से बतानाचाता हूँ की कोई जान नहीं अख...</td>\n",
              "      <td>इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>विस्ते साथ यह सो एक वोड़ोग साथ बारंग गाए जाएगी...</td>\n",
              "      <td>इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da4cb1a-662f-4930-8f16-7aa4ee922745')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0da4cb1a-662f-4930-8f16-7aa4ee922745 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0da4cb1a-662f-4930-8f16-7aa4ee922745');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84213e56-6b7a-4fe9-abb1-5dcb961e71de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84213e56-6b7a-4fe9-abb1-5dcb961e71de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84213e56-6b7a-4fe9-abb1-5dcb961e71de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9eb8f1b2-fcf3-4d29-bd23-6b769682693d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('baseline_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9eb8f1b2-fcf3-4d29-bd23-6b769682693d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('baseline_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "wer = jiwer.wer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZMfw_kPIVXh",
        "outputId": "fdd163d5-094e-4a2b-aa6c-226a87f1c117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 90.01 %\n",
            "CER: 62.58 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **We see whisper small on the sub sample of diverse hindi dataset shows extremely poor accuracy around 90% .This disparity in performance is consistent across different input modalities, whether using direct audio files or Mel spectrograms extracted from the audio.There is improvement  on whisper large where we are getting around 50% accuracy but still its below par\n",
        "We would be refining the performance on whisper small.**\n"
      ],
      "metadata": {
        "id": "QRpz0zILctwo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DrvdKNZZfV"
      },
      "source": [
        "###2.5  Decoding with Integrated Fine tuned Whisper model and with LM deep fusion\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "dEfO8QAbbdKO",
        "outputId": "422cf661-6683-4d1e-c49e-8b87e104ae5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:03<00:00, 81.6MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HisMIkZzYJjJ",
        "outputId": "d2d78304-251e-4953-9c46-b77a738b3d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [13:58<00:00, 27.95s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...   \n",
              "1   झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...   \n",
              "2   विरोधियों के बीच होने वाले इस मैच की तारीख से ...   \n",
              "3   इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...   \n",
              "4   कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...   \n",
              "5   छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...   \n",
              "6   वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...   \n",
              "7                     भीड़ देखने को मिल रही है धन्यवाद   \n",
              "8   में की बोली गयी है कि बारह बजे दिन से से दो बज...   \n",
              "9   उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...   \n",
              "10  प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अलीग...   \n",
              "11  मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन ...   \n",
              "12  आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...   \n",
              "13  की ज़वाबदेही भी तय की गई है वहीं इस योजना के ना...   \n",
              "14  जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...   \n",
              "15  प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...   \n",
              "16                          विधायक सांसद जाना तय होगा   \n",
              "17  अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...   \n",
              "18  हर समय हर दुख को हदाकर सुख और इसमे भी थी और आग...   \n",
              "19  एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...   \n",
              "20  पालन करने को लेकर आम लोगों में जागरूकता नहीं य...   \n",
              "21  वाहु की कताई हो जाने से शुद्ध हवा के अभाव में ...   \n",
              "22  हथियारों को बेहतर खरीद आतंकवाद के अंत जैसे एक ...   \n",
              "23  नमस्कार श्रोताओं मैं धनबाद मोबाइल मीडिया से रि...   \n",
              "24  गरीब बच्चे को सही पोषण नहीं मिलने के कारण पोषण...   \n",
              "25  नमस्कार श्रोताओं मैं मोबाइल मीडिया रिपोर्टर खु...   \n",
              "26  सरकारी कार्यालयों में बढ़ते दृष्टाचार का मूल का...   \n",
              "27  नमस्कार श्रोताओं मैं धनबाद मोबाइल मीडिया से रि...   \n",
              "28  इसी के साथ से बताना चाहता हूँ की कोई ध्यान नही...   \n",
              "29  इसके साथ एक तो एक गुड़ोत बैसाथ भारी जाएगी और आर...   \n",
              "\n",
              "                                            reference  \n",
              "0   दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...  \n",
              "1   झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...  \n",
              "2   विरोधियों के बीच होने वाले इस मैच की तारीख से ...  \n",
              "3   इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...  \n",
              "4   कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...  \n",
              "5   छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...  \n",
              "6   वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...  \n",
              "7                     भीड़ देखने को मिल रही है धन्यवाद  \n",
              "8    में की बोली गयी है कि बारह बजे दिन से से दो ब...  \n",
              "9   उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...  \n",
              "10   प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...  \n",
              "11   मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...  \n",
              "12  आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...  \n",
              "13   की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...  \n",
              "14  जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...  \n",
              "15  प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...  \n",
              "16                          विधायक सांसद जाना तय होगा  \n",
              "17  अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...  \n",
              "18  हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...  \n",
              "19  एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...  \n",
              "20  पालन करने को लेकर आम लोगों में जागरूकता नहीं य...  \n",
              "21  वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...  \n",
              "22  हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...  \n",
              "23  नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...  \n",
              "24  गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...  \n",
              "25  नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...  \n",
              "26  की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...  \n",
              "27  नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...  \n",
              "28  इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...  \n",
              "29  इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245b1db4-17de-49f8-9c25-8addf7ea2b21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...</td>\n",
              "      <td>दीपक कुमार आर्य मुंगेर मोबाइल वाणी के माध्यम स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...</td>\n",
              "      <td>झारखण्ड में पिछले तीन चार दिनों से लगातार हो र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>विरोधियों के बीच होने वाले इस मैच की तारीख से ...</td>\n",
              "      <td>विरोधियों के बीच होने वाले इस मैच की तारीख से ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...</td>\n",
              "      <td>इसका खामियाज़ा खामियाज़ा हम लोग तो भुगत ही रहे ह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...</td>\n",
              "      <td>कड़ी में और यह सिलसिला अब रुकने वाला नहीं है क्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...</td>\n",
              "      <td>छोटे या कम खेप की पकड़ नहीं पहुँच पा रही है एक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...</td>\n",
              "      <td>वही क्षेत्र में मेला लगने से कपड़ा व्यवसायी व फ़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>भीड़ देखने को मिल रही है धन्यवाद</td>\n",
              "      <td>भीड़ देखने को मिल रही है धन्यवाद</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>में की बोली गयी है कि बारह बजे दिन से से दो बज...</td>\n",
              "      <td>में की बोली गयी है कि बारह बजे दिन से से दो ब...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...</td>\n",
              "      <td>उच्च शिक्षा दे पाएँगे इसलिए वे ग़रीब के ग़रीब रह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अलीग...</td>\n",
              "      <td>प्रखंड एवं सिकंदरा प्रखंड एवं खैरा प्रखंड अली...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन ...</td>\n",
              "      <td>मिशन को भी बखूबी झाँकियाँ में पिरोयां विसर्जन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...</td>\n",
              "      <td>आदाब श्रोताओं जमालपुर से इम्तियाज़ आलम चेन्नई म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>की ज़वाबदेही भी तय की गई है वहीं इस योजना के ना...</td>\n",
              "      <td>की ज़वाबदेही भी तय की गई है वहीं इस योजना के न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...</td>\n",
              "      <td>जनता की रिपोर्ट चर्चा मंच पर अतिक्रमण मुक्त सड़...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...</td>\n",
              "      <td>प्रखंड विकास पदाधिकारी घटना स्थल पर पहुँच और स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>विधायक सांसद जाना तय होगा</td>\n",
              "      <td>विधायक सांसद जाना तय होगा</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...</td>\n",
              "      <td>अपना मकान सड़ जो सड़कों गलियों पर बना चुके हैं स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>हर समय हर दुख को हदाकर सुख और इसमे भी थी और आग...</td>\n",
              "      <td>हर समय हर दुःख को हटाकर सुख और स्मृति की ओर आग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...</td>\n",
              "      <td>एवं देश की जीतने भी लोग वासी हैं एवं मोबाइल वा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>पालन करने को लेकर आम लोगों में जागरूकता नहीं य...</td>\n",
              "      <td>पालन करने को लेकर आम लोगों में जागरूकता नहीं य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>वाहु की कताई हो जाने से शुद्ध हवा के अभाव में ...</td>\n",
              "      <td>वनों की कटाई हो जाने से शुद्ध हवा के अभाव में ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>हथियारों को बेहतर खरीद आतंकवाद के अंत जैसे एक ...</td>\n",
              "      <td>हथियारों की बेहतर खरीद आतंकवाद के अंत जैसे एकज...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मीडिया से रि...</td>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मोबाइल मीडिय...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पोषण...</td>\n",
              "      <td>गरीब बच्चे को सही पोषण नहीं मिलने के कारण पौष्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>नमस्कार श्रोताओं मैं मोबाइल मीडिया रिपोर्टर खु...</td>\n",
              "      <td>नमस्कार श्रोता मैं मोबाइल मिडिया रिपोर्टर खुर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>सरकारी कार्यालयों में बढ़ते दृष्टाचार का मूल का...</td>\n",
              "      <td>की सरकारी कार्यालयों में बढ़ती भ्रष्टाचार का मू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>नमस्कार श्रोताओं मैं धनबाद मोबाइल मीडिया से रि...</td>\n",
              "      <td>नमस्कार श्रोताओ में मैं धनबाद मोबाइल मीडिया से...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>इसी के साथ से बताना चाहता हूँ की कोई ध्यान नही...</td>\n",
              "      <td>इसी के साथ बताना चाहता हूँ कि कोई ध्यान नहीं र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>इसके साथ एक तो एक गुड़ोत बैसाथ भारी जाएगी और आर...</td>\n",
              "      <td>इसके साथ एक सौ एक घोड़े के साथ बारात निकाली जाए...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245b1db4-17de-49f8-9c25-8addf7ea2b21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-245b1db4-17de-49f8-9c25-8addf7ea2b21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-245b1db4-17de-49f8-9c25-8addf7ea2b21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-babe0d8a-e2b5-486f-9706-842ea57ff5fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-babe0d8a-e2b5-486f-9706-842ea57ff5fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-babe0d8a-e2b5-486f-9706-842ea57ff5fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bcbde9da-31e3-4ffb-945b-26c5bf673673\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('deep_fusion_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bcbde9da-31e3-4ffb-945b-26c5bf673673 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('deep_fusion_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 5\n",
        "lm_alpha = 0.9\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    # result = decode_baseline(model, mel, beam_size)\n",
        "    result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "deep_fusion_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "deep_fusion_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpu45C9BblyC",
        "outputId": "0a2e80bc-cb01-43d8-bb46-0e9bf12ce9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 15.18 %\n",
            "CER: 8.47 %\n"
          ]
        }
      ],
      "source": [
        "wer = jiwer.wer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***WER is quite low , so we fine tune the parmeters now to get the optimal params value of beam size and lm_alpha.***"
      ],
      "metadata": {
        "id": "wA9AnflUbWLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we fine tune the paramaters to ge tthe best WER ]\n",
        "\n",
        "best_wer = float('inf')\n",
        "best_params = {'beam_size': None, 'lm_alpha': None}\n",
        "\n",
        "for beam_size in [5, 10, 15, 20]:\n",
        "    for lm_alpha in [0.1, 0.5, 0.9, 1.0]:\n",
        "        hypotheses = []\n",
        "        references = []\n",
        "\n",
        "        for mel, text in tqdm(loader):\n",
        "            result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "            hypotheses.extend(result)\n",
        "            references.extend(text)\n",
        "\n",
        "        deep_fusion_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "        wer = jiwer.wer(deep_fusion_df[\"reference\"].tolist(), deep_fusion_df[\"hypothesis\"].tolist())\n",
        "\n",
        "        if wer < best_wer:\n",
        "            best_wer = wer\n",
        "            best_params['beam_size'] = beam_size\n",
        "            best_params['lm_alpha'] = lm_alpha\n",
        "\n",
        "        print(f\"Beam size: {beam_size}, LM Alpha: {lm_alpha}, WER: {wer * 100:.2f}\")\n",
        "\n",
        "print(f\"Best WER: {best_wer * 100:.2f} achieved with Beam Size: {best_params['beam_size']} and LM Alpha: {best_params['lm_alpha']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlOHj6xA2t2x",
        "outputId": "2d320627-3cd0-4fdf-aa4b-761333c7f40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [13:46<00:00, 27.54s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 5, LM Alpha: 0.1, WER: 0.1517509727626459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [13:39<00:00, 27.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 5, LM Alpha: 0.5, WER: 0.1517509727626459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [13:43<00:00, 27.44s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 5, LM Alpha: 0.9, WER: 0.1517509727626459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [13:44<00:00, 27.48s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 5, LM Alpha: 1.0, WER: 0.1517509727626459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [26:51<00:00, 53.73s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 10, LM Alpha: 0.1, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [26:45<00:00, 53.52s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 10, LM Alpha: 0.5, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [26:44<00:00, 53.50s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 10, LM Alpha: 0.9, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [27:18<00:00, 54.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 10, LM Alpha: 1.0, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [40:42<00:00, 81.41s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 15, LM Alpha: 0.1, WER: 0.1543450064850843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [40:33<00:00, 81.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 15, LM Alpha: 0.5, WER: 0.1543450064850843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [40:39<00:00, 81.30s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 15, LM Alpha: 0.9, WER: 0.1543450064850843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [41:27<00:00, 82.93s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 15, LM Alpha: 1.0, WER: 0.1543450064850843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [54:32<00:00, 109.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 20, LM Alpha: 0.1, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [54:16<00:00, 108.54s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 20, LM Alpha: 0.5, WER: 0.15304798962386512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [54:28<00:00, 108.96s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam size: 20, LM Alpha: 0.9, WER: 0.15304798962386512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [54:25<00:00, 108.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam size: 20, LM Alpha: 1.0, WER: 0.15304798962386512\n",
            "Best WER: 0.1517509727626459 achieved with Beam Size: 5 and LM Alpha: 0.1\n",
            "Beam size: 20, LM Alpha: 1.0, WER: 0.15304798962386512\n",
            "Best WER: 0.1517509727626459 achieved with Beam Size: 5 and LM Alpha: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We get Best WER: 15.17509727626459 achieved with Beam Size: 5 and LM Alpha: 0.1** . Now we run the WER with these params on the unseen test dataset"
      ],
      "metadata": {
        "id": "tnHgJnnydbZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = customDataset(split_test_datasets[\"test\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "VzV14WKu2jVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 5\n",
        "lm_alpha = 0.1\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    # result = decode_baseline(model, mel, beam_size)\n",
        "    result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "deep_fusion_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "deep_fusion_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "FurE3io62qE8",
        "outputId": "24eaecca-cf02-4bb7-8069-d4c09b38cf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [1:02:39<00:00, 13.92s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            hypothesis  \\\n",
              "0              यह ऑस्ट्रेलिया का सर्वोत्तम न्यायालय है   \n",
              "1                इस पर्वत पर एक सुंदर मंदिर बना हुआ है   \n",
              "2                               इस संदेश का क्या संदेश   \n",
              "3            अतः तुम उनके विषय में चिंता करना त्याग दो   \n",
              "4                                        स्वतंत्रता से   \n",
              "..                                                 ...   \n",
              "265  वो लोग खुद ना फंस जाए इस डर से सिमा के ससुराल ...   \n",
              "266  नही दी एंट्री भारत की स्टार टेबल टेनिस खिलाड़ी ...   \n",
              "267  ने इक्कीस पैसे की राहत दी है अब तक किसानों को ...   \n",
              "268  कार्यता को घटा दिया है इस सीमा को एक हजार रूपए...   \n",
              "269  नमस्कार दोस्तों गिद्धौर मोबाइल वाणी से मैं संज...   \n",
              "\n",
              "                                             reference  \n",
              "0              यह आस्ट्रेलिया का सर्वोत्तम न्यायालय है  \n",
              "1                   इस पर्वत पर एक सुंदर मंदिर बना हुआ  \n",
              "2    इस सन्देश का क्या अर्थ है मेरी समझ से बाहर है ...  \n",
              "3            अतः तुम उनके विषय में चिंता करना त्याग दो  \n",
              "4    स्वतंत्रता सेनानी वकील एवं संस्कृत भाषा के विद...  \n",
              "..                                                 ...  \n",
              "265   वो लोग खुद ना फंस जाए इस डर से सिमा के ससुराल...  \n",
              "266  नहीं दी एंट्री भारत की स्टार टेबल टेनिस खिलाड़ी...  \n",
              "267  ने इक्कीस पैसे की राहत दी है अब तक किसानों को ...  \n",
              "268   कार्यता को घटा दिया है इस सीमा को एक हजार रूप...  \n",
              "269  नमस्कार दोस्तों गिद्धौर मोबाइल वाणी से मैं संज...  \n",
              "\n",
              "[270 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ab92177-302e-4928-80a3-8470ea79f16e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>यह ऑस्ट्रेलिया का सर्वोत्तम न्यायालय है</td>\n",
              "      <td>यह आस्ट्रेलिया का सर्वोत्तम न्यायालय है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>इस पर्वत पर एक सुंदर मंदिर बना हुआ है</td>\n",
              "      <td>इस पर्वत पर एक सुंदर मंदिर बना हुआ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>इस संदेश का क्या संदेश</td>\n",
              "      <td>इस सन्देश का क्या अर्थ है मेरी समझ से बाहर है ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अतः तुम उनके विषय में चिंता करना त्याग दो</td>\n",
              "      <td>अतः तुम उनके विषय में चिंता करना त्याग दो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>स्वतंत्रता से</td>\n",
              "      <td>स्वतंत्रता सेनानी वकील एवं संस्कृत भाषा के विद...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>वो लोग खुद ना फंस जाए इस डर से सिमा के ससुराल ...</td>\n",
              "      <td>वो लोग खुद ना फंस जाए इस डर से सिमा के ससुराल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>नही दी एंट्री भारत की स्टार टेबल टेनिस खिलाड़ी ...</td>\n",
              "      <td>नहीं दी एंट्री भारत की स्टार टेबल टेनिस खिलाड़ी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>ने इक्कीस पैसे की राहत दी है अब तक किसानों को ...</td>\n",
              "      <td>ने इक्कीस पैसे की राहत दी है अब तक किसानों को ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>कार्यता को घटा दिया है इस सीमा को एक हजार रूपए...</td>\n",
              "      <td>कार्यता को घटा दिया है इस सीमा को एक हजार रूप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>नमस्कार दोस्तों गिद्धौर मोबाइल वाणी से मैं संज...</td>\n",
              "      <td>नमस्कार दोस्तों गिद्धौर मोबाइल वाणी से मैं संज...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab92177-302e-4928-80a3-8470ea79f16e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ab92177-302e-4928-80a3-8470ea79f16e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ab92177-302e-4928-80a3-8470ea79f16e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acc5510a-f97a-44f4-bd05-7d29a2e00a8e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acc5510a-f97a-44f4-bd05-7d29a2e00a8e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acc5510a-f97a-44f4-bd05-7d29a2e00a8e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_73f1753e-959b-4d4c-87dc-bf0a0e12338f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('deep_fusion_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_73f1753e-959b-4d4c-87dc-bf0a0e12338f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('deep_fusion_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wer = jiwer.wer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scV-aNHg2y-x",
        "outputId": "60524a4d-888e-4a03-877f-ac42bd5dece9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 7.46 %\n",
            "CER: 3.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Huge difference : We see a WER of around 8% . THis too on whisper small .**\n",
        "\n",
        "---\n",
        "\n",
        "THis is huge difference in terms of improving accuracy ."
      ],
      "metadata": {
        "id": "uWcTjutRdscu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8jjEY_BZc0X"
      },
      "source": [
        "###2.6  Decoding with Integrated Fine tuned Whisper model and with LM shallow fusion (Beam Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQvvnm2IYfK_",
        "outputId": "e73f11c5-3b79-413d-dc10-7cbfbcc69f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [04:20<00:00,  8.67s/it]\n"
          ]
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.05\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "    #exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lOP4glqbuEO",
        "outputId": "610d28c4-1424-4a12-ccb1-8ba521d32886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 34.11 %\n",
            "CER: 27.24 %\n"
          ]
        }
      ],
      "source": [
        "import jiwer\n",
        "\n",
        "shallow_fusion_beam_search_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "wer = jiwer.wer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The WER is better than orignal whisper but far from above model and quite inferior so will not use it ."
      ],
      "metadata": {
        "id": "VJ1LaXMLeoZN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20hHgyUZjJk"
      },
      "source": [
        "###2.7 Decoding with Integrated Fine tuned Whisper model and with LM shallow fusion (Best of N hypothesis _ greedy approach )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "best_of = 5\n",
        "temperature = 0.1\n",
        "lm_weight = 0.1\n",
        "\n",
        "#Best Of: 5, Temperature: 0.2 and LM Weight: 0.01\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    hypotheses.extend(decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False))\n",
        "    references.extend(text)\n",
        "\n",
        "\n",
        "shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "#shallow_fusion_nbest_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EASNl1EmvdS",
        "outputId": "b5009897-9338-48be-89cd-291707462a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:14<00:00,  2.49s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNxDedEonOQi",
        "outputId": "d0bde3ac-c4b3-4b93-810d-068137ae3b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 15.56 %\n",
            "CER: 8.57 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**THis approach has very close to best WER , so we will fine tune the paramaters and then run WER on the whole final test dataset of 270 utterances .**"
      ],
      "metadata": {
        "id": "jGtrvCGCnTTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after tuning\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import jiwer\n",
        "\n",
        "# Function to calculate WER and CER\n",
        "def compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path):\n",
        "    hypotheses = []\n",
        "    references = []\n",
        "\n",
        "    for mel, text in tqdm(loader):\n",
        "        result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "        hypotheses.extend(result)\n",
        "        references.extend(text)\n",
        "\n",
        "    shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "\n",
        "    wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "    cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].tolist(), shallow_fusion_nbest_df[\"hypothesis\"].tolist())\n",
        "    return wer, cer\n",
        "\n",
        "# Tuning parameters\n",
        "best_of_values = [5]\n",
        "temperature_values = [0.1,0.25,0.5,0.75,0.9]\n",
        "lm_weights = [0.1,0.25,0.5,0.75,0.9]\n",
        "\n",
        "best_wer = float('inf')\n",
        "best_params = {'best_of': None, 'temperature': None, 'lm_weight': None}\n",
        "\n",
        "for best_of in best_of_values:\n",
        "    for temperature in temperature_values:\n",
        "        for lm_weight in lm_weights:\n",
        "            wer, cer = compute_metrics(model, loader, best_of, temperature, lm_weight, lm_path)\n",
        "            print(f\"Best of: {best_of}, Temperature: {temperature}, LM Weight: {lm_weight}, WER: {wer * 100:.2f} %, CER: {cer * 100:.2f} %\")\n",
        "\n",
        "            if wer < best_wer:\n",
        "                best_wer = wer\n",
        "                best_params['best_of'] = best_of\n",
        "                best_params['temperature'] = temperature\n",
        "                best_params['lm_weight'] = lm_weight\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"Best WER: {best_wer * 100:.2f} % with Best Of: {best_params['best_of']}, Temperature: {best_params['temperature']} and LM Weight: {best_params['lm_weight']}\")\n"
      ],
      "metadata": {
        "id": "wQvigSWQcux2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca5d8a4-dd0e-45fd-ce71-fedc76270cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.1, WER: 15.43 %, CER: 8.12 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.25, WER: 15.95 %, CER: 8.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.5, WER: 16.34 %, CER: 9.05 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.75, WER: 15.95 %, CER: 8.86 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.1, LM Weight: 0.9, WER: 15.30 %, CER: 8.57 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.1, WER: 15.43 %, CER: 8.65 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.25, WER: 15.30 %, CER: 8.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.5, WER: 15.82 %, CER: 8.62 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.75, WER: 16.21 %, CER: 8.99 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.25, LM Weight: 0.9, WER: 16.73 %, CER: 9.26 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.1, WER: 16.47 %, CER: 9.78 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.25, WER: 16.34 %, CER: 9.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.5, WER: 17.38 %, CER: 10.15 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.75, WER: 18.81 %, CER: 10.55 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.5, LM Weight: 0.9, WER: 18.16 %, CER: 10.94 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.1, WER: 17.77 %, CER: 10.31 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.25, WER: 18.42 %, CER: 10.52 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.5, WER: 19.33 %, CER: 10.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.75, WER: 19.84 %, CER: 10.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.75, LM Weight: 0.9, WER: 20.62 %, CER: 11.60 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.1, WER: 21.40 %, CER: 11.76 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.25, WER: 19.46 %, CER: 11.02 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.5, WER: 20.62 %, CER: 12.37 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:17<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.75, WER: 19.84 %, CER: 11.66 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:18<00:00,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best of: 5, Temperature: 0.9, LM Weight: 0.9, WER: 20.49 %, CER: 11.34 %\n",
            "Best WER: 15.30 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best WER: 15.30 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.9\n",
        "\n",
        "We will run WER on whole remaining unseen dataset ."
      ],
      "metadata": {
        "id": "Gvk9SpZTE6v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = customDataset(split_test_datasets[\"test\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "fHGsv2Nort6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "#best_of = 10\n",
        "#temperature = 0.3\n",
        "#lm_weight = 0.01\n",
        "#WER: 24.31 % , CER: 10.69 %\n",
        "\n",
        "#best_of = 30 temperature = 0.5 lm_weight = .5 WER: 20.00 % CER: 6.89 %\n",
        "#Best WER: 23.45 % with Best Of: 5, Temperature: 0.1 and LM Weight: 0.1\n",
        "best_of = 5\n",
        "temperature = 0.1\n",
        "lm_weight = 0.9\n",
        "\n",
        "#Best Of: 5, Temperature: 0.2 and LM Weight: 0.01\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    hypotheses.extend(decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False))\n",
        "    references.extend(text)\n",
        "\n",
        "\n",
        "shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "#shallow_fusion_nbest_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KV7bMFSRDAlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc985bf-75a2-4d01-c694-c9ab89188f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [06:15<00:00,  1.39s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "wer = jiwer.wer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "cer = jiwer.cer(shallow_fusion_nbest_df[\"reference\"].to_list(),shallow_fusion_nbest_df[\"hypothesis\"].to_list())\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "STboVmzyilu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437cdde1-cedc-41a8-f7c5-adb60d248536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 7.03 %\n",
            "CER: 3.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclude :  We see both the approach Deep fusion with Beam seach and shallow fusion with greedy search and n best parmaters and very close in terms of performance and accuracy .\n",
        "But with Beam search deep fusion , we invest more time in compratively getting transcriptions . So based on scenario , a consumer who wants to get faster results with much less computational power can go for shallow fusion approach .\n",
        "With Deep fusion , the accuracy is not compromised but it consumes more computational resources .**"
      ],
      "metadata": {
        "id": "VwooKUAvgn_T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKtFtijYJmbi"
      },
      "source": [
        "#3 Inferences of Our model vs BenchMarkModels - Wave2wec and GoogleUSM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to record some audios and transcibe them on 4 models - whisper orignal , our whisper , Facebook wave2wc and Google USM and see the difference in result ."
      ],
      "metadata": {
        "id": "WwrvlbTqhxz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading the required libraries\n",
        "#These libraires have already been downloaded as a part of section 2 . In case section 2 is not run and we come stragith to this section , then only we need to run below code to install librariees\n",
        "\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install transformers\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "# !pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install accelerate -U\n",
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJp6L4DM_nPb",
        "outputId": "9fc7a075-876c-41cc-bf8d-4b6d2be1d3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Using cached https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (17.0.6)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-754gg0e8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-754gg0e8\n",
            "  Resolved https://github.com/huggingface/transformers to commit 7b6324e18ee1b43d130a381fedddeb2b544e9e1a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.8.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.104.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231106)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.6)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF8NmdKLKDpZ"
      },
      "source": [
        "###3.1 Orignal  Whisper Model without any integration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of audio files\n",
        "audio_files = [\n",
        "    \"/content/audio_1.mp3\",\n",
        "    \"/content/audio_2.mp3\",\n",
        "    \"/content/audio_3.mp3\",\n",
        "    \"/content/audio_4.mp3\",\n",
        "    \"/content/audio_5.mp3\",\n",
        "    \"/content/audio_6.mp3\",\n",
        "    \"/content/audio_7.mp3\",\n",
        "    \"/content/audio_8.mp3\",\n",
        "    \"/content/audio_9.mp3\",\n",
        "    \"/content/audio_10.mp3\"\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "qDI7xPq9s3D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example output lines\n",
        "output_lines = [\n",
        "    \"/content/audio_1_16kHz.mp3: ['हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।']\",\n",
        "    \"/content/audio_2_16kHz.mp3: ['मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।']\",\n",
        "    \"/content/audio_3_16kHz.mp3: ['बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।']\",\n",
        "    \"/content/audio_4_16kHz.mp3: ['भारत में झारखंड प्रदेश एक जिला है।']\",\n",
        "    \"/content/audio_5_16kHz.mp3: ['भारत की राजधानी दिल्ली है।']\",\n",
        "    \"/content/audio_6_16kHz.mp3: ['भारत दो हजार ग्यारह में वर्ल्ड कप जीता था।']\",\n",
        "    \"/content/audio_7_16kHz.mp3: ['दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।']\",\n",
        "    \"/content/audio_8_16kHz.mp3: ['आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।']\",\n",
        "    \"/content/audio_9_16kHz.mp3: ['भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।']\",\n",
        "    \"/content/audio_10_16kHz.mp3: ['हम राँची से है झारखंड स्टेट है हमारा।']\"\n",
        "    # ... other lines\n",
        "]\n",
        "\n",
        "# Parse the output and map audio files to their transcriptions\n",
        "transcriptions = {}\n",
        "for line in output_lines:\n",
        "    parts = line.split(\":\")\n",
        "    audio_file = parts[0].strip()\n",
        "    transcription = parts[1].strip(\" ['']\")\n",
        "    transcriptions[audio_file] = transcription\n",
        "\n",
        "# Now, transcriptions is a dictionary with audio file paths as keys and their transcriptions as values\n",
        "for audio_file, transcription in transcriptions.items():\n",
        "    print(f\"{audio_file}: {transcription}\")"
      ],
      "metadata": {
        "id": "hKEiq1KCGMGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def downsample_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Function to downsample an audio file to a given sample rate and returns the new file path.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): Path to the audio file.\n",
        "    target_sr (int, optional): Target sample rate. Defaults to 16000 Hz.\n",
        "\n",
        "    Returns:\n",
        "    str: Path to the resampled audio file.\n",
        "    \"\"\"\n",
        "    # Load the audio file with its original sample rate\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # 'sr=None' loads with the file's original sample rate\n",
        "\n",
        "    # Resample to the target sample rate\n",
        "    audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    # Save the resampled audio\n",
        "    new_file_path = file_path.replace('.mp3', '_16kHz.mp3')\n",
        "    sf.write(new_file_path, audio_resampled, target_sr)\n",
        "\n",
        "    return new_file_path\n",
        "\n",
        "# List to hold the paths of resampled audio files\n",
        "resampled_files = []\n",
        "\n",
        "# Apply the downsample function to each audio file and store the new file paths\n",
        "for file in audio_files:\n",
        "    new_file = downsample_audio(file)\n",
        "    resampled_files.append(new_file)\n",
        "\n",
        "# Now, resampled_files contains the paths to the resampled audio files\n",
        "print(resampled_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RykqtM-JFJzv",
        "outputId": "44d3c19b-3560-4110-b5a7-525a0ecbb9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/audio_1_16kHz.mp3', '/content/audio_2_16kHz.mp3', '/content/audio_3_16kHz.mp3', '/content/audio_4_16kHz.mp3', '/content/audio_5_16kHz.mp3', '/content/audio_6_16kHz.mp3', '/content/audio_7_16kHz.mp3', '/content/audio_8_16kHz.mp3', '/content/audio_9_16kHz.mp3', '/content/audio_10_16kHz.mp3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4f2gCnpLG23",
        "outputId": "19fe92df-7705-4e98-a604-4d475863eaf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/audio_1_16kHz.mp3:  खिम्दूएक की अथ्टियंद पवित्र दी खल्गा पत्ना से गुजर्ती हैं\n",
            "/content/audio_2_16kHz.mp3:  मेरनाम चन्लिल कुमार सिंग है और मेरान्ची से होँ\n",
            "/content/audio_3_16kHz.mp3:  बिहार की आद्टिक स्थिती तोडी अची मेही है\n",
            "/content/audio_4_16kHz.mp3:  बारत में जारक्ड़ पर देश एक चिला है\n",
            "/content/audio_5_16kHz.mp3:  बारत के दास्दानी दिल्ली हैं\n",
            "/content/audio_6_16kHz.mp3:  बारद 2011 में वल्कब जीता तां\n",
            "/content/audio_7_16kHz.mp3:  दून्या में बहरत की जन्संख्या भी सबसे जआदा है\n",
            "/content/audio_8_16kHz.mp3:  आज सुबवह हम लेट से उटे कल रात में लेट से सोए तें\n",
            "/content/audio_9_16kHz.mp3:  बारत की वल्गग में हार से सारे बहारतीया बहुत ही दुखित हैं\n",
            "/content/audio_10_16kHz.mp3:  अम राची से हैं जारकन श्टेट है हमारा\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model_orignal_whisper = whisper.load_model(\"small\")  # Choose model size as needed\n",
        "\n",
        "# Dictionary to hold results\n",
        "orignal_whisper_results = {}\n",
        "\n",
        "# Transcribe each audio file\n",
        "for audio_file in resampled_files:\n",
        "    result = model_orignal_whisper.transcribe(audio_file, language=\"hi\")\n",
        "    orignal_whisper_results[audio_file] = result[\"text\"]\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in orignal_whisper_results.items():\n",
        "    print(f\"{audio_file}: {transcription}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model_orignal_whisper = whisper.load_model(\"small\")  # Choose the model size as needed\n",
        "\n",
        "# Dictionary to hold results\n",
        "orignal_whisper_results = {}\n",
        "\n",
        "# Transcribe each audio file\n",
        "for audio_file in resampled_files:\n",
        "    result = model_orignal_whisper.transcribe(audio_file, language=\"hi\")\n",
        "    # Store the transcription in the dictionary as a list\n",
        "    orignal_whisper_results[audio_file] = [result[\"text\"]]\n",
        "\n",
        "# orignal_whisper_results now contains the audio file paths and their corresponding transcriptions in lists\n"
      ],
      "metadata": {
        "id": "02HEYcIZGBnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orignal_whisper_results"
      ],
      "metadata": {
        "id": "uZSL1kEpGZ7L",
        "outputId": "55b97c9a-6046-405a-9014-72a0e957a0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/audio_1_16kHz.mp3': [' खिम्दूएक की अथ्टियंद पवित्र दी खल्गा पत्ना से गुजर्ती हैं'],\n",
              " '/content/audio_2_16kHz.mp3': [' मेरनाम चन्लिल कुमार सिंग है और मेरान्ची से होँ'],\n",
              " '/content/audio_3_16kHz.mp3': [' बिहार की आद्टिक स्थिती तोडी अची मेही है'],\n",
              " '/content/audio_4_16kHz.mp3': [' बारत में जारक्ड़ पर देश एक चिला है'],\n",
              " '/content/audio_5_16kHz.mp3': [' बारत के दास्दानी दिल्ली हैं'],\n",
              " '/content/audio_6_16kHz.mp3': [' बारद 2011 में वल्कब जीता तां'],\n",
              " '/content/audio_7_16kHz.mp3': [' दून्या में बहरत की जन्संख्या भी सबसे जआदा है'],\n",
              " '/content/audio_8_16kHz.mp3': [' आज सुबवह हम लेट से उटे कल रात में लेट से सोए तें'],\n",
              " '/content/audio_9_16kHz.mp3': [' बारत की वल्गग में हार से सारे बहारतीया बहुत ही दुखित हैं'],\n",
              " '/content/audio_10_16kHz.mp3': [' अम राची से हैं जारकन श्टेट है हमारा']}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER and CER\n",
        "results_df  = calculate_wer_and_cer(transcriptions, orignal_whisper_results)\n",
        "display(HTML(results_df.to_html()))\n",
        "\n"
      ],
      "metadata": {
        "id": "A2gwgqAKGVfa",
        "outputId": "4badbc08-a628-4b27-f6e6-cdf842db9ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Sentence</th>\n",
              "      <th>Speech To Text Sentence</th>\n",
              "      <th>WER</th>\n",
              "      <th>CER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।</td>\n",
              "      <td>खिम्दूएक की अथ्टियंद पवित्र दी खल्गा पत्ना से गुजर्ती हैं</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>मेरनाम चन्लिल कुमार सिंग है और मेरान्ची से होँ</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>बिहार की आद्टिक स्थिती तोडी अची मेही है</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>बारत में जारक्ड़ पर देश एक चिला है</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>बारत के दास्दानी दिल्ली हैं</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>भारत दो हजार ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>बारद 2011 में वल्कब जीता तां</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>दून्या में बहरत की जन्संख्या भी सबसे जआदा है</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।</td>\n",
              "      <td>आज सुबवह हम लेट से उटे कल रात में लेट से सोए तें</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>बारत की वल्गग में हार से सारे बहारतीया बहुत ही दुखित हैं</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा।</td>\n",
              "      <td>अम राची से हैं जारकन श्टेट है हमारा</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Total</td>\n",
              "      <td></td>\n",
              "      <td>0.66</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WHisper integrated with deep fusion**"
      ],
      "metadata": {
        "id": "YeDv5Ley0uot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only run below code if Section 2 is not run as we download our model and make it ready to transcribe .\n"
      ],
      "metadata": {
        "id": "tZwX0GvZHI_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the model\n",
        "\n",
        "import whisper\n",
        "import kenlm\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "import torch\n",
        "import jiwer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "# using pickle to serialize the map_dict\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "filename = \"pytorch_model.bin\"\n",
        "\n",
        "\n",
        "#hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-firefox\", filename=filename, local_dir=\"/content/\")\n",
        "#hf_hub_download(repo_id=\"sanchit-gandhi/whisper-small-hi\", filename=filename, local_dir=\"/content/\")\n",
        "hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-graminVoice\", filename=filename, local_dir=\"/content/\")\n",
        "\n",
        "##We define function to import the model after doing some validation checks ex: state dictionary of model .\n",
        "\n",
        "# to enable verbose printing of exceptions (+ layers matching name)\n",
        "DEBUG = True\n",
        "\n",
        "# set to True if your custom model has been trained using DDP (multi-gpu)\n",
        "# as in my case, in the custom HF model, keys have a prefix (model.)\n",
        "# it should come from the fact that I have trained on a milti-gpu machine, using DDP\n",
        "DDP_TRAINED = True\n",
        "\n",
        "# if DDP we have to add a prefix to match with the HF state_dict\n",
        "if DDP_TRAINED:\n",
        "    PREFIX = \"model.\"\n",
        "else:\n",
        "    PREFIX = \"\"\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "# the device where you're running this code\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# the name of the file with your fine-tuned model\n",
        "FINETUNED_MODEL = \"pytorch_model.bin\"\n",
        "\n",
        "# the name of the file for the serialized map_dict\n",
        "# a different name, to avoid overwrite it\n",
        "\n",
        "\n",
        "# Generate a random suffix between 1 and 100\n",
        "suffix = random.randint(1, 100)\n",
        "\n",
        "# Append the suffix to the filename\n",
        "FILE_DICT = f\"{MODEL_SIZE}_map_dict{suffix:02d}.pkl\"\n",
        "\n",
        "# Now FILE_DICT will have a name like 'small_map_dict05.pkl', 'small_map_dict38.pkl', etc.\n",
        "  ## rename this filename from map_dict05.pkl to something else like  map_dict06.pkl , in case you run it again and again as already the model would be stored with this filename and an error with referring to model might occur\n",
        "\n",
        "def import_hf_model(finetuned_model, model_size, device, file_dict, debug=True):\n",
        "\n",
        "  def has_numbers(inputString):\n",
        "      return any(char.isdigit() for char in inputString)\n",
        "\n",
        "  # next functions are used to make sanity checks for the mappings\n",
        "\n",
        "  # get if it is encoder or decoder\n",
        "  def extract_function(key_name):\n",
        "      # encoder or decoder is the first part of the key\n",
        "      first_part = key_name.split(\".\")[0]\n",
        "\n",
        "      key_func = None\n",
        "      if first_part in [\"enconder\", \"decoder\"]:\n",
        "          key_func = first_part\n",
        "\n",
        "      return key_func\n",
        "\n",
        "  def extract_layer_num(key_name):\n",
        "      # layer num is the third piece\n",
        "      layer_num = None\n",
        "\n",
        "      if has_numbers(key_name):\n",
        "          layer_num = key_name.split(\".\")[2]\n",
        "\n",
        "      return layer_num\n",
        "\n",
        "  # check that the two keys are for layers\n",
        "  # with the same function\n",
        "  # (both encoder or both decoder)\n",
        "  # and have the same layer number\n",
        "  # this way we are super-safe (I think)\n",
        "  def sanity_check(key1, key2):\n",
        "      is_ok = True\n",
        "\n",
        "      # check same func (encoder or decoder)\n",
        "      func1 = extract_function(key1)\n",
        "      func2 = extract_function(key2)\n",
        "\n",
        "      if func1 != func2:\n",
        "          print(f\"Warning: layers seem to have different functions: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      # check same layer_num\n",
        "      layer1 = extract_layer_num(key1)\n",
        "      layer2 = extract_layer_num(key2)\n",
        "\n",
        "      if layer1 != layer2:\n",
        "          print(f\"Warning: layers seem to have different numbers: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      return is_ok\n",
        "\n",
        "  if not os.path.isfile(file_dict):\n",
        "    # Vanilla means: not custom trained\n",
        "    print()\n",
        "    print(\"Loading vanilla Whisper model\")\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "    print(\"Loading vanilla HF Model\")\n",
        "    hugging_face_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        \"openai/whisper-\" + model_size\n",
        "    ).to(device)\n",
        "\n",
        "    # extract state-dict from both\n",
        "    state_d_openai = model.state_dict()\n",
        "    state_d_huggingface = hugging_face_model.model.state_dict()\n",
        "\n",
        "    # build the mapping between keys...\n",
        "    map_dict = {}\n",
        "    print(\"Matching layers...\")\n",
        "\n",
        "    # for every layer in OpenAI model\n",
        "    n_sanity_ok = 0\n",
        "\n",
        "    #\n",
        "    # here we're considering the cartesian product of the two state dict and try to match\n",
        "    # rules applied:\n",
        "    # 1. the two layers have the same shape\n",
        "    # 2. the two layer have the same parameters' values\n",
        "    # 3. we apply sanity check (see function above)\n",
        "    #\n",
        "    for k in tqdm(state_d_openai):\n",
        "        # find a layer in the HF model, check with j\n",
        "        for j in state_d_huggingface:\n",
        "            # where parameters have same shape and same values\n",
        "            if state_d_huggingface[j].shape == state_d_openai[k].shape:\n",
        "                if torch.all(torch.eq(state_d_huggingface[j], state_d_openai[k])).item():\n",
        "                    # found, register the mapping\n",
        "                    map_dict[k] = j\n",
        "                    # make some check and eventually print a warning\n",
        "                    if sanity_check(k, j) == True:\n",
        "                        n_sanity_ok += 1\n",
        "\n",
        "                        # if you enable thsi print you can see the name of the layer\n",
        "                        # chosen in the match and you will se that they have the same functions\n",
        "                        if debug:\n",
        "                            print(k, j)\n",
        "\n",
        "                    break\n",
        "\n",
        "\n",
        "    # check if we have matched every entry\n",
        "    print(\"Check if we have matched every entry in state_dict...\")\n",
        "    print()\n",
        "    print(f\"Number of keys: {len(map_dict.keys())}\")\n",
        "    assert len(map_dict.keys()) == len(state_d_openai.keys()), \"The match is not complete !\"\n",
        "\n",
        "    print(f\"Number of sanity_check ok: {n_sanity_ok}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Match is complete !!!\")\n",
        "    print()\n",
        "\n",
        "\n",
        "    # serialize the map_dict to file\n",
        "    print(\"Serializing map_dict...\")\n",
        "\n",
        "    with open(file_dict, \"wb\") as f:\n",
        "        pickle.dump(map_dict, f)\n",
        "        f.close()\n",
        "\n",
        "    print(f\"map_dict saved as: {file_dict}...\")\n",
        "    print()\n",
        "\n",
        "  else:\n",
        "    # loading with match keys\n",
        "    # restart from pickle file\n",
        "    print(\"Reloading map_dict...\")\n",
        "    print()\n",
        "    with open(file_dict, \"rb\") as f:\n",
        "        map_dict = pickle.load(f)\n",
        "\n",
        "  # loading fine-tuned dict\n",
        "  print(\"Loading fine tuned dict...\")\n",
        "\n",
        "  # added map_location to handle the fact that the custom model has been trained on GPU\n",
        "  state_dict_finetuned = torch.load(finetuned_model, map_location=torch.device(device))\n",
        "\n",
        "  print(state_dict_finetuned.keys())\n",
        "  # build the state_dict to be used\n",
        "  # take the key name from standard (OpenAI) and the value from finetuned (HF)\n",
        "  print(\"Rebuild the state dict...\")\n",
        "  new_state_dict = {}\n",
        "  n_except = 0\n",
        "  for k in tqdm(map_dict.keys()):\n",
        "      try:\n",
        "        # You must add \"model.\" if you have used DDP in custom training\n",
        "        # see DDP_TRAINED above\n",
        "        # PREFIX is added to a HF fine-tuned 8with DDP). It is not in vanulla HF models\n",
        "        new_state_dict[k] = state_dict_finetuned[PREFIX + map_dict[k]]\n",
        "      except Exception as ex:\n",
        "        n_except += 1\n",
        "\n",
        "        if debug:\n",
        "            print(\"exception\")\n",
        "            print(PREFIX + map_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  msg_err = f\"Rebuild state dict failed, {n_except} pick failed\"\n",
        "  assert n_except == 0, msg_err\n",
        "\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(\"Loading the final model...\")\n",
        "  model.load_state_dict(new_state_dict)\n",
        "  return model\n",
        "\n",
        "\n",
        "def decode_deep_fusion(model, mel, beam_size, lm_path, lm_alpha):\n",
        "  \"\"\"\n",
        "    This function performs the deep fusion of the LM with Whisper during the beam search decoding step\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_alpha: A numerical value representing the weight assigned to the language model scores during deep fusion.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=beam_size,\n",
        "        patience=0.7, lm_path=lm_path, lm_alpha=lm_alpha, lm_beta=0.1,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n",
        "\n",
        "\n",
        "def decode_shallow_fusion_nbest(model, mel, best_of, lm_path, temperature, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (greedy decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - best_of: An integer specifying the number of best hypotheses to consider during decoding.\n",
        "    - lm_path: A string representing the path to the language model used for fusion.\n",
        "    - temperature: A numerical value indicating the temperature parameter used during sampling. Higher temperature corresponds to more variation in the n best list\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful when finding the optimal value for the lm_weight\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, best_of=best_of, return_nbest=True, without_timestamps=True, temperature=temperature, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "        nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "        normalized_scores = [(text,\n",
        "                              whisper_score / len(text.split()),\n",
        "                              lm_model.score(text) / len(text.split()))\n",
        "                             for text, whisper_score, _ in nbest_with_lm_score]\n",
        "        combined_score = [(text,\n",
        "                           (whisper_score ** 2) + (lm_weight * lm_score ** 2),\n",
        "                           whisper_score,\n",
        "                           lm_score)\n",
        "                          for text, whisper_score, lm_score in normalized_scores]\n",
        "        combined_score.sort(key=lambda t: t[1], reverse=False)\n",
        "        combined_scores.append(combined_score)\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = []\n",
        "  for datapoint in combined_scores:\n",
        "    combined_score = datapoint[0]\n",
        "    hyp, comb_score, w_score, lm_score = combined_score\n",
        "    result.append(hyp)\n",
        "  # result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result\n",
        "\n",
        "  # Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Aq4Gf8FgG8mJ",
        "outputId": "cbd80a12-0e0a-44fc-f930-6bc69cc7fd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 256MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'language_model_3p0.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  model = import_hf_model(finetuned_model=FINETUNED_MODEL, debug= False, model_size=MODEL_SIZE, device=DEVICE, file_dict=FILE_DICT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13qIHIA4Vq0J",
        "outputId": "832e10dd-e539-4439-9399-e5ba6a729e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading vanilla Whisper model\n",
            "Loading vanilla HF Model\n",
            "Matching layers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:01<00:00, 270.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if we have matched every entry in state_dict...\n",
            "\n",
            "Number of keys: 479\n",
            "Number of sanity_check ok: 479\n",
            "\n",
            "Match is complete !!!\n",
            "\n",
            "Serializing map_dict...\n",
            "map_dict saved as: small_map_dict45.pkl...\n",
            "\n",
            "Loading fine tuned dict...\n",
            "odict_keys(['model.encoder.conv1.weight', 'model.encoder.conv1.bias', 'model.encoder.conv2.weight', 'model.encoder.conv2.bias', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layer_norm.weight', 'model.encoder.layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layer_norm.weight', 'model.decoder.layer_norm.bias', 'proj_out.weight'])\n",
            "Rebuild the state dict...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:00<00:00, 856746.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the final model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with deep fusion with beam search**"
      ],
      "metadata": {
        "id": "ezp_EZCEXCMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 10\n",
        "lm_alpha = 0.1\n",
        "#Best WER: 0.1517509727626459 achieved with Beam Size: 5 and LM Alpha: 0.1\n",
        "whisper_results_with_deep_fusion_beam_search = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # decode_baseline decode_shallow_fusion_beam_search\n",
        "# result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# result\n",
        "\n",
        "global resampled_files\n",
        "# Transcribe each audio file\n",
        "for audio_file in resampled_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "    whisper_results_with_deep_fusion_beam_search[audio_file] = result\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in whisper_results_with_deep_fusion_beam_search.items():\n",
        "    print(f\"{audio_file}: {transcription}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-cdfm_JXMMc",
        "outputId": "e27a2b0a-1803-4c6a-d65e-2f0ab3876b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/audio_1_16kHz.mp3: ['हिंदुओं की अत्यन्थ-पवित्र भी गंगा पटना से गुजरती है।']\n",
            "/content/audio_2_16kHz.mp3: ['मेरे नाम चंद कुमार सिंह है और मैं रांची से हूँ।']\n",
            "/content/audio_3_16kHz.mp3: ['बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।']\n",
            "/content/audio_4_16kHz.mp3: ['भारत में झारखंड प्रदेश एक जिला है।']\n",
            "/content/audio_5_16kHz.mp3: ['भारत की राजधानी दिल्ली है।']\n",
            "/content/audio_6_16kHz.mp3: ['भारत दो हज़ार ग्यारह में वर्ल्ड कप जीता था।']\n",
            "/content/audio_7_16kHz.mp3: ['दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।']\n",
            "/content/audio_8_16kHz.mp3: ['आज सुबह हम लेट्स उठे कल रात में लेट्स से सोए थे।']\n",
            "/content/audio_9_16kHz.mp3: ['भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।']\n",
            "/content/audio_10_16kHz.mp3: ['हम राँची से है झारखंड स्टेट है हमारा']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jiwer\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def calculate_wer_and_cer(inputs, outputs):\n",
        "    data = []\n",
        "\n",
        "    total_wer = 0\n",
        "    count = 0\n",
        "\n",
        "    for key, ref_transcription in inputs.items():\n",
        "        hyp_transcription = outputs[key][0] if key in outputs and outputs[key] else \"\"\n",
        "\n",
        "        wer = jiwer.wer(ref_transcription, hyp_transcription)\n",
        "        cer = jiwer.cer(ref_transcription, hyp_transcription)\n",
        "\n",
        "        total_wer += wer\n",
        "        count += 1\n",
        "\n",
        "        data.append({\n",
        "            \"Actual Sentence\": ref_transcription,\n",
        "            \"Speech To Text Sentence\": hyp_transcription,\n",
        "            \"WER\": round(wer, 2),\n",
        "            \"CER\": round(cer, 2)\n",
        "        })\n",
        "\n",
        "    # Adding total WER\n",
        "    data.append({\n",
        "        \"Actual Sentence\": \"Total\",\n",
        "        \"Speech To Text Sentence\": \"\",\n",
        "        \"WER\": round(total_wer / count, 2) if count > 0 else 0,\n",
        "        \"CER\": \"\"\n",
        "    })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pp6RRRkntmlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER and CER\n",
        "results_df  = calculate_wer_and_cer(transcriptions, whisper_results_with_deep_fusion_beam_search)\n",
        "display(HTML(results_df.to_html()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "zj45LL9UtvLR",
        "outputId": "9ccf361b-f89f-4758-8fb9-6c9bba5d557f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Sentence</th>\n",
              "      <th>Speech To Text Sentence</th>\n",
              "      <th>WER</th>\n",
              "      <th>CER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।</td>\n",
              "      <td>हिंदुओं की अत्यन्थ-पवित्र भी गंगा पटना से गुजरती है।</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>मेरे नाम चंद कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>भारत दो हजार ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>भारत दो हज़ार ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।</td>\n",
              "      <td>आज सुबह हम लेट्स उठे कल रात में लेट्स से सोए थे।</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा।</td>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Total</td>\n",
              "      <td></td>\n",
              "      <td>0.09</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with shallow fusion and greedy decoding:**"
      ],
      "metadata": {
        "id": "oEKn50DSpuO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "best_of = 5\n",
        "temperature = 0.1\n",
        "lm_weight = .9\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "\n",
        "\n",
        "whisper_results_with_shallow_fusion_greedy_decoding = {}\n",
        "\n",
        "# audio = whisper.load_audio(\"/content/audio_1.wav\")\n",
        "# audio = whisper.pad_or_trim(audio)\n",
        "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# # decode_baseline decode_shallow_fusion_beam_search\n",
        "# result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "# result\n",
        "\n",
        "global resampled_files\n",
        "# Transcribe each audio file\n",
        "for audio_file in resampled_files:\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "    whisper_results_with_shallow_fusion_greedy_decoding[audio_file] = result\n",
        "\n",
        "# Print the results\n",
        "for audio_file, transcription in whisper_results_with_shallow_fusion_greedy_decoding.items():\n",
        "    print(f\"{audio_file}: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Xp3eU7jIp3",
        "outputId": "2c8cd395-e1b8-4c17-8b83-8596ff2f8233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/audio_1_16kHz.mp3: ['हिन्दूओं की अत्यन्थ-पवित्र भी गंगा पटना से गुजरती है।']\n",
            "/content/audio_2_16kHz.mp3: ['मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।']\n",
            "/content/audio_3_16kHz.mp3: ['बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।']\n",
            "/content/audio_4_16kHz.mp3: ['भारत में झारखंड प्रदेश एक जिला है।']\n",
            "/content/audio_5_16kHz.mp3: ['भारत की राजधानी दिल्ली है।']\n",
            "/content/audio_6_16kHz.mp3: ['भारत दो हज़र ग्यारह में वर्ल्ड कप जीता था।']\n",
            "/content/audio_7_16kHz.mp3: ['दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।']\n",
            "/content/audio_8_16kHz.mp3: ['आज सुबह हम लेट्स उठे कल रात में लेट्स से सोए थे।']\n",
            "/content/audio_9_16kHz.mp3: ['भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।']\n",
            "/content/audio_10_16kHz.mp3: ['हमराची से है झारखंड स्टेट है हमारा']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER and CER\n",
        "results_df  = calculate_wer_and_cer(transcriptions, whisper_results_with_shallow_fusion_greedy_decoding)\n",
        "display(HTML(results_df.to_html()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "sWUxq79lwA3d",
        "outputId": "4b8d9046-31dd-44d8-ac72-29540bd05af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Sentence</th>\n",
              "      <th>Output Sentence</th>\n",
              "      <th>WER</th>\n",
              "      <th>CER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।</td>\n",
              "      <td>हिन्दूओं की अत्यन्थ-पवित्र भी गंगा पटना से गुजरती है।</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>भारत दो हजार ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>भारत दो हज़र ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।</td>\n",
              "      <td>आज सुबह हम लेट्स उठे कल रात में लेट्स से सोए थे।</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा।</td>\n",
              "      <td>हमराची से है झारखंड स्टेट है हमारा</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Total</td>\n",
              "      <td></td>\n",
              "      <td>0.11</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beam Search and Deep Fused model and Greedy Search Shallow Fused model are very close but Beam search takes the lead . WHisper orignal is far from accuracy ."
      ],
      "metadata": {
        "id": "86wzeWB1iqnt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ofgIloKYdf"
      },
      "source": [
        "###3.2 Orignal Wave2wec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hXopFc9cSJj",
        "outputId": "17faebfc-ab55-4e24-bbdc-7867a0df3b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:733: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************* Wav2Vec2 Transcription ***************** \n",
            "{'/content/audio_1_16kHz.mp3': ['EN DUOKI A DEMME TE POVITRAL DIGANGA WHIKE NOTING WAS AT TIER'], '/content/audio_2_16kHz.mp3': ['MAYNAM GENDLE COMA SING HE OR BERATISILO'], '/content/audio_3_16kHz.mp3': ['BIHAKIANTIS TI PITORYA TIMIGIGI'], '/content/audio_4_16kHz.mp3': ['MAHADA MITAR KAN KAVISH IKJILA'], '/content/audio_5_16kHz.mp3': ['BARATI DAS MANI TE LIER'], '/content/audio_6_16kHz.mp3': ['NOTTED DOWAS A AGADA MIWORKO JIDATAM'], '/content/audio_7_16kHz.mp3': ['DUNYA MEBAREKIDAN SANKOUT HI SUBSES ZATAHE'], '/content/audio_8_16kHz.mp3': ['OUR SUBERHUM LADE SU TAKE O THAT MAYLAD SESOYETY'], '/content/audio_9_16kHz.mp3': ['BALATGIVORCOV MEHARSI SAREBARTIO BOXOTI DUCUETAIN'], '/content/audio_10_16kHz.mp3': [\"HAMORAJI'S A HEAHAD GUN STAYED HEHAMATA\"]}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model_facebook = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "# Function to read and preprocess the audio file\n",
        "def speech_file_to_array_fn(path):\n",
        "    speech_array, sampling_rate = sf.read(path)\n",
        "    return speech_array\n",
        "\n",
        "# Function to perform inference\n",
        "def asr_transcript(audio_file):\n",
        "    # Load and preprocess the audio\n",
        "    speech = speech_file_to_array_fn(audio_file)\n",
        "    input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        logits = model_facebook(input_values).logits\n",
        "\n",
        "    # Get predicted IDs and decode them to text\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = tokenizer.batch_decode(predicted_ids)\n",
        "\n",
        "    return transcription[0]\n",
        "\n",
        "# Assuming 'resampled_files' is a list of your audio files\n",
        "transcriptions_dict = {}\n",
        "\n",
        "for file in resampled_files:\n",
        "    transcription = asr_transcript(file)\n",
        "    transcriptions_dict[file] = [transcription]\n",
        "\n",
        "# Print for verification, you can remove this in the final version\n",
        "print(\"******************* Wav2Vec2 Transcription ***************** \")\n",
        "print(transcriptions_dict)\n",
        "print(\"------------------------------------------------------------\")\n",
        "\n",
        "# 'transcriptions_dict' now contains your audio file paths and their corresponding transcriptions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER and CER\n",
        "results_df  = calculate_wer_and_cer(transcriptions, transcriptions_dict)\n",
        "display(HTML(results_df.to_html()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "L7KQ8pCCwFuz",
        "outputId": "e3e0f2fb-47c8-487a-8b07-d0e6f532d001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Sentence</th>\n",
              "      <th>Output Sentence</th>\n",
              "      <th>WER</th>\n",
              "      <th>CER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।</td>\n",
              "      <td>EN DUOKI A DEMME TE POVITRAL DIGANGA WHIKE NOTING WAS AT TIER</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>MAYNAM GENDLE COMA SING HE OR BERATISILO</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>BIHAKIANTIS TI PITORYA TIMIGIGI</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>MAHADA MITAR KAN KAVISH IKJILA</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>BARATI DAS MANI TE LIER</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>भारत दो हज़र ग्यारह में वर्लकप जीता था।</td>\n",
              "      <td>NOTTED DOWAS A AGADA MIWORKO JIDATAM</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>DUNYA MEBAREKIDAN SANKOUT HI SUBSES ZATAHE</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।</td>\n",
              "      <td>OUR SUBERHUM LADE SU TAKE O THAT MAYLAD SESOYETY</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>BALATGIVORCOV MEHARSI SAREBARTIO BOXOTI DUCUETAIN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा।</td>\n",
              "      <td>HAMORAJI'S A HEAHAD GUN STAYED HEHAMATA</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Total</td>\n",
              "      <td></td>\n",
              "      <td>1.02</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facebook Wave2wec is worse performing for Hindi transcription ."
      ],
      "metadata": {
        "id": "HJehocRcjHeH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jpnOwYUKc15"
      },
      "source": [
        "###3.3 Google USM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "uDfTKL4PeFSy",
        "outputId": "1b589968-1b0f-449c-e714-85e59508f81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-speech\n",
            "  Downloading google_cloud_speech-2.22.0-py2.py3-none-any.whl (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/275.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/275.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.61.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.59.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.5.0)\n",
            "Installing collected packages: google-cloud-speech\n",
            "Successfully installed google-cloud-speech-2.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.8.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "#Google USM\n",
        "!pip install google-cloud-speech\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW125a12CNY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drivedownloaduplaod-eed71df0371c (1).json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S58lF2odEu9x",
        "outputId": "0a30c7f8-d6e0-4bcc-e835-6c19a4db399a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/audio_1_16kHz.flac', '/content/audio_2_16kHz.flac', '/content/audio_3_16kHz.flac', '/content/audio_4_16kHz.flac', '/content/audio_5_16kHz.flac', '/content/audio_6_16kHz.flac', '/content/audio_7_16kHz.flac', '/content/audio_8_16kHz.flac', '/content/audio_9_16kHz.flac', '/content/audio_10_16kHz.flac']\n"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def convert_to_flac(audio_files_list):\n",
        "    \"\"\"\n",
        "    Convert a list of audio files to FLAC format.\n",
        "\n",
        "    Parameters:\n",
        "    audio_files_list (list): List of paths to the audio files.\n",
        "\n",
        "    Returns:\n",
        "    list: List of paths to the converted FLAC files.\n",
        "    \"\"\"\n",
        "    flac_files_list = []\n",
        "\n",
        "    for wav_file in audio_files_list:\n",
        "        # Load the WAV file\n",
        "        wav_audio = AudioSegment.from_file(wav_file, format=\"mp3\")\n",
        "\n",
        "        # Define the path for the new FLAC file\n",
        "        flac_file = wav_file.replace(\".mp3\", \".flac\")\n",
        "\n",
        "        # Export as FLAC\n",
        "        wav_audio.export(flac_file, format=\"flac\")\n",
        "\n",
        "        # Add the new FLAC file path to the list\n",
        "        flac_files_list.append(flac_file)\n",
        "\n",
        "    return flac_files_list\n",
        "\n",
        "\n",
        "# Convert all files in the list to FLAC\n",
        "flac_files = convert_to_flac(resampled_files)\n",
        "\n",
        "# flac_files now contains the paths to the converted FLAC files\n",
        "print(flac_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of audio files\n",
        "gc_audio_files_url_1 = [\n",
        "    \"gs://test_310189/audio_1_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_2_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_3_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_4_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_5_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_6_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_7_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_8_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_9_16kHz.flac\",\n",
        "    \"gs://test_310189/audio_10_16kHz.flac\"\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "WLaweUzaPWK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import subprocess\n",
        "\n",
        "# Function to get the Google Cloud access token\n",
        "def get_access_token():\n",
        "    result = subprocess.run(['gcloud', 'auth', 'application-default', 'print-access-token'], capture_output=True, text=True)\n",
        "    return result.stdout.strip()\n",
        "\n",
        "# Get the access token\n",
        "access_token = get_access_token()\n",
        "\n",
        "# Path to the JSON file\n",
        "json_file_path = '/content/sync-request.json'\n",
        "\n",
        "# Dictionary to store the results\n",
        "google_transcriptions_dict = {}\n",
        "\n",
        "# Iterate over the URLs\n",
        "for url in gc_audio_files_url_1:\n",
        "    # Read the JSON file\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Update the 'uri' field\n",
        "    data['audio']['uri'] = url\n",
        "\n",
        "    # Write back to the JSON file\n",
        "    with open(json_file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "    # Prepare the curl command\n",
        "    curl_command = [\n",
        "        \"curl\", \"-s\", \"-H\", \"Content-Type: application/json\",\n",
        "        \"-H\", f\"Authorization: Bearer {access_token}\",\n",
        "        \"https://speech.googleapis.com/v1/speech:recognize\",\n",
        "        \"-d\", f\"@{json_file_path}\"\n",
        "    ]\n",
        "\n",
        "    # Run the curl command and capture the output\n",
        "    result = subprocess.run(curl_command, check=True, capture_output=True, text=True)\n",
        "\n",
        "    # Parse the output as JSON\n",
        "    response = json.loads(result.stdout)\n",
        "\n",
        "    # Extract and store the transcript\n",
        "    transcript = \"\"\n",
        "    for res in response.get('results', []):\n",
        "        for alt in res.get('alternatives', []):\n",
        "            transcript = alt.get('transcript', \"\")\n",
        "            break  # Assuming you only need the first alternative\n",
        "        if transcript:\n",
        "            break  # Exit after the first non-empty transcript\n",
        "\n",
        "    # Add the transcript to the dictionary\n",
        "    google_transcriptions_dict[url] = transcript\n",
        "\n",
        "# 'transcriptions_dict' now contains your audio file URLs and their corresponding transcriptions\n"
      ],
      "metadata": {
        "id": "ovHrYjs0zmCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_updated_dict = {}\n",
        "\n",
        "for key in google_transcriptions_dict:\n",
        "    # Extract the part of the key after the last '/'\n",
        "    file_name = key.split('/')[-1]\n",
        "\n",
        "    # Replace the file extension from .flac to .mp3\n",
        "    new_file_name = file_name.replace('.flac', '.mp3')\n",
        "\n",
        "    # Construct the new key\n",
        "    new_key = f'/content/{new_file_name}'\n",
        "\n",
        "    # Assign the value from the original dictionary to the new key in updated_dict\n",
        "    # Ensure the value is put into a list\n",
        "    google_updated_dict[new_key] = [google_transcriptions_dict[key]]\n",
        "\n",
        "# google_updated_dict now contains the updated keys with values in lists\n",
        "print(google_updated_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRZ_zgxx4uMP",
        "outputId": "f2d7b9eb-2c83-4095-fa3f-55add47408be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'/content/audio_1_16kHz.mp3': ['हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है'], '/content/audio_2_16kHz.mp3': ['मेरा नाम चंदन कुमार सिंह है और मैं रांची से हूं'], '/content/audio_3_16kHz.mp3': ['बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है'], '/content/audio_4_16kHz.mp3': ['भारत में झारखंड प्रदेश एक जिला है'], '/content/audio_5_16kHz.mp3': ['भारत की राजधानी दिल्ली है'], '/content/audio_6_16kHz.mp3': ['भारत 2011 में वर्ल्ड कप जीता था'], '/content/audio_7_16kHz.mp3': ['दुनिया में भारत की जनसंख्या अधिक सबसे ज्यादा है'], '/content/audio_8_16kHz.mp3': ['आज सुबह हम लेट से उठे कल रात में लेट से सोए थे'], '/content/audio_9_16kHz.mp3': ['भारत की वर्ल्ड कप में हादसे सारे भारतीय बहुत ही दुखद है'], '/content/audio_10_16kHz.mp3': ['हम रांची से झारखंड स्टेट है हमारा']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_updated_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saBQANTB56sZ",
        "outputId": "ce302895-fdbe-4e88-8d33-82c37498f990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/audio_1_16kHz.mp3': ['हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है'],\n",
              " '/content/audio_2_16kHz.mp3': ['मेरा नाम चंदन कुमार सिंह है और मैं रांची से हूं'],\n",
              " '/content/audio_3_16kHz.mp3': ['बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है'],\n",
              " '/content/audio_4_16kHz.mp3': ['भारत में झारखंड प्रदेश एक जिला है'],\n",
              " '/content/audio_5_16kHz.mp3': ['भारत की राजधानी दिल्ली है'],\n",
              " '/content/audio_6_16kHz.mp3': ['भारत 2011 में वर्ल्ड कप जीता था'],\n",
              " '/content/audio_7_16kHz.mp3': ['दुनिया में भारत की जनसंख्या अधिक सबसे ज्यादा है'],\n",
              " '/content/audio_8_16kHz.mp3': ['आज सुबह हम लेट से उठे कल रात में लेट से सोए थे'],\n",
              " '/content/audio_9_16kHz.mp3': ['भारत की वर्ल्ड कप में हादसे सारे भारतीय बहुत ही दुखद है'],\n",
              " '/content/audio_10_16kHz.mp3': ['हम रांची से झारखंड स्टेट है हमारा']}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER and CER\n",
        "results_df  = calculate_wer_and_cer(transcriptions, google_updated_dict)\n",
        "display(HTML(results_df.to_html()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "lX0njZFOyrlM",
        "outputId": "2cc8ed3c-f26d-4321-fe1e-2ed987dee983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Sentence</th>\n",
              "      <th>Output Sentence</th>\n",
              "      <th>WER</th>\n",
              "      <th>CER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है।</td>\n",
              "      <td>हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे नाम चंदन कुमार सिंह है और मैं रांची से हूँ।</td>\n",
              "      <td>मेरा नाम चंदन कुमार सिंह है और मैं रांची से हूं</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है।</td>\n",
              "      <td>बिहार की आर्थिक स्थिति थोड़ी अच्छी नहीं है</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है।</td>\n",
              "      <td>भारत में झारखंड प्रदेश एक जिला है</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भारत की राजधानी दिल्ली है।</td>\n",
              "      <td>भारत की राजधानी दिल्ली है</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>भारत दो हजार ग्यारह में वर्ल्ड कप जीता था।</td>\n",
              "      <td>भारत 2011 में वर्ल्ड कप जीता था</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दुनिया में भारत की जनसंख्या अभी सबसे ज़्यादा है।</td>\n",
              "      <td>दुनिया में भारत की जनसंख्या अधिक सबसे ज्यादा है</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे।</td>\n",
              "      <td>आज सुबह हम लेट से उठे कल रात में लेट से सोए थे</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>भारत की वर्ल्ड कप में हार से सारे भारतीय बहुत ही दुखित है।</td>\n",
              "      <td>भारत की वर्ल्ड कप में हादसे सारे भारतीय बहुत ही दुखद है</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>हम राँची से है झारखंड स्टेट है हमारा।</td>\n",
              "      <td>हम रांची से झारखंड स्टेट है हमारा</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Total</td>\n",
              "      <td></td>\n",
              "      <td>0.23</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -s -H \"Content-Type: application/json\" \\\n",
        "#     -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "#     https://speech.googleapis.com/v1/speech:recognize \\\n",
        "#     -d @sync-request.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJmdj8Tx8YP2",
        "outputId": "a02953e6-918a-4225-ddc6-30f358065778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"भारत की राजधानी दिल्ली है\",\n",
            "          \"confidence\": 0.9577488\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"2.430s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"3s\",\n",
            "  \"requestId\": \"1269373751260805310\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hypothetical accuracy data for each model\n",
        "models = ['Deep Fusion Custom Whisper', 'Shallow Fusion Whisper', 'Google USM', 'Original Whisper', 'Facebook Wave2Vec']\n",
        "WER = [0.09, 0.11 , 0.23 ,0.66, 1.02]  # Example accuracy percentages\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, WER, color='skyblue')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Model WER Comparison , Lower the WER - Better is Accuracy ')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('WER (%)')\n",
        "plt.xticks(rotation=45)  # Rotate the model names for better readability\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GSOdzrjlOFEj",
        "outputId": "b468ce62-8bf9-4eae-fd7c-2740f2f107d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "n2tQ_aF0P7eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Custom Whisper Performance Analysis:\n",
        "> \"Our custom Whisper model demonstrates commendable performance, closely competing with Google's USM.\"\n",
        "2. Google USM Performance Insights:\n",
        "> Punctuation Handling: Google USM's performance is generally good, but it tends to overlook punctuation marks, such as '|', which is often equivalent to a full stop.<br>\n",
        "> Transcription Accuracy: While the transcription quality is satisfactory, it occasionally misinterprets certain Hindi words, for example, rendering 'हादसे' instead of 'हार से' and '2011' instead of 'दो हजार ग्यारह'.\n",
        "3. Comparative Transcription Analysis:\n",
        "> \"In a particular instance, the transcription by Google USM ('हिंदुओं की अत्यंत पवित्र नदी गंगा पटना से गुजरती है') was superior to our custom Whisper model's output ('हिन्दूओं की अत्यन्थ-पवित्र भी गंगा पटना से गुजरती है।').\"\n",
        "4. Overall Model Performance Comparison:\n",
        "> \"Overall, these models exhibit performance enhancements compared to the original Whisper and Facebook's Wave2Vec models.\"\n",
        "5. Model Performance Ranking:\n",
        "> <b>Best Performance</b>: Deep Fusion Custom Whisper model emerges as the most effective. <br>\n",
        "> <b>Close Competitors</b>: Followed by the Shallow Fusion Whisper and then Google USM. If we disregard punctuation errors in Google USM, it closely rivals the Shallow Fusion Whisper.<br>\n",
        "> <b>Next in Line</b>: The Original Whisper ranks next in the list.<br>\n",
        "> <b>Least Effective</b>: Facebook's Wave2Vec model, however, is significantly less effective for Hindi transcription. Upon further investigation, we found that it is not well-optimized for the Hindi language."
      ],
      "metadata": {
        "id": "N6_c5pXDkSHU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k95oodnAOqDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "150486309a0540b0a51a96664f78aba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "24c1c8f49f5a43eab9b1b9f9f0a12fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273a08df24d343a7a227d09b9e23ebb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b858b805f54292a322d13611833c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd766dafea94135862b6e9e0d9876cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f065f61e9e1443a85aee518670a4fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "style": "IPY_MODEL_e543d211badc4d41bd944df904ce0317",
            "value": true
          }
        },
        "455bae593a3240d9ba064c213a90ece9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4928327c81124c60bd8e3aca15942167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7390656d2d4240969f6202876d1a57c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a0a08417de42e88bdf8ffc693f42b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b595673f6a4db4a47a25e88ebc2d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_981bc86f56014362942f1fad9d5fe00c",
            "value": "Token is valid (permission: write)."
          }
        },
        "773b457557fd4352a317068d87fa4eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5806a46c454e0c9c3f1ca5f70d4279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455bae593a3240d9ba064c213a90ece9",
            "placeholder": "​",
            "style": "IPY_MODEL_ba5939381af044029e254989149974db",
            "value": "Connecting..."
          }
        },
        "8536aa41d17347508a262bbc9693b7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75a0a08417de42e88bdf8ffc693f42b6",
              "IPY_MODEL_bb853deecb594dad80ae466afa531d75",
              "IPY_MODEL_920da0787e654f6bb9a0c76cc88f0f5c",
              "IPY_MODEL_bbb0d45741c8401b819941a9eda1c1a7"
            ],
            "layout": "IPY_MODEL_150486309a0540b0a51a96664f78aba7"
          }
        },
        "920da0787e654f6bb9a0c76cc88f0f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7390656d2d4240969f6202876d1a57c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "981bc86f56014362942f1fad9d5fe00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f33f70e05d4897aac484cb940392d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1471db6c574235ac5967dd80734786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9c06e19a154517b4ff46c7a52d29d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed79d83bbe84ba5aa53f601588c4ee8",
            "placeholder": "​",
            "style": "IPY_MODEL_28b858b805f54292a322d13611833c33",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "aed79d83bbe84ba5aa53f601588c4ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b805718a8b76423386511730e0fdeaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b595673f6a4db4a47a25e88ebc2d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba507efc55c145419acdec6f0fb62b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773b457557fd4352a317068d87fa4eef",
            "placeholder": "​",
            "style": "IPY_MODEL_b805718a8b76423386511730e0fdeaff",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ba5939381af044029e254989149974db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba67e8ff964d4073b870e1200a87fd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d6ef36d77a09460d82ce46f28df66665",
            "style": "IPY_MODEL_c16fa1150d12439688fa21af50d995c7",
            "tooltip": ""
          }
        },
        "bb853deecb594dad80ae466afa531d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f33f70e05d4897aac484cb940392d4",
            "placeholder": "​",
            "style": "IPY_MODEL_4928327c81124c60bd8e3aca15942167",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "bbb0d45741c8401b819941a9eda1c1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273a08df24d343a7a227d09b9e23ebb4",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd766dafea94135862b6e9e0d9876cf",
            "value": "Login successful"
          }
        },
        "c16fa1150d12439688fa21af50d995c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d6ef36d77a09460d82ce46f28df66665": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e543d211badc4d41bd944df904ce0317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0885c2a4abd4fe6902ca4f7aba7b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f96cd823f757434997f49f4b2c7d2a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab1471db6c574235ac5967dd80734786",
            "placeholder": "​",
            "style": "IPY_MODEL_ff114fffeab840c6a8fab1662d1dddd7",
            "value": ""
          }
        },
        "ff114fffeab840c6a8fab1662d1dddd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87eb53498bc343dcbfd83a09b0dffabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f99611bb13cf48978f4528abe35c94ca",
              "IPY_MODEL_8aaaa39b4ea7480180d87baba74d9f57",
              "IPY_MODEL_6272a6a5629043eda1053d431274e311"
            ],
            "layout": "IPY_MODEL_fef0b24d0dca40afb97fb1a7dfecda9c"
          }
        },
        "f99611bb13cf48978f4528abe35c94ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219f999ff1e94f459715a5d27a209889",
            "placeholder": "​",
            "style": "IPY_MODEL_1eb6c7cc83e04ef28d3588aea44b8968",
            "value": "Downloading data: 100%"
          }
        },
        "8aaaa39b4ea7480180d87baba74d9f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df54bd2301f48d38c3cd1ba57a8862b",
            "max": 12463616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91e313e5d1c148249be2da0090fdadbb",
            "value": 12463616
          }
        },
        "6272a6a5629043eda1053d431274e311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1736f1f8f0746759724d1bf596c43ab",
            "placeholder": "​",
            "style": "IPY_MODEL_bfdabc82cf3d4ee08de3b15eabee8683",
            "value": " 12.5M/12.5M [00:00&lt;00:00, 60.2MB/s]"
          }
        },
        "fef0b24d0dca40afb97fb1a7dfecda9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219f999ff1e94f459715a5d27a209889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eb6c7cc83e04ef28d3588aea44b8968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df54bd2301f48d38c3cd1ba57a8862b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e313e5d1c148249be2da0090fdadbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1736f1f8f0746759724d1bf596c43ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdabc82cf3d4ee08de3b15eabee8683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05cb9b0b58cc4958a1a0768ed5c0bf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f4d4bac262c4647be909b8b99bcd80c",
              "IPY_MODEL_2c3d02d94ab34bddb128b2054b0a7a06",
              "IPY_MODEL_bdeba3611e0a4f5eb999ca74e0871df7"
            ],
            "layout": "IPY_MODEL_7a317f9b94bb49b69edaa6a93231ddec"
          }
        },
        "9f4d4bac262c4647be909b8b99bcd80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_261ceb3cf8c2433192c47829653e47bf",
            "placeholder": "​",
            "style": "IPY_MODEL_22c9ab8413414a7b8152971d43cb6859",
            "value": "Generating txt.done.data.utf8 split: "
          }
        },
        "2c3d02d94ab34bddb128b2054b0a7a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a7ea7bd571491d8ac144458d4c7250",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc3bb2339b894e43adf92198cacbe7aa",
            "value": 1
          }
        },
        "bdeba3611e0a4f5eb999ca74e0871df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39079201a5704207b09282801a3f9ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_da1e977bfc7d45d08307e64ea191fddd",
            "value": " 1000/0 [00:00&lt;00:00, 1980.83 examples/s]"
          }
        },
        "7a317f9b94bb49b69edaa6a93231ddec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261ceb3cf8c2433192c47829653e47bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c9ab8413414a7b8152971d43cb6859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a7ea7bd571491d8ac144458d4c7250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fc3bb2339b894e43adf92198cacbe7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39079201a5704207b09282801a3f9ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1e977bfc7d45d08307e64ea191fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07064292c8374a69874cef5799adeb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b048f0b5247d4eb18f2af761236b9697",
              "IPY_MODEL_0b3aa4beac1c41d1be4e1b131f08c47b",
              "IPY_MODEL_cef8a2e7e98c432fa7d77a090a56aad8"
            ],
            "layout": "IPY_MODEL_c179f2c779ab45189d68fcc499df31fb"
          }
        },
        "b048f0b5247d4eb18f2af761236b9697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087f6c3f571446edbd58375140e4e145",
            "placeholder": "​",
            "style": "IPY_MODEL_4386a4e3defa430caa888ee9e2ff6175",
            "value": "Downloading data: 100%"
          }
        },
        "0b3aa4beac1c41d1be4e1b131f08c47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a0ed0d39aa4991b453cd5a1f91a4e9",
            "max": 452581888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d89d53a21c3948b1b7d9a36991439f67",
            "value": 452581888
          }
        },
        "cef8a2e7e98c432fa7d77a090a56aad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1fdc97875f4ad58d714a2c8b6d4268",
            "placeholder": "​",
            "style": "IPY_MODEL_fad1ebded3794fb6bd3c7966f6b23b5b",
            "value": " 453M/453M [00:06&lt;00:00, 84.7MB/s]"
          }
        },
        "c179f2c779ab45189d68fcc499df31fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087f6c3f571446edbd58375140e4e145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4386a4e3defa430caa888ee9e2ff6175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09a0ed0d39aa4991b453cd5a1f91a4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89d53a21c3948b1b7d9a36991439f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c1fdc97875f4ad58d714a2c8b6d4268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad1ebded3794fb6bd3c7966f6b23b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00118bd7f6a34c4cbd607eca312e413d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_616c5731cf374615b9a94d0333d1982a",
              "IPY_MODEL_32897cad5b2d4592820e1a86bc1e72c8",
              "IPY_MODEL_f547ce81afab403a8c1ab01ad6e82318"
            ],
            "layout": "IPY_MODEL_7994120056a74fe4bc219a8f78b1740a"
          }
        },
        "616c5731cf374615b9a94d0333d1982a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea200594f1b4291a74eebf7bd1e6fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_c7958d371e1144a7a4b67fea63fc934d",
            "value": "Generating train split: "
          }
        },
        "32897cad5b2d4592820e1a86bc1e72c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bebf678d96964ccab9cb17a36a4f5ac9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04fce5d2833e421683b8328e395bd301",
            "value": 1
          }
        },
        "f547ce81afab403a8c1ab01ad6e82318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc062c4900374d2bafc7f90d7b3da848",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e25b4c8370487db868604b5f53c8ae",
            "value": " 4630/0 [00:02&lt;00:00, 2075.50 examples/s]"
          }
        },
        "7994120056a74fe4bc219a8f78b1740a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea200594f1b4291a74eebf7bd1e6fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7958d371e1144a7a4b67fea63fc934d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bebf678d96964ccab9cb17a36a4f5ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "04fce5d2833e421683b8328e395bd301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc062c4900374d2bafc7f90d7b3da848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e25b4c8370487db868604b5f53c8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d24f54fef5c4ad9963147941eb2f69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffe1b371614c4a5ba639ec7c171d2e5f",
              "IPY_MODEL_71f00ab808fd4216a62d614086fe051f",
              "IPY_MODEL_3ae501affe274bfa8c6d26f06095e200"
            ],
            "layout": "IPY_MODEL_7ffd3c08117249bda123e7e7dcd88e06"
          }
        },
        "ffe1b371614c4a5ba639ec7c171d2e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9986fa2d15964d28898a999386dc2f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_2aa7c8d3874947e2b91f66d21156ad2e",
            "value": "Generating test split: "
          }
        },
        "71f00ab808fd4216a62d614086fe051f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf4ecf375db423ab1f6f0cedfc24f11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbc7dff7162d4001b5964fa6e220cc95",
            "value": 1
          }
        },
        "3ae501affe274bfa8c6d26f06095e200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18a1b07b3cb4a20ac612258ad3d6c20",
            "placeholder": "​",
            "style": "IPY_MODEL_e7c95420e4524c17bac3c0a8ff99b025",
            "value": " 3072/0 [00:02&lt;00:00, 1109.49 examples/s]"
          }
        },
        "7ffd3c08117249bda123e7e7dcd88e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9986fa2d15964d28898a999386dc2f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa7c8d3874947e2b91f66d21156ad2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf4ecf375db423ab1f6f0cedfc24f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cbc7dff7162d4001b5964fa6e220cc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d18a1b07b3cb4a20ac612258ad3d6c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c95420e4524c17bac3c0a8ff99b025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a7129fb3759426caf0594b784343c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_172c631c808a498189335756360f9a24",
              "IPY_MODEL_d1181ccb86724ff2ada86c4153fa6f74",
              "IPY_MODEL_3a56f5099a294e8da9750d22001cae3f"
            ],
            "layout": "IPY_MODEL_230facabdb1849c2a4fde6c91fb97702"
          }
        },
        "172c631c808a498189335756360f9a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910f883c0bbb42999d61d956db2b7e52",
            "placeholder": "​",
            "style": "IPY_MODEL_9ab78da65bd747b885561af5840edc0d",
            "value": "Generating validation split: "
          }
        },
        "d1181ccb86724ff2ada86c4153fa6f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f9d9157e87448c7b522015d2b5e3493",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b0cedcdd5484a06aec442aa3030390d",
            "value": 1
          }
        },
        "3a56f5099a294e8da9750d22001cae3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d2f237c1ee14a2c9ca6fa92858a73b7",
            "placeholder": "​",
            "style": "IPY_MODEL_48a7fd0dcaa84a40adefc955353aa20e",
            "value": " 2416/0 [00:01&lt;00:00, 1133.84 examples/s]"
          }
        },
        "230facabdb1849c2a4fde6c91fb97702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910f883c0bbb42999d61d956db2b7e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab78da65bd747b885561af5840edc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f9d9157e87448c7b522015d2b5e3493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4b0cedcdd5484a06aec442aa3030390d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d2f237c1ee14a2c9ca6fa92858a73b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a7fd0dcaa84a40adefc955353aa20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaf6d9d7bcb74b5d9ee1a0a73da49e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99ad30c7759f491c95b3e3686e9b3071",
              "IPY_MODEL_60732c3ac6c4402fa8731f9a708e9200",
              "IPY_MODEL_af4dbf58e83a440f9442dd4e4f034863"
            ],
            "layout": "IPY_MODEL_5d01dd31f18f4638ba0bb425e2d743ab"
          }
        },
        "99ad30c7759f491c95b3e3686e9b3071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d2d28fcc184059b0a24eba3b680e81",
            "placeholder": "​",
            "style": "IPY_MODEL_94f2c41a7d6a4216b68d2622b90bd716",
            "value": "Generating other split: "
          }
        },
        "60732c3ac6c4402fa8731f9a708e9200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d123379f7274e46ab6f4a5b756a3d94",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2309f10ace0043e8bc236cc39497dc5c",
            "value": 1
          }
        },
        "af4dbf58e83a440f9442dd4e4f034863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc24501c7cbc4b689918ee10fcb2ed73",
            "placeholder": "​",
            "style": "IPY_MODEL_274c71e215974fa9862eecf3b1316a58",
            "value": " 3767/0 [00:02&lt;00:00, 2208.57 examples/s]"
          }
        },
        "5d01dd31f18f4638ba0bb425e2d743ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d2d28fcc184059b0a24eba3b680e81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f2c41a7d6a4216b68d2622b90bd716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d123379f7274e46ab6f4a5b756a3d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2309f10ace0043e8bc236cc39497dc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc24501c7cbc4b689918ee10fcb2ed73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274c71e215974fa9862eecf3b1316a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9c004db91c14668b6088f46bf4a5713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa07060e87d241e3a0bc72c88ce972d1",
              "IPY_MODEL_c5e366786d5a48c28ca6aef685b170d6",
              "IPY_MODEL_14979eeec8fe4f958f624abe2e412d1c"
            ],
            "layout": "IPY_MODEL_92e48ad23618430e8ba1c14e7b4be4bd"
          }
        },
        "fa07060e87d241e3a0bc72c88ce972d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8e7dcd3b73497c8192e3b825f2a1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_94386c405bac4094b5403dc6d2089ad7",
            "value": "Generating validated split: "
          }
        },
        "c5e366786d5a48c28ca6aef685b170d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a0f45790704bddb20e0fc6cc021dc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c69acf080f82494684b13bc5c84452df",
            "value": 1
          }
        },
        "14979eeec8fe4f958f624abe2e412d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af3e5b75b1748fa8303a0ba7174f004",
            "placeholder": "​",
            "style": "IPY_MODEL_d7cfa195350146dab26f287393dcbfdf",
            "value": " 10173/0 [00:05&lt;00:00, 1203.01 examples/s]"
          }
        },
        "92e48ad23618430e8ba1c14e7b4be4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8e7dcd3b73497c8192e3b825f2a1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94386c405bac4094b5403dc6d2089ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78a0f45790704bddb20e0fc6cc021dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c69acf080f82494684b13bc5c84452df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4af3e5b75b1748fa8303a0ba7174f004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7cfa195350146dab26f287393dcbfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2f0e7459b3f4518acd80910b02afbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4589c89b3e384b3aab6affcb4b5a9646",
              "IPY_MODEL_1863f9c325f541a0931687a706b629c4",
              "IPY_MODEL_1bc5efda55e14142a5a41d30d94ed812"
            ],
            "layout": "IPY_MODEL_06812d1505914993883714be78553c45"
          }
        },
        "4589c89b3e384b3aab6affcb4b5a9646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544df24dd87b4fcfac0e72d2d2392ec3",
            "placeholder": "​",
            "style": "IPY_MODEL_133f88f9c0354ca5b72f0d2b257bc066",
            "value": "Generating invalidated split: "
          }
        },
        "1863f9c325f541a0931687a706b629c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb5096705a14975aa572cf9fbf7c351",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3be399d6e661428b8894be3e24885d3e",
            "value": 1
          }
        },
        "1bc5efda55e14142a5a41d30d94ed812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af47caeca8de46a4bc0c00d7bb801211",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0989dc083545c0a9359b8925e67718",
            "value": " 757/0 [00:01&lt;00:00, 426.42 examples/s]"
          }
        },
        "06812d1505914993883714be78553c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "544df24dd87b4fcfac0e72d2d2392ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133f88f9c0354ca5b72f0d2b257bc066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb5096705a14975aa572cf9fbf7c351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3be399d6e661428b8894be3e24885d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af47caeca8de46a4bc0c00d7bb801211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0989dc083545c0a9359b8925e67718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b224bd3a49f440609e72aca8de29027a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be68a86b2dc54123b9f78ed758b03e8d",
              "IPY_MODEL_478527a4b44045c4a40a10b9f6d14442",
              "IPY_MODEL_90424414e2ef4d8f887e5210b7a36aa1"
            ],
            "layout": "IPY_MODEL_75ec815dbc7b43d2907d12db3a69e8b7"
          }
        },
        "be68a86b2dc54123b9f78ed758b03e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8d9bbfabe043a6a5a55fb4c7b44344",
            "placeholder": "​",
            "style": "IPY_MODEL_3e868311faf3404ba92058692f423388",
            "value": "Downloading data: 100%"
          }
        },
        "478527a4b44045c4a40a10b9f6d14442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215d8c849e5b489b9a988e09a8007c8b",
            "max": 64410112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e892f8799ce487bb72662b2ab072d9d",
            "value": 64410112
          }
        },
        "90424414e2ef4d8f887e5210b7a36aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3930002b623642e192df0c8a2f0bd9c6",
            "placeholder": "​",
            "style": "IPY_MODEL_bcbf9018c3494890bf9b6071e6fa1eb4",
            "value": " 64.4M/64.4M [00:00&lt;00:00, 87.6MB/s]"
          }
        },
        "75ec815dbc7b43d2907d12db3a69e8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8d9bbfabe043a6a5a55fb4c7b44344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e868311faf3404ba92058692f423388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215d8c849e5b489b9a988e09a8007c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e892f8799ce487bb72662b2ab072d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3930002b623642e192df0c8a2f0bd9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbf9018c3494890bf9b6071e6fa1eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7eb09f2fec48d8a4d8b2eb5b446bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eb4a998c85d44668a03d278e107d24e",
              "IPY_MODEL_4f47de6f12c04e4fb9f4f1d7033b12bb",
              "IPY_MODEL_b954e1b5a2674aaf8c8e9f7b68028342"
            ],
            "layout": "IPY_MODEL_ae2d94211b1640e98aaf13a6186ebca6"
          }
        },
        "1eb4a998c85d44668a03d278e107d24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5443dde30ac04b44b1a39df4f405ff07",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0f74eb25d94762babba0e46dc15509",
            "value": "Generating text split: "
          }
        },
        "4f47de6f12c04e4fb9f4f1d7033b12bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee7e248ce43c46898151e6957b07105e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_249f126300b148b4862c4038a2e74ef9",
            "value": 1
          }
        },
        "b954e1b5a2674aaf8c8e9f7b68028342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f8c9822e68489aaf66d2a1ef4fbff1",
            "placeholder": "​",
            "style": "IPY_MODEL_97f2557a8aff4fdba5b45b42c169c6a5",
            "value": " 1032/0 [00:01&lt;00:00, 603.92 examples/s]"
          }
        },
        "ae2d94211b1640e98aaf13a6186ebca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5443dde30ac04b44b1a39df4f405ff07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0f74eb25d94762babba0e46dc15509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee7e248ce43c46898151e6957b07105e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "249f126300b148b4862c4038a2e74ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91f8c9822e68489aaf66d2a1ef4fbff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f2557a8aff4fdba5b45b42c169c6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9dbfbf1620d49a697c7176bf80071b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b993933e17b4ec685c97e33ca92893a",
              "IPY_MODEL_11c5ffddb2774d39af67ce808ea80171",
              "IPY_MODEL_dfdd9f91092a40b48296d247c12812a0"
            ],
            "layout": "IPY_MODEL_d46ed3c9f09a43f1979be4ba973af7e8"
          }
        },
        "0b993933e17b4ec685c97e33ca92893a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91184721dd1a4fa5a3f0604623d885fb",
            "placeholder": "​",
            "style": "IPY_MODEL_020a541beaa34c9e8a6fa0e7695360fb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "11c5ffddb2774d39af67ce808ea80171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0d7b6125a5412f9fa9c52075690351",
            "max": 967122759,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c943bdc937c4ca29fc3ebfcf2ba8764",
            "value": 967122759
          }
        },
        "dfdd9f91092a40b48296d247c12812a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4e80a53fa04db49f877012e056c57f",
            "placeholder": "​",
            "style": "IPY_MODEL_d3af644b6fb24a578f820e174a776dda",
            "value": " 967M/967M [00:47&lt;00:00, 20.7MB/s]"
          }
        },
        "d46ed3c9f09a43f1979be4ba973af7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91184721dd1a4fa5a3f0604623d885fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020a541beaa34c9e8a6fa0e7695360fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f0d7b6125a5412f9fa9c52075690351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c943bdc937c4ca29fc3ebfcf2ba8764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4e80a53fa04db49f877012e056c57f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3af644b6fb24a578f820e174a776dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c4b754c910c4e82abaa9818cea25827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e057ed8e9d8483d82c22aa04eb1da6f",
              "IPY_MODEL_aafd20e5307b4219ab68771ad64234b4",
              "IPY_MODEL_4da88e6d50524d4687bc230b026c1b67"
            ],
            "layout": "IPY_MODEL_3a25f187d31b481e81df928e5cece90f"
          }
        },
        "5e057ed8e9d8483d82c22aa04eb1da6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1c7db967fe4be4ba0bab6af503b48d",
            "placeholder": "​",
            "style": "IPY_MODEL_587d9632dabb41afbcf4683a85beed57",
            "value": "config.json: 100%"
          }
        },
        "aafd20e5307b4219ab68771ad64234b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452c6d1dc5b443f98d6664ddea5fffff",
            "max": 1967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92e8fdc2f84b407a9459606a5361b3ff",
            "value": 1967
          }
        },
        "4da88e6d50524d4687bc230b026c1b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e59633001d844518c7ff17b9520c58b",
            "placeholder": "​",
            "style": "IPY_MODEL_f8a90c593ccc454fb452015581463c34",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 178kB/s]"
          }
        },
        "3a25f187d31b481e81df928e5cece90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1c7db967fe4be4ba0bab6af503b48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587d9632dabb41afbcf4683a85beed57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "452c6d1dc5b443f98d6664ddea5fffff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e8fdc2f84b407a9459606a5361b3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e59633001d844518c7ff17b9520c58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a90c593ccc454fb452015581463c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdc1387613a4f98b8b3c7d47b499585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cb6909cca1340089a786e99b5eac46b",
              "IPY_MODEL_e7f6cde221e34fb3bd7168dcbed88b95",
              "IPY_MODEL_04c5aa8989d04b6db87c6d5d02c9fe31"
            ],
            "layout": "IPY_MODEL_71c0515309114b64877f145a41d62f60"
          }
        },
        "8cb6909cca1340089a786e99b5eac46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b1032f0a474cedabbfb2bff2837df9",
            "placeholder": "​",
            "style": "IPY_MODEL_f2e76e8459e04ba6a7ba28f63a295cf6",
            "value": "model.safetensors: 100%"
          }
        },
        "e7f6cde221e34fb3bd7168dcbed88b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba96771636574e2b902449dfd7a392ea",
            "max": 966995080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3071cad79909425eb9c17d28b3f4c71e",
            "value": 966995080
          }
        },
        "04c5aa8989d04b6db87c6d5d02c9fe31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7ce1e867004d8bb604cf52db1d2cd2",
            "placeholder": "​",
            "style": "IPY_MODEL_e2ac25180a7e43938a6830aeece0ed79",
            "value": " 967M/967M [01:07&lt;00:00, 13.4MB/s]"
          }
        },
        "71c0515309114b64877f145a41d62f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b1032f0a474cedabbfb2bff2837df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e76e8459e04ba6a7ba28f63a295cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba96771636574e2b902449dfd7a392ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3071cad79909425eb9c17d28b3f4c71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7ce1e867004d8bb604cf52db1d2cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ac25180a7e43938a6830aeece0ed79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474bd86cd7cc487abc15cb1bcb43fa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eba231871654fac92c5eab5c2d1b30f",
              "IPY_MODEL_73f61a4eb15f485bb800a14a55ea3ff5",
              "IPY_MODEL_7ede266ab2cf44eb9210c23f54304f13"
            ],
            "layout": "IPY_MODEL_b9747e58922c49ffa248a94819d83a09"
          }
        },
        "0eba231871654fac92c5eab5c2d1b30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2464cb6e239740c990cdaf257bcbeafc",
            "placeholder": "​",
            "style": "IPY_MODEL_032282b431194fc89f6fb2523316bab1",
            "value": "generation_config.json: 100%"
          }
        },
        "73f61a4eb15f485bb800a14a55ea3ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52da4d83c83e4ebcbff787f442c489a2",
            "max": 3837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7adf0b5c6484c4d9779f64974b1acdb",
            "value": 3837
          }
        },
        "7ede266ab2cf44eb9210c23f54304f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21f1cb0e47b45639278811f9076e859",
            "placeholder": "​",
            "style": "IPY_MODEL_49a3262a46de42b9b5cf66f1332b0c97",
            "value": " 3.84k/3.84k [00:00&lt;00:00, 330kB/s]"
          }
        },
        "b9747e58922c49ffa248a94819d83a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2464cb6e239740c990cdaf257bcbeafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032282b431194fc89f6fb2523316bab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52da4d83c83e4ebcbff787f442c489a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7adf0b5c6484c4d9779f64974b1acdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e21f1cb0e47b45639278811f9076e859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a3262a46de42b9b5cf66f1332b0c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}